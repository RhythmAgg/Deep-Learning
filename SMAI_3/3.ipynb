{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6df54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a59657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.200000</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.900000</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.100000</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.200000</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.100000</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.700000</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.300000</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.880000</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM        AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.200000  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.900000  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.100000  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.800000  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.200000  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...        ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.100000  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.700000  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.000000  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.300000  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  68.518519  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B      LSTAT  MEDV  \n",
       "0       15.3  396.90   4.980000  24.0  \n",
       "1       17.8  396.90   9.140000  21.6  \n",
       "2       17.8  392.83   4.030000  34.7  \n",
       "3       18.7  394.63   2.940000  33.4  \n",
       "4       18.7  396.90  12.715432  36.2  \n",
       "..       ...     ...        ...   ...  \n",
       "501     21.0  391.99  12.715432  22.4  \n",
       "502     21.0  396.90   9.080000  20.6  \n",
       "503     21.0  396.90   5.640000  23.9  \n",
       "504     21.0  393.45   6.480000  22.0  \n",
       "505     21.0  396.90   7.880000  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/HousingData.csv')\n",
    "df = df.fillna(df.mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea3b6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_rest, y_train, y_rest = train_test_split(df.iloc[:,:-1], df['MEDV'].values.reshape(-1,1), test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_rest, y_rest, test_size=0.5, random_state=42)\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7ee041",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = scalar.transform(x_train)\n",
    "x_validation = scalar.transform(x_val)\n",
    "x_testing = scalar.transform(x_test)\n",
    "\n",
    "# # Replacing Nan with 0\n",
    "# x_training[np.isnan(x_training)] = 1\n",
    "# x_validation[np.isnan(x_validation)] = 1\n",
    "# x_testing[np.isnan(x_testing)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9879f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true,y_pred):\n",
    "    return np.square(y_pred - y_true).mean()\n",
    "\n",
    "def tanh(y):\n",
    "#     return (np.exp(y)-np.exp(-y)) / (np.exp(y)+np.exp(-y))\n",
    "    return 2 / (1 + np.exp(-2 * y)) - 1\n",
    "\n",
    "def relu(y):\n",
    "    temp = np.where(y >= 0,y,0.0)\n",
    "    return temp\n",
    "#     return np.where(temp > 10,10.0,temp)\n",
    "\n",
    "def sigmoid(y):\n",
    "    return 1 / (1 + np.exp(-y))\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self,input_size,output_size,num_layers,layer_sizes,activations,optimiser = 'batch',lr = 0.01):\n",
    "        self.lr = lr\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activations = activations\n",
    "        self.optimiser = optimiser\n",
    "#         Initialising weights and biases\n",
    "        self.w_and_b = []\n",
    "        prev_size = input_size\n",
    "        for layer in range(num_layers):\n",
    "            self.w_and_b.append(0.1*np.random.rand(layer_sizes[layer],prev_size+1))\n",
    "            prev_size = layer_sizes[layer]\n",
    "        self.w_and_b.append(np.random.rand(output_size,prev_size+1))\n",
    "                            \n",
    "        self.layer_inputs = []    \n",
    "        self.layer_outputs = []\n",
    "        self.out = np.zeros(output_size)\n",
    "    \n",
    "    def tanh_grad(self,z):\n",
    "        return 1 - tanh(z)**2\n",
    "    \n",
    "    def relu_grad(self,z):\n",
    "        return np.where(z > 0,1.0,0.0)\n",
    "                            \n",
    "    def sigmoid_grad(self,z):\n",
    "        return sigmoid(z)*(1 - sigmoid(z))\n",
    "    \n",
    "    def mseGrad(self,y_true,y_pred):\n",
    "        return (2/len(y_true))*(y_pred - y_true)                    \n",
    "        \n",
    "    def forward(self,x):\n",
    "        inp = np.append(x,np.ones((x.shape[0],1)),axis=1)\n",
    "        for layer in range(self.num_layers):    \n",
    "            self.layer_inputs.append(inp) # (914,12)\n",
    "            z = inp @ self.w_and_b[layer].T\n",
    "            y = (self.activations[layer])(z)\n",
    "            self.layer_outputs.append(z)\n",
    "            inp = np.append(y,np.ones((y.shape[0],1)),axis=1)\n",
    "\n",
    "        self.layer_inputs.append(inp) # (914,12)\n",
    "        z = inp @ self.w_and_b[self.num_layers].T\n",
    "        self.layer_outputs.append(z)\n",
    "        self.out = z\n",
    "        return z\n",
    "    \n",
    "    def backward(self,y_true):\n",
    "        w_and_b_gradients = []\n",
    "        grad_y_out = self.mseGrad(y_true,self.out) # (914,1)\n",
    "        grad_w_and_b = grad_y_out.T @ self.layer_inputs[-1]\n",
    "        w_and_b_gradients.append(grad_w_and_b)\n",
    "        grad_y = grad_y_out @ self.w_and_b[-1][:,:-1]\n",
    "        for layer in range(self.num_layers-1,-1,-1):\n",
    "            grad_z = []\n",
    "            if(self.activations[layer] == tanh):\n",
    "                grad_z = grad_y*self.tanh_grad(self.layer_outputs[layer])\n",
    "            elif(self.activations[layer] == relu):\n",
    "                grad_z = grad_y*self.relu_grad(self.layer_outputs[layer])\n",
    "            elif(self.activations[layer] == sigmoid):\n",
    "                grad_z = grad_y*self.sigmoid_grad(self.layer_outputs[layer])\n",
    "            \n",
    "            grad_w_and_b = grad_z.T @ self.layer_inputs[layer] \n",
    "            w_and_b_gradients.append(grad_w_and_b)\n",
    "            grad_y = grad_z@self.w_and_b[layer][:,:-1]\n",
    "            \n",
    "        for layer in range(self.num_layers,-1,-1):\n",
    "            self.w_and_b[layer] -= self.lr*w_and_b_gradients[self.num_layers-layer]\n",
    "#             print(f\"{layer} => w and b : {self.w_and_b[layer]}\")\n",
    "\n",
    "    def training(self,x,y,epochs):\n",
    "        num_samples = len(x)\n",
    "        batch_size = 0\n",
    "        prev_5_best = 0\n",
    "        best_epoch = 0\n",
    "        if(self.optimiser == 'batch'):\n",
    "            batch_size = x.shape[0]\n",
    "        elif(self.optimiser == 'sgd'):\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = 64\n",
    "        for epoch in range(epochs):\n",
    "            permutation = np.random.permutation(len(x))\n",
    "            x_shuffled = x[permutation]\n",
    "            y_shuffled = y[permutation]\n",
    "            total_batches = math.ceil(num_samples / batch_size)\n",
    "            for i in range(0,total_batches,batch_size):\n",
    "                out = self.forward(x_shuffled[i:batch_size+i])\n",
    "#                 print(f\"Epoch [{epoch}], batch [{i+1}] Training => Loss : {loss:.4f}\")\n",
    "                self.backward(y_shuffled[i:batch_size+i])\n",
    "            \n",
    "#             loss = mse(y_shuffled[i:batch_size+1],out)\n",
    "#             if(loss < prev_5_best):\n",
    "#                 prev_5_best = loss\n",
    "#                 best_epoch = epoch\n",
    "#             else:\n",
    "#                 best_epoch +=1\n",
    "#             if(best_epoch > 5):\n",
    "#                 break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65853a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkhushi1703\u001b[0m (\u001b[33msmai-khushi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c51cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_training.shape[1]\n",
    "output_size = 1\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8de8e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e756b17f51d4fcdabf2054269bf521d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167471289324264, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_041339-xj6o5ndq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/xj6o5ndq' target=\"_blank\">drawn-grass-28</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/xj6o5ndq' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/xj6o5ndq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Training => MSE : 60.6164\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => MSE : 54.1406\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 7.3580\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => R2 score : 0.3473\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Training => MSE : 85.1451\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => MSE : 78.0648\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 8.8354\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.0589\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Training => MSE : 57.8083\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => MSE : 37.5556\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 6.1283\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => R2 score : 0.5473\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Training => MSE : 104.0491\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => MSE : 108.3140\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 10.4074\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => R2 score : -0.3057\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Training => MSE : 48.6920\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => MSE : 41.7933\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 6.4648\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.4962\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Training => MSE : 77.5545\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => MSE : 86.8851\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 9.3212\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => R2 score : -0.0474\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Training => MSE : 90.2558\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => MSE : 86.6071\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 9.3063\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => R2 score : -0.0440\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Training => MSE : 59.9928\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => MSE : 52.6560\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 7.2564\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.3652\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Training => MSE : 46.7426\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => MSE : 24.0631\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 4.9054\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => R2 score : 0.7099\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Training => MSE : 68.8242\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => MSE : 69.0751\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 8.3111\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.1673\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Training => MSE : 48.2123\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => MSE : 43.6574\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 6.6074\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.4737\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Training => MSE : 53.5197\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => MSE : 40.3189\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 6.3497\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.5140\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Training => MSE : 64.4358\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => MSE : 52.5154\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 7.2468\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.3669\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Training => MSE : 71.4534\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => MSE : 65.5630\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 8.0971\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.2096\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Training => MSE : 57.1049\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => MSE : 50.2855\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 7.0912\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.3938\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Training => MSE : 80.0673\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => MSE : 82.0919\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 9.0605\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.0104\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Training => MSE : 61.2952\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => MSE : 62.1266\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 7.8820\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.2511\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Training => MSE : 63.9721\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => MSE : 58.4765\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 7.6470\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.2951\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Training => MSE : 81.9350\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => MSE : 71.1250\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 8.4336\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.1426\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Training => MSE : 65.0765\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => MSE : 53.3999\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 7.3075\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.3563\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Training => MSE : 58.4674\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => MSE : 50.6921\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 7.1198\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.3889\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Training => MSE : 52.4287\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => MSE : 52.4081\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 7.2393\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.3682\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Training => MSE : 65.9510\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => MSE : 61.1658\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 7.8209\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.2627\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Training => MSE : 51.6767\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => MSE : 63.0278\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 7.9390\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.2402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Training => MSE : 69.9975\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => MSE : 67.5209\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 8.2171\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.1860\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Training => MSE : 64.0548\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => MSE : 55.2665\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 7.4341\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.3338\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Training => MSE : 61.9943\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => MSE : 47.4273\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 6.8867\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.4283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cb4a4b036e429b9fda2f47c507c4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>▃▆▂█▁▅▆▃▁▄▁▂▃▄▂▅▃▃▅▃▂▂▃▂▄▃▃</td></tr><tr><td>Validation MSE</td><td>▃▅▂█▂▆▆▃▁▅▃▂▃▄▃▆▄▄▅▃▃▃▄▄▅▄▃</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>61.99427</td></tr><tr><td>Validation MSE</td><td>47.42726</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-grass-28</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/xj6o5ndq' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/xj6o5ndq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_041339-xj6o5ndq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_041539-pyqtkd3k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/pyqtkd3k' target=\"_blank\">fresh-shadow-29</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/pyqtkd3k' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/pyqtkd3k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 94.4824\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 97.0451\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 9.8511\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : -0.1699\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 91.2050\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 90.6555\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 9.5213\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : -0.0928\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 69.5707\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 60.6679\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 7.7890\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : 0.2687\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 88.6575\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 88.2779\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 9.3956\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : -0.0642\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 53.5282\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 39.8224\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 6.3105\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : 0.5199\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 57.5544\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 48.6391\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 6.9742\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : 0.4137\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 89.1983\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 89.4540\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 9.4580\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : -0.0784\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 85.0845\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 83.2832\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 9.1260\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : -0.0040\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 94.2248\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 95.5551\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 9.7752\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : -0.1519\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 89.9076\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 89.9143\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 9.4823\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : -0.0839\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 73.8436\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 72.7312\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 8.5283\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.1232\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 76.9487\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 61.8959\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 7.8674\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.2539\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 94.1936\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 93.5003\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 9.6696\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : -0.1271\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 52.3036\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 40.6697\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 6.3773\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.5097\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 69.8553\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 63.2952\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 7.9558\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.2370\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 90.0748\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 90.1791\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 9.4963\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : -0.0871\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 76.9118\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 71.7995\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 8.4735\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.1345\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 54.2758\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 52.3652\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 7.2364\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.3687\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 63.8242\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 48.0088\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 6.9288\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.4213\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 63.9482\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 52.3488\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 7.2352\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.3689\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 103.3507\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 108.3003\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 10.4067\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : -0.3055\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 51.8122\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 43.8256\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 6.6201\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.4717\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 87.0517\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 82.4963\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 9.0827\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 59.7371\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 46.5272\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 6.8211\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : 0.4391\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 76.5960\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 72.1920\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 8.4966\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.1297\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 73.2133\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 47.4427\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 6.8879\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.4281\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 62.6025\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 42.4205\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 6.5131\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : 0.4886\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5111ff4c4149a098461b7e249e4ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.071443…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>▇▆▃▆▁▂▆▆▇▆▄▄▇▁▃▆▄▁▃▃█▁▆▂▄▄▂</td></tr><tr><td>Validation MSE</td><td>▇▆▃▆▁▂▆▅▇▆▄▃▆▁▃▆▄▂▂▂█▁▅▂▄▂▁</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>62.60246</td></tr><tr><td>Validation MSE</td><td>42.42052</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-shadow-29</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/pyqtkd3k' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/pyqtkd3k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_041539-pyqtkd3k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af45c23af4414821966b7f48f48e1eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011168251855350617, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_041740-akcw60sg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/akcw60sg' target=\"_blank\">good-puddle-30</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/akcw60sg' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/akcw60sg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Training => MSE : 56.4164\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Validation => MSE : 48.0662\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Validation => RMSE : 6.9330\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Validation => R2 score : 0.4206\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Training => MSE : 94.1703\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Validation => MSE : 69.5160\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Validation => RMSE : 8.3376\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Validation => R2 score : 0.1620\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Training => MSE : 48.1975\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Validation => MSE : 24.3381\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Validation => RMSE : 4.9334\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Validation => R2 score : 0.7066\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Training => MSE : 42.5169\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Validation => MSE : 26.4630\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Validation => RMSE : 5.1442\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Validation => R2 score : 0.6810\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Training => MSE : 43.4764\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Validation => MSE : 25.8096\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Validation => RMSE : 5.0803\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Validation => R2 score : 0.6889\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Training => MSE : 48.2890\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Validation => MSE : 36.4990\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Validation => RMSE : 6.0414\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Validation => R2 score : 0.5600\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Training => MSE : 48.5742\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Validation => MSE : 32.6926\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Validation => RMSE : 5.7177\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Validation => R2 score : 0.6059\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Training => MSE : 37.7445\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Validation => MSE : 27.9197\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Validation => RMSE : 5.2839\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Validation => R2 score : 0.6634\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Training => MSE : 52.2476\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Validation => MSE : 36.2352\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Validation => RMSE : 6.0196\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Validation => R2 score : 0.5632\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Training => MSE : 38.4272\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Validation => MSE : 19.7448\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Validation => RMSE : 4.4435\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Validation => R2 score : 0.7620\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Training => MSE : 84.7272\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Validation => MSE : 79.8745\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Validation => RMSE : 8.9373\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Validation => R2 score : 0.0371\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Training => MSE : 38.1605\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Validation => MSE : 25.2855\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Validation => RMSE : 5.0285\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Validation => R2 score : 0.6952\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Training => MSE : 47.4703\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Validation => MSE : 28.3528\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Validation => RMSE : 5.3247\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Validation => R2 score : 0.6582\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Training => MSE : 30.5825\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Validation => MSE : 14.5812\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Validation => RMSE : 3.8185\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Validation => R2 score : 0.8242\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Training => MSE : 28.6200\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Validation => MSE : 17.7329\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Validation => RMSE : 4.2110\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Validation => R2 score : 0.7862\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Training => MSE : 53.1162\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Validation => MSE : 29.8733\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Validation => RMSE : 5.4656\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Validation => R2 score : 0.6399\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Training => MSE : 36.0093\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Validation => MSE : 23.3201\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Validation => RMSE : 4.8291\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Validation => R2 score : 0.7189\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Training => MSE : 38.3774\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Validation => MSE : 20.7114\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Validation => RMSE : 4.5510\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Validation => R2 score : 0.7503\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Training => MSE : 51.1236\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Validation => MSE : 28.8294\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Validation => RMSE : 5.3693\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Validation => R2 score : 0.6525\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Training => MSE : 47.4950\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Validation => MSE : 36.7952\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Validation => RMSE : 6.0659\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.5564\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Training => MSE : 39.6412\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Validation => MSE : 30.1899\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Validation => RMSE : 5.4945\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Validation => R2 score : 0.6361\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Training => MSE : 47.5815\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Validation => MSE : 28.8285\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Validation => RMSE : 5.3692\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Validation => R2 score : 0.6525\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Training => MSE : 80.3748\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Validation => MSE : 57.3060\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Validation => RMSE : 7.5701\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.3092\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Training => MSE : 34.8202\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Validation => MSE : 25.9768\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Validation => RMSE : 5.0967\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Validation => R2 score : 0.6869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Training => MSE : 43.4886\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Validation => MSE : 25.7092\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Validation => RMSE : 5.0704\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Validation => R2 score : 0.6901\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Training => MSE : 26.7311\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => MSE : 21.4425\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => RMSE : 4.6306\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.7415\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Training => MSE : 31.5134\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Validation => MSE : 19.0435\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Validation => RMSE : 4.3639\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Validation => R2 score : 0.7704\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef18a4c175cf45938759882865fdc9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.073202…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>▄█▃▃▃▃▃▂▄▂▇▂▃▁▁▄▂▂▄▃▂▃▇▂▃▁▁</td></tr><tr><td>Validation MSE</td><td>▅▇▂▂▂▃▃▂▃▂█▂▂▁▁▃▂▂▃▃▃▃▆▂▂▂▁</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>31.51342</td></tr><tr><td>Validation MSE</td><td>19.04349</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-puddle-30</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/akcw60sg' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/akcw60sg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_041740-akcw60sg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [4000,6000,8000]\n",
    "layer_sizes = [[8],[25],[64]]\n",
    "activations =  [[tanh],[sigmoid],[relu]]\n",
    "activation_names = ['tanh','sigmoid','relu']\n",
    "optimiser = 'batch'\n",
    "\n",
    "table = []\n",
    "lrs = [0.001,0.002,0.003]\n",
    "\n",
    "#  batch\n",
    "for idx,activation in enumerate(activations):\n",
    "    wandb.init(project = \"Multilayer Regression Perceptron\")\n",
    "    for lr in lrs:\n",
    "        for epoch in epochs:\n",
    "            for size in layer_sizes:\n",
    "                regressor = MLP(input_size,output_size,num_layers,size,activation,'batch',lr)\n",
    "                size = size[0]\n",
    "        #       Training\n",
    "                regressor.training(x_training,y_train,epoch)\n",
    "        #       Training metrics\n",
    "                out = regressor.forward(x_training)\n",
    "                mse_train = mse(y_train,out)\n",
    "                print(\"TRAINING\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Training => MSE : {mse_train:.4f}\")\n",
    "\n",
    "        #       Validation\n",
    "                out = regressor.forward(x_validation)\n",
    "                mse_val = mean_squared_error(y_val, out)\n",
    "                rmse_val = mean_squared_error(y_val, out, squared=False)\n",
    "                r2_val = r2_score(y_val, out)\n",
    "                print(\"VALIDATION\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => MSE : {mse_val:.4f}\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => RMSE : {rmse_val:.4f}\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => R2 score : {r2_val:.4f}\")\n",
    "\n",
    "                wandb.log({\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"epochs\": epoch,\n",
    "                    \"layer_size\": size,\n",
    "                    \"Validation MSE\": mse_val,\n",
    "                    \"Training MSE\": mse_train,\n",
    "                })\n",
    "                entry = [lr,epoch,idx,size,mse_val,rmse_val,r2_val]\n",
    "                table.append(entry)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a2e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_batch = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87c8dca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Activation</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>54.140618</td>\n",
       "      <td>7.358031</td>\n",
       "      <td>0.347340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>78.064834</td>\n",
       "      <td>8.835431</td>\n",
       "      <td>0.058936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>37.555593</td>\n",
       "      <td>6.128262</td>\n",
       "      <td>0.547271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>108.313991</td>\n",
       "      <td>10.407401</td>\n",
       "      <td>-0.305714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>41.793350</td>\n",
       "      <td>6.464778</td>\n",
       "      <td>0.496185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>57.305965</td>\n",
       "      <td>7.570070</td>\n",
       "      <td>0.309182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>25.976757</td>\n",
       "      <td>5.096740</td>\n",
       "      <td>0.686853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>25.709159</td>\n",
       "      <td>5.070420</td>\n",
       "      <td>0.690079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>21.442516</td>\n",
       "      <td>4.630606</td>\n",
       "      <td>0.741513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>19.043485</td>\n",
       "      <td>4.363884</td>\n",
       "      <td>0.770433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  Activation  layer size         MSE       RMSE        R2\n",
       "0   0.001    4000           0           8   54.140618   7.358031  0.347340\n",
       "1   0.001    4000           0          25   78.064834   8.835431  0.058936\n",
       "2   0.001    4000           0          64   37.555593   6.128262  0.547271\n",
       "3   0.001    6000           0           8  108.313991  10.407401 -0.305714\n",
       "4   0.001    6000           0          25   41.793350   6.464778  0.496185\n",
       "..    ...     ...         ...         ...         ...        ...       ...\n",
       "76  0.003    6000           2          25   57.305965   7.570070  0.309182\n",
       "77  0.003    6000           2          64   25.976757   5.096740  0.686853\n",
       "78  0.003    8000           2           8   25.709159   5.070420  0.690079\n",
       "79  0.003    8000           2          25   21.442516   4.630606  0.741513\n",
       "80  0.003    8000           2          64   19.043485   4.363884  0.770433\n",
       "\n",
       "[81 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(table_batch,columns = ['LR','Epochs','Activation','layer size','MSE','RMSE','R2'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d75653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch tanh Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>24.063110</td>\n",
       "      <td>4.905416</td>\n",
       "      <td>0.709922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>37.555593</td>\n",
       "      <td>6.128262</td>\n",
       "      <td>0.547271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>40.318944</td>\n",
       "      <td>6.349720</td>\n",
       "      <td>0.513959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>41.793350</td>\n",
       "      <td>6.464778</td>\n",
       "      <td>0.496185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>43.657368</td>\n",
       "      <td>6.607372</td>\n",
       "      <td>0.473715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>47.427263</td>\n",
       "      <td>6.886745</td>\n",
       "      <td>0.428269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>50.285465</td>\n",
       "      <td>7.091224</td>\n",
       "      <td>0.393814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>50.692137</td>\n",
       "      <td>7.119841</td>\n",
       "      <td>0.388912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>52.408100</td>\n",
       "      <td>7.239344</td>\n",
       "      <td>0.368226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>52.515410</td>\n",
       "      <td>7.246752</td>\n",
       "      <td>0.366932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>52.655978</td>\n",
       "      <td>7.256444</td>\n",
       "      <td>0.365238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>53.399921</td>\n",
       "      <td>7.307525</td>\n",
       "      <td>0.356269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>54.140618</td>\n",
       "      <td>7.358031</td>\n",
       "      <td>0.347340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>55.266504</td>\n",
       "      <td>7.434144</td>\n",
       "      <td>0.333768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>58.476513</td>\n",
       "      <td>7.646994</td>\n",
       "      <td>0.295072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>61.165772</td>\n",
       "      <td>7.820855</td>\n",
       "      <td>0.262653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>62.126602</td>\n",
       "      <td>7.882043</td>\n",
       "      <td>0.251070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>63.027841</td>\n",
       "      <td>7.939008</td>\n",
       "      <td>0.240206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>65.562964</td>\n",
       "      <td>8.097096</td>\n",
       "      <td>0.209645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>67.520927</td>\n",
       "      <td>8.217112</td>\n",
       "      <td>0.186042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>69.075115</td>\n",
       "      <td>8.311144</td>\n",
       "      <td>0.167307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>71.125032</td>\n",
       "      <td>8.433566</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>78.064834</td>\n",
       "      <td>8.835431</td>\n",
       "      <td>0.058936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>82.091891</td>\n",
       "      <td>9.060458</td>\n",
       "      <td>0.010391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>86.607075</td>\n",
       "      <td>9.306292</td>\n",
       "      <td>-0.044039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>86.885063</td>\n",
       "      <td>9.321216</td>\n",
       "      <td>-0.047390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>108.313991</td>\n",
       "      <td>10.407401</td>\n",
       "      <td>-0.305714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size         MSE       RMSE        R2\n",
       "8   0.001    8000          64   24.063110   4.905416  0.709922\n",
       "2   0.001    4000          64   37.555593   6.128262  0.547271\n",
       "11  0.002    4000          64   40.318944   6.349720  0.513959\n",
       "4   0.001    6000          25   41.793350   6.464778  0.496185\n",
       "10  0.002    4000          25   43.657368   6.607372  0.473715\n",
       "26  0.003    8000          64   47.427263   6.886745  0.428269\n",
       "14  0.002    6000          64   50.285465   7.091224  0.393814\n",
       "20  0.003    4000          64   50.692137   7.119841  0.388912\n",
       "21  0.003    6000           8   52.408100   7.239344  0.368226\n",
       "12  0.002    6000           8   52.515410   7.246752  0.366932\n",
       "7   0.001    8000          25   52.655978   7.256444  0.365238\n",
       "19  0.003    4000          25   53.399921   7.307525  0.356269\n",
       "0   0.001    4000           8   54.140618   7.358031  0.347340\n",
       "25  0.003    8000          25   55.266504   7.434144  0.333768\n",
       "17  0.002    8000          64   58.476513   7.646994  0.295072\n",
       "22  0.003    6000          25   61.165772   7.820855  0.262653\n",
       "16  0.002    8000          25   62.126602   7.882043  0.251070\n",
       "23  0.003    6000          64   63.027841   7.939008  0.240206\n",
       "13  0.002    6000          25   65.562964   8.097096  0.209645\n",
       "24  0.003    8000           8   67.520927   8.217112  0.186042\n",
       "9   0.002    4000           8   69.075115   8.311144  0.167307\n",
       "18  0.003    4000           8   71.125032   8.433566  0.142595\n",
       "1   0.001    4000          25   78.064834   8.835431  0.058936\n",
       "15  0.002    8000           8   82.091891   9.060458  0.010391\n",
       "6   0.001    8000           8   86.607075   9.306292 -0.044039\n",
       "5   0.001    6000          64   86.885063   9.321216 -0.047390\n",
       "3   0.001    6000           8  108.313991  10.407401 -0.305714"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Batch tanh Metrics\")\n",
    "df_batch_tanh = table[table['Activation'] == 0].drop('Activation',axis = 1)\n",
    "df_batch_tanh = df_batch_tanh.sort_values(by='R2', ascending=False)\n",
    "df_batch_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98b1d311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch sigmoid Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>39.822357</td>\n",
       "      <td>6.310496</td>\n",
       "      <td>0.519946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>40.669739</td>\n",
       "      <td>6.377283</td>\n",
       "      <td>0.509730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>42.420519</td>\n",
       "      <td>6.513104</td>\n",
       "      <td>0.488625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>43.825565</td>\n",
       "      <td>6.620088</td>\n",
       "      <td>0.471687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>46.527223</td>\n",
       "      <td>6.821087</td>\n",
       "      <td>0.439119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>47.442704</td>\n",
       "      <td>6.887866</td>\n",
       "      <td>0.428083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>48.008758</td>\n",
       "      <td>6.928835</td>\n",
       "      <td>0.421259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>48.639124</td>\n",
       "      <td>6.974176</td>\n",
       "      <td>0.413660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>52.348756</td>\n",
       "      <td>7.235244</td>\n",
       "      <td>0.368941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>52.365200</td>\n",
       "      <td>7.236380</td>\n",
       "      <td>0.368743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>60.667862</td>\n",
       "      <td>7.788958</td>\n",
       "      <td>0.268655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>61.895930</td>\n",
       "      <td>7.867397</td>\n",
       "      <td>0.253851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>63.295236</td>\n",
       "      <td>7.955830</td>\n",
       "      <td>0.236982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>71.799516</td>\n",
       "      <td>8.473460</td>\n",
       "      <td>0.134464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>72.192032</td>\n",
       "      <td>8.496589</td>\n",
       "      <td>0.129732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>72.731193</td>\n",
       "      <td>8.528259</td>\n",
       "      <td>0.123233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>82.496282</td>\n",
       "      <td>9.082746</td>\n",
       "      <td>0.005516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>83.283241</td>\n",
       "      <td>9.125965</td>\n",
       "      <td>-0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>88.277906</td>\n",
       "      <td>9.395632</td>\n",
       "      <td>-0.064181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>89.453968</td>\n",
       "      <td>9.458011</td>\n",
       "      <td>-0.078358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>89.914308</td>\n",
       "      <td>9.482316</td>\n",
       "      <td>-0.083908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>90.179127</td>\n",
       "      <td>9.496269</td>\n",
       "      <td>-0.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>90.655514</td>\n",
       "      <td>9.521319</td>\n",
       "      <td>-0.092843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>93.500322</td>\n",
       "      <td>9.669556</td>\n",
       "      <td>-0.127137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>95.555062</td>\n",
       "      <td>9.775227</td>\n",
       "      <td>-0.151906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>97.045148</td>\n",
       "      <td>9.851150</td>\n",
       "      <td>-0.169869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>108.300298</td>\n",
       "      <td>10.406743</td>\n",
       "      <td>-0.305549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size         MSE       RMSE        R2\n",
       "31  0.001    6000          25   39.822357   6.310496  0.519946\n",
       "40  0.002    6000          25   40.669739   6.377283  0.509730\n",
       "53  0.003    8000          64   42.420519   6.513104  0.488625\n",
       "48  0.003    6000           8   43.825565   6.620088  0.471687\n",
       "50  0.003    6000          64   46.527223   6.821087  0.439119\n",
       "52  0.003    8000          25   47.442704   6.887866  0.428083\n",
       "45  0.003    4000           8   48.008758   6.928835  0.421259\n",
       "32  0.001    6000          64   48.639124   6.974176  0.413660\n",
       "46  0.003    4000          25   52.348756   7.235244  0.368941\n",
       "44  0.002    8000          64   52.365200   7.236380  0.368743\n",
       "29  0.001    4000          64   60.667862   7.788958  0.268655\n",
       "38  0.002    4000          64   61.895930   7.867397  0.253851\n",
       "41  0.002    6000          64   63.295236   7.955830  0.236982\n",
       "43  0.002    8000          25   71.799516   8.473460  0.134464\n",
       "51  0.003    8000           8   72.192032   8.496589  0.129732\n",
       "37  0.002    4000          25   72.731193   8.528259  0.123233\n",
       "49  0.003    6000          25   82.496282   9.082746  0.005516\n",
       "34  0.001    8000          25   83.283241   9.125965 -0.003971\n",
       "30  0.001    6000           8   88.277906   9.395632 -0.064181\n",
       "33  0.001    8000           8   89.453968   9.458011 -0.078358\n",
       "36  0.002    4000           8   89.914308   9.482316 -0.083908\n",
       "42  0.002    8000           8   90.179127   9.496269 -0.087100\n",
       "28  0.001    4000          25   90.655514   9.521319 -0.092843\n",
       "39  0.002    6000           8   93.500322   9.669556 -0.127137\n",
       "35  0.001    8000          64   95.555062   9.775227 -0.151906\n",
       "27  0.001    4000           8   97.045148   9.851150 -0.169869\n",
       "47  0.003    4000          64  108.300298  10.406743 -0.305549"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Batch sigmoid Metrics\")\n",
    "df_batch_sigmoid = table[table['Activation'] == 1].drop('Activation',axis = 1)\n",
    "df_batch_sigmoid = df_batch_sigmoid.sort_values(by='R2', ascending=False)\n",
    "df_batch_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34f5f6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ReLU Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>14.581198</td>\n",
       "      <td>3.818534</td>\n",
       "      <td>0.824225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>17.732855</td>\n",
       "      <td>4.211040</td>\n",
       "      <td>0.786232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>19.043485</td>\n",
       "      <td>4.363884</td>\n",
       "      <td>0.770433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>19.744770</td>\n",
       "      <td>4.443509</td>\n",
       "      <td>0.761979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>20.711379</td>\n",
       "      <td>4.550976</td>\n",
       "      <td>0.750326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>21.442516</td>\n",
       "      <td>4.630606</td>\n",
       "      <td>0.741513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>23.320110</td>\n",
       "      <td>4.829090</td>\n",
       "      <td>0.718878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>24.338104</td>\n",
       "      <td>4.933366</td>\n",
       "      <td>0.706607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>25.285458</td>\n",
       "      <td>5.028465</td>\n",
       "      <td>0.695186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>25.709159</td>\n",
       "      <td>5.070420</td>\n",
       "      <td>0.690079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>25.809568</td>\n",
       "      <td>5.080312</td>\n",
       "      <td>0.688868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>25.976757</td>\n",
       "      <td>5.096740</td>\n",
       "      <td>0.686853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>26.463041</td>\n",
       "      <td>5.144224</td>\n",
       "      <td>0.680991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>27.919729</td>\n",
       "      <td>5.283912</td>\n",
       "      <td>0.663431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>28.352768</td>\n",
       "      <td>5.324732</td>\n",
       "      <td>0.658210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>28.828549</td>\n",
       "      <td>5.369222</td>\n",
       "      <td>0.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>28.829366</td>\n",
       "      <td>5.369298</td>\n",
       "      <td>0.652465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>29.873277</td>\n",
       "      <td>5.465645</td>\n",
       "      <td>0.639881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>30.189862</td>\n",
       "      <td>5.494530</td>\n",
       "      <td>0.636064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>32.692611</td>\n",
       "      <td>5.717745</td>\n",
       "      <td>0.605894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>36.235223</td>\n",
       "      <td>6.019570</td>\n",
       "      <td>0.563188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>36.499022</td>\n",
       "      <td>6.041442</td>\n",
       "      <td>0.560008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>36.795195</td>\n",
       "      <td>6.065904</td>\n",
       "      <td>0.556438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>48.066155</td>\n",
       "      <td>6.932976</td>\n",
       "      <td>0.420567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>57.305965</td>\n",
       "      <td>7.570070</td>\n",
       "      <td>0.309182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>69.516023</td>\n",
       "      <td>8.337627</td>\n",
       "      <td>0.161992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>79.874474</td>\n",
       "      <td>8.937252</td>\n",
       "      <td>0.037121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size        MSE      RMSE        R2\n",
       "67  0.002    6000          25  14.581198  3.818534  0.824225\n",
       "68  0.002    6000          64  17.732855  4.211040  0.786232\n",
       "80  0.003    8000          64  19.043485  4.363884  0.770433\n",
       "63  0.002    4000           8  19.744770  4.443509  0.761979\n",
       "71  0.002    8000          64  20.711379  4.550976  0.750326\n",
       "79  0.003    8000          25  21.442516  4.630606  0.741513\n",
       "70  0.002    8000          25  23.320110  4.829090  0.718878\n",
       "56  0.001    4000          64  24.338104  4.933366  0.706607\n",
       "65  0.002    4000          64  25.285458  5.028465  0.695186\n",
       "78  0.003    8000           8  25.709159  5.070420  0.690079\n",
       "58  0.001    6000          25  25.809568  5.080312  0.688868\n",
       "77  0.003    6000          64  25.976757  5.096740  0.686853\n",
       "57  0.001    6000           8  26.463041  5.144224  0.680991\n",
       "61  0.001    8000          25  27.919729  5.283912  0.663431\n",
       "66  0.002    6000           8  28.352768  5.324732  0.658210\n",
       "75  0.003    6000           8  28.828549  5.369222  0.652475\n",
       "72  0.003    4000           8  28.829366  5.369298  0.652465\n",
       "69  0.002    8000           8  29.873277  5.465645  0.639881\n",
       "74  0.003    4000          64  30.189862  5.494530  0.636064\n",
       "60  0.001    8000           8  32.692611  5.717745  0.605894\n",
       "62  0.001    8000          64  36.235223  6.019570  0.563188\n",
       "59  0.001    6000          64  36.499022  6.041442  0.560008\n",
       "73  0.003    4000          25  36.795195  6.065904  0.556438\n",
       "54  0.001    4000           8  48.066155  6.932976  0.420567\n",
       "76  0.003    6000          25  57.305965  7.570070  0.309182\n",
       "55  0.001    4000          25  69.516023  8.337627  0.161992\n",
       "64  0.002    4000          25  79.874474  8.937252  0.037121"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Batch ReLU Metrics\")\n",
    "df_batch_relu = table[table['Activation'] == 2].drop('Activation',axis = 1)\n",
    "df_batch_relu = df_batch_relu.sort_values(by='R2', ascending=False)\n",
    "df_batch_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e72371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_042916-nczu228p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/nczu228p' target=\"_blank\">glad-bird-31</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/nczu228p' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/nczu228p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Training => MSE : 108.2059\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => MSE : 114.6147\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 10.7058\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => R2 score : -0.3817\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Training => MSE : 76.6624\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => MSE : 76.1439\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 8.7260\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.0821\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Training => MSE : 53.7286\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => MSE : 48.8311\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 6.9879\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => R2 score : 0.4113\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Training => MSE : 79.9635\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => MSE : 62.6822\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 7.9172\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => R2 score : 0.2444\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Training => MSE : 68.1790\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => MSE : 63.6930\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 7.9808\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.2322\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Training => MSE : 47.1491\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => MSE : 30.7512\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 5.5454\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => R2 score : 0.6293\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Training => MSE : 67.8261\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => MSE : 60.2745\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 7.7637\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => R2 score : 0.2734\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Training => MSE : 74.3262\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => MSE : 65.1812\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 8.0735\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.2142\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Training => MSE : 42.7276\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => MSE : 38.6666\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 6.2182\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => R2 score : 0.5339\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Training => MSE : 95.4580\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => MSE : 84.6067\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 9.1982\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => R2 score : -0.0199\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Training => MSE : 69.0722\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => MSE : 61.5104\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 7.8429\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.2585\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Training => MSE : 65.7663\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => MSE : 56.4953\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 7.5163\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.3190\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Training => MSE : 58.1371\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => MSE : 39.7913\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 6.3080\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.5203\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Training => MSE : 66.9484\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => MSE : 66.2142\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 8.1372\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.2018\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Training => MSE : 59.0105\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => MSE : 55.3356\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 7.4388\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.3329\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Training => MSE : 87.0939\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => MSE : 77.0914\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 8.7802\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.0707\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Training => MSE : 66.8788\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => MSE : 61.3360\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 7.8317\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.2606\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Training => MSE : 64.0428\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => MSE : 49.1257\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 7.0090\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.4078\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Training => MSE : 66.3750\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => MSE : 61.1444\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 7.8195\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.2629\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Training => MSE : 64.1371\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => MSE : 57.6051\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 7.5898\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.3056\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Training => MSE : 58.9518\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => MSE : 43.0559\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 6.5617\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.4810\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Training => MSE : 42.0606\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => MSE : 30.9370\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 5.5621\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.6271\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Training => MSE : 53.5645\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => MSE : 34.7822\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 5.8976\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.5807\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Training => MSE : 45.9005\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => MSE : 37.9976\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 6.1642\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.5419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Training => MSE : 84.8342\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => MSE : 85.7884\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 9.2622\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => R2 score : -0.0342\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Training => MSE : 54.5475\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => MSE : 51.4656\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 7.1740\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.3796\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Training => MSE : 49.6539\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => MSE : 45.0205\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 6.7097\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.4573\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>█▅▂▅▄▂▄▄▁▇▄▄▃▄▃▆▄▃▄▃▃▁▂▁▆▂▂</td></tr><tr><td>Validation MSE</td><td>█▅▃▄▄▁▃▄▂▅▄▃▂▄▃▅▄▃▄▃▂▁▁▂▆▃▂</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>49.65393</td></tr><tr><td>Validation MSE</td><td>45.02049</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-bird-31</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/nczu228p' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/nczu228p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_042916-nczu228p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_042940-t0f0kq0t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/t0f0kq0t' target=\"_blank\">dainty-moon-32</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/t0f0kq0t' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/t0f0kq0t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 100.9590\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 100.8371\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 10.0418\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : -0.2156\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 88.3322\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 75.7635\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 8.7042\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : 0.0867\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 109.6399\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 106.2258\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 10.3066\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : -0.2805\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 93.3927\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 86.2812\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 9.2888\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : -0.0401\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 50.1668\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 38.3512\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 6.1928\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : 0.5377\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 54.1628\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 42.5599\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 6.5238\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : 0.4869\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 88.3192\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 86.4565\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 9.2982\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : -0.0422\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 59.8605\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 48.2912\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 6.9492\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : 0.4179\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 78.7272\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 80.5443\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 8.9746\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : 0.0290\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 101.3587\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 101.2824\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 10.0639\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : -0.2209\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 90.8855\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 80.3512\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 8.9639\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.0314\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 41.8789\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 33.3584\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 5.7757\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.5979\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 82.0610\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 77.5369\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 8.8055\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : 0.0653\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 53.7705\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 45.2498\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 6.7268\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.4545\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 62.8461\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 41.4882\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 6.4411\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.4999\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 66.1329\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 59.0071\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 7.6816\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : 0.2887\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 52.9978\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 41.9473\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 6.4767\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.4943\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 56.3180\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 35.7498\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 5.9791\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.5690\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 85.0733\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 88.1166\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 9.3870\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : -0.0622\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 54.7391\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 49.6061\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 7.0432\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.4020\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 53.0832\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 34.0563\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 5.8358\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : 0.5895\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 73.0355\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 57.4288\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 7.5782\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.3077\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 45.7026\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 42.8323\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 6.5446\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.4837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 84.5844\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 85.3882\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 9.2406\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : -0.0293\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 58.4641\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 71.1373\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 8.4343\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.1424\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 55.0061\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 46.8388\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 6.8439\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.4354\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 40.2671\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 32.6496\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 5.7140\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : 0.6064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28ec8c8c24843368f90786c310cdce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>▇▆█▆▂▂▆▃▅▇▆▁▅▂▃▄▂▃▆▂▂▄▂▅▃▂▁</td></tr><tr><td>Validation MSE</td><td>▇▅█▆▂▂▆▂▆█▆▁▅▂▂▄▂▁▆▃▁▃▂▆▅▂▁</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>40.2671</td></tr><tr><td>Validation MSE</td><td>32.6496</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dainty-moon-32</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/t0f0kq0t' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/t0f0kq0t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_042940-t0f0kq0t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986951b2c39b472eb7f2edd83e06302b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01116806017752323, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_043002-9gbagx76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/9gbagx76' target=\"_blank\">scarlet-moon-33</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/9gbagx76' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/9gbagx76</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Training => MSE : 56.6523\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Validation => MSE : 44.2571\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Validation => RMSE : 6.6526\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Validation => R2 score : 0.4665\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Training => MSE : 54.3862\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Validation => MSE : 50.7540\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Validation => RMSE : 7.1242\n",
      "Epoch [4000], lr [0.001], activation [relu], size [25] Validation => R2 score : 0.3882\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Training => MSE : 95.8152\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Validation => MSE : 91.5873\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Validation => RMSE : 9.5701\n",
      "Epoch [4000], lr [0.001], activation [relu], size [64] Validation => R2 score : -0.1041\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Training => MSE : 54.7181\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Validation => MSE : 35.9453\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Validation => RMSE : 5.9954\n",
      "Epoch [6000], lr [0.001], activation [relu], size [8] Validation => R2 score : 0.5667\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Training => MSE : 76.7831\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Validation => MSE : 73.6620\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Validation => RMSE : 8.5827\n",
      "Epoch [6000], lr [0.001], activation [relu], size [25] Validation => R2 score : 0.1120\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Training => MSE : 28.2790\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Validation => MSE : 25.3222\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Validation => RMSE : 5.0321\n",
      "Epoch [6000], lr [0.001], activation [relu], size [64] Validation => R2 score : 0.6947\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Training => MSE : 24.3465\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Validation => MSE : 14.5384\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Validation => RMSE : 3.8129\n",
      "Epoch [8000], lr [0.001], activation [relu], size [8] Validation => R2 score : 0.8247\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Training => MSE : 48.1688\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Validation => MSE : 28.0880\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Validation => RMSE : 5.2998\n",
      "Epoch [8000], lr [0.001], activation [relu], size [25] Validation => R2 score : 0.6614\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Training => MSE : 63.7630\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Validation => MSE : 36.7565\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Validation => RMSE : 6.0627\n",
      "Epoch [8000], lr [0.001], activation [relu], size [64] Validation => R2 score : 0.5569\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Training => MSE : 49.4110\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Validation => MSE : 31.8941\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Validation => RMSE : 5.6475\n",
      "Epoch [4000], lr [0.002], activation [relu], size [8] Validation => R2 score : 0.6155\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Training => MSE : 50.3292\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Validation => MSE : 43.9093\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Validation => RMSE : 6.6264\n",
      "Epoch [4000], lr [0.002], activation [relu], size [25] Validation => R2 score : 0.4707\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Training => MSE : 43.6752\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Validation => MSE : 25.2604\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Validation => RMSE : 5.0260\n",
      "Epoch [4000], lr [0.002], activation [relu], size [64] Validation => R2 score : 0.6955\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Training => MSE : 60.7749\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Validation => MSE : 56.5389\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Validation => RMSE : 7.5192\n",
      "Epoch [6000], lr [0.002], activation [relu], size [8] Validation => R2 score : 0.3184\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Training => MSE : 37.7215\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Validation => MSE : 29.9083\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Validation => RMSE : 5.4688\n",
      "Epoch [6000], lr [0.002], activation [relu], size [25] Validation => R2 score : 0.6395\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Training => MSE : 34.8237\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Validation => MSE : 23.7860\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Validation => RMSE : 4.8771\n",
      "Epoch [6000], lr [0.002], activation [relu], size [64] Validation => R2 score : 0.7133\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Training => MSE : 54.5014\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Validation => MSE : 42.9073\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Validation => RMSE : 6.5504\n",
      "Epoch [8000], lr [0.002], activation [relu], size [8] Validation => R2 score : 0.4828\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Training => MSE : 43.2533\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Validation => MSE : 25.5045\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Validation => RMSE : 5.0502\n",
      "Epoch [8000], lr [0.002], activation [relu], size [25] Validation => R2 score : 0.6925\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Training => MSE : 47.2450\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Validation => MSE : 29.7666\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Validation => RMSE : 5.4559\n",
      "Epoch [8000], lr [0.002], activation [relu], size [64] Validation => R2 score : 0.6412\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Training => MSE : 39.9343\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Validation => MSE : 34.7705\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Validation => RMSE : 5.8967\n",
      "Epoch [4000], lr [0.003], activation [relu], size [8] Validation => R2 score : 0.5808\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Training => MSE : 39.1606\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Validation => MSE : 21.6213\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Validation => RMSE : 4.6499\n",
      "Epoch [4000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.7394\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Training => MSE : 45.3686\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Validation => MSE : 33.5222\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Validation => RMSE : 5.7898\n",
      "Epoch [4000], lr [0.003], activation [relu], size [64] Validation => R2 score : 0.5959\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Training => MSE : 51.0085\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Validation => MSE : 39.1026\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Validation => RMSE : 6.2532\n",
      "Epoch [6000], lr [0.003], activation [relu], size [8] Validation => R2 score : 0.5286\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Training => MSE : 24.9013\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Validation => MSE : 15.8829\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Validation => RMSE : 3.9853\n",
      "Epoch [6000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.8085\n",
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Training => MSE : 64.6741\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Validation => MSE : 46.4451\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Validation => RMSE : 6.8151\n",
      "Epoch [6000], lr [0.003], activation [relu], size [64] Validation => R2 score : 0.4401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Training => MSE : 37.9988\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Validation => MSE : 31.1140\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Validation => RMSE : 5.5780\n",
      "Epoch [8000], lr [0.003], activation [relu], size [8] Validation => R2 score : 0.6249\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Training => MSE : 44.3221\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => MSE : 33.7956\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => RMSE : 5.8134\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.5926\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Training => MSE : 28.5089\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Validation => MSE : 20.4732\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Validation => RMSE : 4.5247\n",
      "Epoch [8000], lr [0.003], activation [relu], size [64] Validation => R2 score : 0.7532\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>▄▄█▄▆▁▁▃▅▃▄▃▅▂▂▄▃▃▃▂▃▄▁▅▂▃▁</td></tr><tr><td>Validation MSE</td><td>▄▄█▃▆▂▁▂▃▃▄▂▅▂▂▄▂▂▃▂▃▃▁▄▃▃▂</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>28.50888</td></tr><tr><td>Validation MSE</td><td>20.47324</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-moon-33</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/9gbagx76' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/9gbagx76</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_043002-9gbagx76/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [4000,6000,8000]\n",
    "layer_sizes = [[8],[25],[64]]\n",
    "activations =  [[tanh],[sigmoid],[relu]]\n",
    "activation_names = ['tanh','sigmoid','relu']\n",
    "\n",
    "table = []\n",
    "lrs = [0.001,0.002,0.003]\n",
    "\n",
    "#  minibatch\n",
    "for idx,activation in enumerate(activations):\n",
    "    wandb.init(project = \"Multilayer Regression Perceptron\")\n",
    "    for lr in lrs:\n",
    "        for epoch in epochs:\n",
    "            for size in layer_sizes:\n",
    "                regressor = MLP(input_size,output_size,num_layers,size,activation,'minibatch',lr)\n",
    "                size = size[0]\n",
    "        #       Training\n",
    "                regressor.training(x_training,y_train,epoch)\n",
    "        #       Training metrics\n",
    "                out = regressor.forward(x_training)\n",
    "                mse_train = mse(y_train,out)\n",
    "                print(\"TRAINING\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Training => MSE : {mse_train:.4f}\")\n",
    "\n",
    "        #       Validation\n",
    "                out = regressor.forward(x_validation)\n",
    "                mse_val = mean_squared_error(y_val, out)\n",
    "                rmse_val = mean_squared_error(y_val, out, squared=False)\n",
    "                r2_val = r2_score(y_val, out)\n",
    "                print(\"VALIDATION\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => MSE : {mse_val:.4f}\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => RMSE : {rmse_val:.4f}\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => R2 score : {r2_val:.4f}\")\n",
    "\n",
    "                wandb.log({\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"epochs\": epoch,\n",
    "                    \"layer_size\": size,\n",
    "                    \"Validation MSE\": mse_val,\n",
    "                    \"Training MSE\": mse_train,\n",
    "                })\n",
    "                entry = [lr,epoch,idx,size,mse_val,rmse_val,r2_val]\n",
    "                table.append(entry)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceaaa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_minibatch = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30eca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Activation</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>114.614665</td>\n",
       "      <td>10.705824</td>\n",
       "      <td>-0.381668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>76.143859</td>\n",
       "      <td>8.726045</td>\n",
       "      <td>0.082094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>48.831065</td>\n",
       "      <td>6.987923</td>\n",
       "      <td>0.411347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>62.682193</td>\n",
       "      <td>7.917209</td>\n",
       "      <td>0.244373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>63.692995</td>\n",
       "      <td>7.980789</td>\n",
       "      <td>0.232188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>15.882950</td>\n",
       "      <td>3.985342</td>\n",
       "      <td>0.808533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>46.445119</td>\n",
       "      <td>6.815066</td>\n",
       "      <td>0.440109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>31.114032</td>\n",
       "      <td>5.577995</td>\n",
       "      <td>0.624924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>33.795624</td>\n",
       "      <td>5.813400</td>\n",
       "      <td>0.592597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>20.473239</td>\n",
       "      <td>4.524736</td>\n",
       "      <td>0.753197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  Activation  layer size         MSE       RMSE        R2\n",
       "0   0.001    4000           0           8  114.614665  10.705824 -0.381668\n",
       "1   0.001    4000           0          25   76.143859   8.726045  0.082094\n",
       "2   0.001    4000           0          64   48.831065   6.987923  0.411347\n",
       "3   0.001    6000           0           8   62.682193   7.917209  0.244373\n",
       "4   0.001    6000           0          25   63.692995   7.980789  0.232188\n",
       "..    ...     ...         ...         ...         ...        ...       ...\n",
       "76  0.003    6000           2          25   15.882950   3.985342  0.808533\n",
       "77  0.003    6000           2          64   46.445119   6.815066  0.440109\n",
       "78  0.003    8000           2           8   31.114032   5.577995  0.624924\n",
       "79  0.003    8000           2          25   33.795624   5.813400  0.592597\n",
       "80  0.003    8000           2          64   20.473239   4.524736  0.753197\n",
       "\n",
       "[81 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(table_minibatch,columns = ['LR','Epochs','Activation','layer size','MSE','RMSE','R2'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872024e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miniBatch ReLU Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>14.538418</td>\n",
       "      <td>3.812928</td>\n",
       "      <td>0.824741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>15.882950</td>\n",
       "      <td>3.985342</td>\n",
       "      <td>0.808533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>20.473239</td>\n",
       "      <td>4.524736</td>\n",
       "      <td>0.753197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>21.621275</td>\n",
       "      <td>4.649868</td>\n",
       "      <td>0.739358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>23.786021</td>\n",
       "      <td>4.877091</td>\n",
       "      <td>0.713262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>25.260437</td>\n",
       "      <td>5.025976</td>\n",
       "      <td>0.695488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>25.322234</td>\n",
       "      <td>5.032120</td>\n",
       "      <td>0.694743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>25.504503</td>\n",
       "      <td>5.050198</td>\n",
       "      <td>0.692546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>28.088019</td>\n",
       "      <td>5.299813</td>\n",
       "      <td>0.661402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>29.766591</td>\n",
       "      <td>5.455877</td>\n",
       "      <td>0.641167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>29.908320</td>\n",
       "      <td>5.468850</td>\n",
       "      <td>0.639458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>31.114032</td>\n",
       "      <td>5.577995</td>\n",
       "      <td>0.624924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>31.894091</td>\n",
       "      <td>5.647485</td>\n",
       "      <td>0.615520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>33.522158</td>\n",
       "      <td>5.789832</td>\n",
       "      <td>0.595894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>33.795624</td>\n",
       "      <td>5.813400</td>\n",
       "      <td>0.592597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>34.770498</td>\n",
       "      <td>5.896651</td>\n",
       "      <td>0.580845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>35.945292</td>\n",
       "      <td>5.995439</td>\n",
       "      <td>0.566683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>36.756456</td>\n",
       "      <td>6.062710</td>\n",
       "      <td>0.556905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>39.102646</td>\n",
       "      <td>6.253211</td>\n",
       "      <td>0.528622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>42.907256</td>\n",
       "      <td>6.550363</td>\n",
       "      <td>0.482757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>43.909292</td>\n",
       "      <td>6.626409</td>\n",
       "      <td>0.470678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>44.257145</td>\n",
       "      <td>6.652604</td>\n",
       "      <td>0.466485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>46.445119</td>\n",
       "      <td>6.815066</td>\n",
       "      <td>0.440109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>50.754001</td>\n",
       "      <td>7.124184</td>\n",
       "      <td>0.388166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>56.538912</td>\n",
       "      <td>7.519236</td>\n",
       "      <td>0.318429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>73.661971</td>\n",
       "      <td>8.582655</td>\n",
       "      <td>0.112013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>91.587270</td>\n",
       "      <td>9.570124</td>\n",
       "      <td>-0.104075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size        MSE      RMSE        R2\n",
       "60  0.001    8000           8  14.538418  3.812928  0.824741\n",
       "76  0.003    6000          25  15.882950  3.985342  0.808533\n",
       "80  0.003    8000          64  20.473239  4.524736  0.753197\n",
       "73  0.003    4000          25  21.621275  4.649868  0.739358\n",
       "68  0.002    6000          64  23.786021  4.877091  0.713262\n",
       "65  0.002    4000          64  25.260437  5.025976  0.695488\n",
       "59  0.001    6000          64  25.322234  5.032120  0.694743\n",
       "70  0.002    8000          25  25.504503  5.050198  0.692546\n",
       "61  0.001    8000          25  28.088019  5.299813  0.661402\n",
       "71  0.002    8000          64  29.766591  5.455877  0.641167\n",
       "67  0.002    6000          25  29.908320  5.468850  0.639458\n",
       "78  0.003    8000           8  31.114032  5.577995  0.624924\n",
       "63  0.002    4000           8  31.894091  5.647485  0.615520\n",
       "74  0.003    4000          64  33.522158  5.789832  0.595894\n",
       "79  0.003    8000          25  33.795624  5.813400  0.592597\n",
       "72  0.003    4000           8  34.770498  5.896651  0.580845\n",
       "57  0.001    6000           8  35.945292  5.995439  0.566683\n",
       "62  0.001    8000          64  36.756456  6.062710  0.556905\n",
       "75  0.003    6000           8  39.102646  6.253211  0.528622\n",
       "69  0.002    8000           8  42.907256  6.550363  0.482757\n",
       "64  0.002    4000          25  43.909292  6.626409  0.470678\n",
       "54  0.001    4000           8  44.257145  6.652604  0.466485\n",
       "77  0.003    6000          64  46.445119  6.815066  0.440109\n",
       "55  0.001    4000          25  50.754001  7.124184  0.388166\n",
       "66  0.002    6000           8  56.538912  7.519236  0.318429\n",
       "58  0.001    6000          25  73.661971  8.582655  0.112013\n",
       "56  0.001    4000          64  91.587270  9.570124 -0.104075"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"miniBatch ReLU Metrics\")\n",
    "df_minibatch_relu = table[table['Activation'] == 2].drop('Activation',axis = 1)\n",
    "df_minibatch_relu = df_minibatch_relu.sort_values(by='R2', ascending=False)\n",
    "df_minibatch_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d53aeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatch tanh Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>30.751160</td>\n",
       "      <td>5.545373</td>\n",
       "      <td>0.629298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>30.936983</td>\n",
       "      <td>5.562102</td>\n",
       "      <td>0.627058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>34.782239</td>\n",
       "      <td>5.897647</td>\n",
       "      <td>0.580704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>37.997556</td>\n",
       "      <td>6.164216</td>\n",
       "      <td>0.541943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>38.666604</td>\n",
       "      <td>6.218248</td>\n",
       "      <td>0.533878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>39.791286</td>\n",
       "      <td>6.308033</td>\n",
       "      <td>0.520320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>43.055877</td>\n",
       "      <td>6.561698</td>\n",
       "      <td>0.480966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>45.020491</td>\n",
       "      <td>6.709731</td>\n",
       "      <td>0.457283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>48.831065</td>\n",
       "      <td>6.987923</td>\n",
       "      <td>0.411347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>49.125667</td>\n",
       "      <td>7.008970</td>\n",
       "      <td>0.407795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>51.465569</td>\n",
       "      <td>7.173951</td>\n",
       "      <td>0.379588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>55.335606</td>\n",
       "      <td>7.438791</td>\n",
       "      <td>0.332935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>56.495329</td>\n",
       "      <td>7.516337</td>\n",
       "      <td>0.318955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>57.605054</td>\n",
       "      <td>7.589799</td>\n",
       "      <td>0.305577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>60.274529</td>\n",
       "      <td>7.763667</td>\n",
       "      <td>0.273397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>61.144403</td>\n",
       "      <td>7.819489</td>\n",
       "      <td>0.262911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>61.336014</td>\n",
       "      <td>7.831731</td>\n",
       "      <td>0.260601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>61.510393</td>\n",
       "      <td>7.842856</td>\n",
       "      <td>0.258499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>62.682193</td>\n",
       "      <td>7.917209</td>\n",
       "      <td>0.244373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>63.692995</td>\n",
       "      <td>7.980789</td>\n",
       "      <td>0.232188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>65.181213</td>\n",
       "      <td>8.073488</td>\n",
       "      <td>0.214247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>66.214202</td>\n",
       "      <td>8.137211</td>\n",
       "      <td>0.201795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>76.143859</td>\n",
       "      <td>8.726045</td>\n",
       "      <td>0.082094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>77.091436</td>\n",
       "      <td>8.780173</td>\n",
       "      <td>0.070671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>84.606711</td>\n",
       "      <td>9.198191</td>\n",
       "      <td>-0.019925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>85.788382</td>\n",
       "      <td>9.262202</td>\n",
       "      <td>-0.034170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>114.614665</td>\n",
       "      <td>10.705824</td>\n",
       "      <td>-0.381668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size         MSE       RMSE        R2\n",
       "5   0.001    6000          64   30.751160   5.545373  0.629298\n",
       "21  0.003    6000           8   30.936983   5.562102  0.627058\n",
       "22  0.003    6000          25   34.782239   5.897647  0.580704\n",
       "23  0.003    6000          64   37.997556   6.164216  0.541943\n",
       "8   0.001    8000          64   38.666604   6.218248  0.533878\n",
       "12  0.002    6000           8   39.791286   6.308033  0.520320\n",
       "20  0.003    4000          64   43.055877   6.561698  0.480966\n",
       "26  0.003    8000          64   45.020491   6.709731  0.457283\n",
       "2   0.001    4000          64   48.831065   6.987923  0.411347\n",
       "17  0.002    8000          64   49.125667   7.008970  0.407795\n",
       "25  0.003    8000          25   51.465569   7.173951  0.379588\n",
       "14  0.002    6000          64   55.335606   7.438791  0.332935\n",
       "11  0.002    4000          64   56.495329   7.516337  0.318955\n",
       "19  0.003    4000          25   57.605054   7.589799  0.305577\n",
       "6   0.001    8000           8   60.274529   7.763667  0.273397\n",
       "18  0.003    4000           8   61.144403   7.819489  0.262911\n",
       "16  0.002    8000          25   61.336014   7.831731  0.260601\n",
       "10  0.002    4000          25   61.510393   7.842856  0.258499\n",
       "3   0.001    6000           8   62.682193   7.917209  0.244373\n",
       "4   0.001    6000          25   63.692995   7.980789  0.232188\n",
       "7   0.001    8000          25   65.181213   8.073488  0.214247\n",
       "13  0.002    6000          25   66.214202   8.137211  0.201795\n",
       "1   0.001    4000          25   76.143859   8.726045  0.082094\n",
       "15  0.002    8000           8   77.091436   8.780173  0.070671\n",
       "9   0.002    4000           8   84.606711   9.198191 -0.019925\n",
       "24  0.003    8000           8   85.788382   9.262202 -0.034170\n",
       "0   0.001    4000           8  114.614665  10.705824 -0.381668"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MiniBatch tanh Metrics\")\n",
    "df_minibatch_tanh = table[table['Activation'] == 0].drop('Activation',axis = 1)\n",
    "df_minibatch_tanh = df_minibatch_tanh.sort_values(by='R2', ascending=False)\n",
    "df_minibatch_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00f567c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatch Sigmoid Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>32.649604</td>\n",
       "      <td>5.713983</td>\n",
       "      <td>0.606412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>33.358381</td>\n",
       "      <td>5.775671</td>\n",
       "      <td>0.597868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>34.056296</td>\n",
       "      <td>5.835777</td>\n",
       "      <td>0.589455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>35.749799</td>\n",
       "      <td>5.979114</td>\n",
       "      <td>0.569040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>38.351227</td>\n",
       "      <td>6.192837</td>\n",
       "      <td>0.537680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>41.488192</td>\n",
       "      <td>6.441133</td>\n",
       "      <td>0.499864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>41.947328</td>\n",
       "      <td>6.476676</td>\n",
       "      <td>0.494329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>42.559938</td>\n",
       "      <td>6.523798</td>\n",
       "      <td>0.486944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>42.832264</td>\n",
       "      <td>6.544636</td>\n",
       "      <td>0.483661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>45.249849</td>\n",
       "      <td>6.726801</td>\n",
       "      <td>0.454518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>46.838833</td>\n",
       "      <td>6.843890</td>\n",
       "      <td>0.435363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>48.291183</td>\n",
       "      <td>6.949186</td>\n",
       "      <td>0.417855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>49.606089</td>\n",
       "      <td>7.043159</td>\n",
       "      <td>0.402004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>57.428792</td>\n",
       "      <td>7.578179</td>\n",
       "      <td>0.307702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>59.007111</td>\n",
       "      <td>7.681609</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>71.137346</td>\n",
       "      <td>8.434296</td>\n",
       "      <td>0.142447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>75.763542</td>\n",
       "      <td>8.704226</td>\n",
       "      <td>0.086678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>77.536928</td>\n",
       "      <td>8.805506</td>\n",
       "      <td>0.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>80.351230</td>\n",
       "      <td>8.963885</td>\n",
       "      <td>0.031374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>80.544337</td>\n",
       "      <td>8.974650</td>\n",
       "      <td>0.029046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>85.388219</td>\n",
       "      <td>9.240575</td>\n",
       "      <td>-0.029346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>86.281220</td>\n",
       "      <td>9.288768</td>\n",
       "      <td>-0.040111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>86.456458</td>\n",
       "      <td>9.298196</td>\n",
       "      <td>-0.042224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>88.116620</td>\n",
       "      <td>9.387045</td>\n",
       "      <td>-0.062237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>100.837086</td>\n",
       "      <td>10.041767</td>\n",
       "      <td>-0.215581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>101.282450</td>\n",
       "      <td>10.063918</td>\n",
       "      <td>-0.220949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>106.225814</td>\n",
       "      <td>10.306591</td>\n",
       "      <td>-0.280541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size         MSE       RMSE        R2\n",
       "53  0.003    8000          64   32.649604   5.713983  0.606412\n",
       "38  0.002    4000          64   33.358381   5.775671  0.597868\n",
       "47  0.003    4000          64   34.056296   5.835777  0.589455\n",
       "44  0.002    8000          64   35.749799   5.979114  0.569040\n",
       "31  0.001    6000          25   38.351227   6.192837  0.537680\n",
       "41  0.002    6000          64   41.488192   6.441133  0.499864\n",
       "43  0.002    8000          25   41.947328   6.476676  0.494329\n",
       "32  0.001    6000          64   42.559938   6.523798  0.486944\n",
       "49  0.003    6000          25   42.832264   6.544636  0.483661\n",
       "40  0.002    6000          25   45.249849   6.726801  0.454518\n",
       "52  0.003    8000          25   46.838833   6.843890  0.435363\n",
       "34  0.001    8000          25   48.291183   6.949186  0.417855\n",
       "46  0.003    4000          25   49.606089   7.043159  0.402004\n",
       "48  0.003    6000           8   57.428792   7.578179  0.307702\n",
       "42  0.002    8000           8   59.007111   7.681609  0.288675\n",
       "51  0.003    8000           8   71.137346   8.434296  0.142447\n",
       "28  0.001    4000          25   75.763542   8.704226  0.086678\n",
       "39  0.002    6000           8   77.536928   8.805506  0.065300\n",
       "37  0.002    4000          25   80.351230   8.963885  0.031374\n",
       "35  0.001    8000          64   80.544337   8.974650  0.029046\n",
       "50  0.003    6000          64   85.388219   9.240575 -0.029346\n",
       "30  0.001    6000           8   86.281220   9.288768 -0.040111\n",
       "33  0.001    8000           8   86.456458   9.298196 -0.042224\n",
       "45  0.003    4000           8   88.116620   9.387045 -0.062237\n",
       "27  0.001    4000           8  100.837086  10.041767 -0.215581\n",
       "36  0.002    4000           8  101.282450  10.063918 -0.220949\n",
       "29  0.001    4000          64  106.225814  10.306591 -0.280541"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MiniBatch Sigmoid Metrics\")\n",
    "df_minibatch_sigmoid = table[table['Activation'] == 1].drop('Activation',axis = 1)\n",
    "df_minibatch_sigmoid = df_minibatch_sigmoid.sort_values(by='R2', ascending=False)\n",
    "df_minibatch_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abd95834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_044335-4a634fdu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/4a634fdu' target=\"_blank\">gallant-star-34</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/4a634fdu' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/4a634fdu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Training => MSE : 72.7614\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => MSE : 49.3259\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 7.0232\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [8] Validation => R2 score : 0.4054\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Training => MSE : 91.5097\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => MSE : 103.1017\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 10.1539\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [25] Validation => R2 score : -0.2429\n",
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Training => MSE : 82.7127\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => MSE : 85.3875\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 9.2405\n",
      "Epoch [4000], lr [0.001], activation [tanh], size [64] Validation => R2 score : -0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Training => MSE : 54.4297\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => MSE : 50.3490\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 7.0957\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [8] Validation => R2 score : 0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Training => MSE : 64.8484\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => MSE : 59.5903\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 7.7195\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Training => MSE : 70.3014\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => MSE : 65.1209\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 8.0698\n",
      "Epoch [6000], lr [0.001], activation [tanh], size [64] Validation => R2 score : 0.2150\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Training => MSE : 85.7932\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => MSE : 83.6950\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => RMSE : 9.1485\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [8] Validation => R2 score : -0.0089\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Training => MSE : 66.1992\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => MSE : 59.9467\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => RMSE : 7.7425\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [25] Validation => R2 score : 0.2773\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Training => MSE : 54.3091\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => MSE : 52.7377\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => RMSE : 7.2621\n",
      "Epoch [8000], lr [0.001], activation [tanh], size [64] Validation => R2 score : 0.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Training => MSE : 77.8413\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => MSE : 71.0085\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 8.4267\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Training => MSE : 69.5810\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => MSE : 52.9426\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 7.2762\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Training => MSE : 70.3536\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => MSE : 57.4037\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 7.5765\n",
      "Epoch [4000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Training => MSE : 63.0050\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => MSE : 55.8488\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 7.4732\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.3267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Training => MSE : 66.2525\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => MSE : 56.7593\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 7.5339\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.3158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Training => MSE : 58.1557\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => MSE : 53.9230\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 7.3432\n",
      "Epoch [6000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Training => MSE : 79.5713\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => MSE : 70.2873\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => RMSE : 8.3837\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [8] Validation => R2 score : 0.1527\n",
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Training => MSE : 81.8924\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => MSE : 78.0110\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => RMSE : 8.8324\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [25] Validation => R2 score : 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Training => MSE : 78.9576\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => MSE : 74.6062\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => RMSE : 8.6375\n",
      "Epoch [8000], lr [0.002], activation [tanh], size [64] Validation => R2 score : 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Training => MSE : 61.2904\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => MSE : 57.9802\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 7.6145\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Training => MSE : 72.2839\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => MSE : 65.0247\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 8.0638\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Training => MSE : 111.2568\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => MSE : 91.8784\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 9.5853\n",
      "Epoch [4000], lr [0.003], activation [tanh], size [64] Validation => R2 score : -0.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Training => MSE : 77.9380\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => MSE : 65.5542\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 8.0966\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Training => MSE : 68.6231\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => MSE : 57.5881\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 7.5887\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.3058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Training => MSE : 68.1864\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => MSE : 62.8273\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 7.9264\n",
      "Epoch [6000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.2426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Training => MSE : 67.1780\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => MSE : 55.6723\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => RMSE : 7.4614\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [8] Validation => R2 score : 0.3289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Training => MSE : 64.5443\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => MSE : 55.1383\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => RMSE : 7.4255\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [25] Validation => R2 score : 0.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * y)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Training => MSE : 53.5870\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => MSE : 48.7607\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => RMSE : 6.9829\n",
      "Epoch [8000], lr [0.003], activation [tanh], size [64] Validation => R2 score : 0.4122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad79b48837de46f9aa4709dac59d1137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>▃▆▅▁▂▃▅▃▁▄▃▃▂▃▂▄▄▄▂▃█▄▃▃▃▂▁</td></tr><tr><td>Validation MSE</td><td>▁█▆▁▂▃▆▂▂▄▂▂▂▂▂▄▅▄▂▃▇▃▂▃▂▂▁</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>53.58696</td></tr><tr><td>Validation MSE</td><td>48.76073</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-star-34</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/4a634fdu' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/4a634fdu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_044335-4a634fdu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_051047-rsgks06i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/rsgks06i' target=\"_blank\">laced-aardvark-35</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/rsgks06i' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/rsgks06i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 74.4689\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 63.7888\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 7.9868\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : 0.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 58.7965\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 53.4427\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 7.3104\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : 0.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 64.8285\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 56.7670\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 7.5344\n",
      "Epoch [4000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : 0.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 50.9096\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 44.3352\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 6.6585\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : 0.4655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 62.8144\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 55.4612\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 7.4472\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : 0.3314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 92.0632\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 82.2557\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 9.0695\n",
      "Epoch [6000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Training => MSE : 58.1505\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => MSE : 49.7422\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => RMSE : 7.0528\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [8] Validation => R2 score : 0.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Training => MSE : 57.9634\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => MSE : 54.6234\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => RMSE : 7.3908\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [25] Validation => R2 score : 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Training => MSE : 68.6838\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => MSE : 58.6680\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => RMSE : 7.6595\n",
      "Epoch [8000], lr [0.001], activation [sigmoid], size [64] Validation => R2 score : 0.2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 73.6526\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 62.3244\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 7.8946\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : 0.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 65.7596\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 56.8799\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 7.5419\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 65.6154\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 59.4375\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 7.7096\n",
      "Epoch [4000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 75.8664\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 59.8034\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 7.7333\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : 0.2791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 69.3238\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 60.1565\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 7.7561\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 66.6132\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 63.5916\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 7.9744\n",
      "Epoch [6000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Training => MSE : 69.2973\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => MSE : 63.5109\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => RMSE : 7.9694\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [8] Validation => R2 score : 0.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Training => MSE : 66.6844\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => MSE : 63.5509\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => RMSE : 7.9719\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [25] Validation => R2 score : 0.2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Training => MSE : 61.1348\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => MSE : 53.7911\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => RMSE : 7.3342\n",
      "Epoch [8000], lr [0.002], activation [sigmoid], size [64] Validation => R2 score : 0.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 71.2432\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 58.4000\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 7.6420\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 72.4950\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 60.8795\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 7.8025\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.2661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 112.4938\n",
      "VALIDATION\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 130.4418\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 11.4211\n",
      "Epoch [4000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : -0.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 76.1540\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 61.9012\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 7.8677\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 60.6841\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 54.9392\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 7.4121\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.3377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 74.7648\n",
      "VALIDATION\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 55.8322\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 7.4721\n",
      "Epoch [6000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : 0.3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Training => MSE : 69.3430\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => MSE : 63.2328\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => RMSE : 7.9519\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [8] Validation => R2 score : 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Training => MSE : 67.8015\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => MSE : 56.0400\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => RMSE : 7.4860\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [25] Validation => R2 score : 0.3244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Training => MSE : 86.1753\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => MSE : 82.1335\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => RMSE : 9.0628\n",
      "Epoch [8000], lr [0.003], activation [sigmoid], size [64] Validation => R2 score : 0.0099\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd85090a2cdc4612af3ad1ee9aaa8a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>▄▂▃▁▂▆▂▂▃▄▃▃▄▃▃▃▃▂▃▃█▄▂▄▃▃▅</td></tr><tr><td>Validation MSE</td><td>▃▂▂▁▂▄▁▂▂▂▂▂▂▂▃▃▃▂▂▂█▂▂▂▃▂▄</td></tr><tr><td>epochs</td><td>▁▁▁▅▅▅███▁▁▁▅▅▅███▁▁▁▅▅▅███</td></tr><tr><td>layer_size</td><td>▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█▁▃█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training MSE</td><td>86.17529</td></tr><tr><td>Validation MSE</td><td>82.13354</td></tr><tr><td>epochs</td><td>8000</td></tr><tr><td>layer_size</td><td>64</td></tr><tr><td>learning_rate</td><td>0.003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-aardvark-35</strong> at: <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/rsgks06i' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/rsgks06i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231022_051047-rsgks06i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhythmaggarwal/Desktop/ML/SMAI_ASSIGNMENT/A3/wandb/run-20231022_053714-s5fqyhkv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/s5fqyhkv' target=\"_blank\">resilient-field-36</a></strong> to <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/s5fqyhkv' target=\"_blank\">https://wandb.ai/smai-khushi/Multilayer%20Regression%20Perceptron/runs/s5fqyhkv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:59: RuntimeWarning: overflow encountered in matmul\n",
      "  z = inp @ self.w_and_b[self.num_layers].T\n",
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:67: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad_w_and_b = grad_y_out.T @ self.layer_inputs[-1]\n",
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:75: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad_z = grad_y*self.relu_grad(self.layer_outputs[layer])\n",
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:53: RuntimeWarning: invalid value encountered in matmul\n",
      "  z = inp @ self.w_and_b[layer].T\n",
      "/var/folders/mv/v9mn77wx1qlfmtfw3d4vz3k80000gn/T/ipykernel_84878/3723145163.py:59: RuntimeWarning: invalid value encountered in matmul\n",
      "  z = inp @ self.w_and_b[self.num_layers].T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [4000], lr [0.001], activation [relu], size [8] Training => MSE : nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#       Validation\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         out \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mforward(x_validation)\n\u001b[0;32m---> 27\u001b[0m         mse_val \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         rmse_val \u001b[38;5;241m=\u001b[39m mean_squared_error(y_val, out, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m         r2_val \u001b[38;5;241m=\u001b[39m r2_score(y_val, out)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    405\u001b[0m     {\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    478\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    100\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    104\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "epochs = [4000,6000,8000]\n",
    "layer_sizes = [[8],[25],[64]]\n",
    "activations =  [[tanh],[sigmoid],[relu]]\n",
    "activation_names = ['tanh','sigmoid','relu']\n",
    "\n",
    "table = []\n",
    "lrs = [0.001,0.002,0.003]\n",
    "\n",
    "#  sgd\n",
    "for idx,activation in enumerate(activations):\n",
    "    wandb.init(project = \"Multilayer Regression Perceptron\")\n",
    "    for lr in lrs:\n",
    "        for epoch in epochs:\n",
    "            for size in layer_sizes:\n",
    "                regressor = MLP(input_size,output_size,num_layers,size,activation,'sgd',lr)\n",
    "                size = size[0]\n",
    "        #       Training\n",
    "                regressor.training(x_training,y_train,epoch)\n",
    "        #       Training metrics\n",
    "                out = regressor.forward(x_training)\n",
    "                mse_train = mse(y_train,out)\n",
    "                print(\"TRAINING\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Training => MSE : {mse_train:.4f}\")\n",
    "\n",
    "        #       Validation\n",
    "                out = regressor.forward(x_validation)\n",
    "                mse_val = mean_squared_error(y_val, out)\n",
    "                rmse_val = mean_squared_error(y_val, out, squared=False)\n",
    "                r2_val = r2_score(y_val, out)\n",
    "                print(\"VALIDATION\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => MSE : {mse_val:.4f}\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => RMSE : {rmse_val:.4f}\")\n",
    "                print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => R2 score : {r2_val:.4f}\")\n",
    "\n",
    "                wandb.log({\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"epochs\": epoch,\n",
    "                    \"layer_size\": size,\n",
    "                    \"Validation MSE\": mse_val,\n",
    "                    \"Training MSE\": mse_train,\n",
    "                })\n",
    "                entry = [lr,epoch,idx,size,mse_val,rmse_val,r2_val]\n",
    "                table.append(entry)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80298042",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sgd = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac30d5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Activation</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>49.325946</td>\n",
       "      <td>7.023243</td>\n",
       "      <td>0.405381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>103.101655</td>\n",
       "      <td>10.153899</td>\n",
       "      <td>-0.242880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>85.387466</td>\n",
       "      <td>9.240534</td>\n",
       "      <td>-0.029337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>50.349019</td>\n",
       "      <td>7.095704</td>\n",
       "      <td>0.393048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59.590267</td>\n",
       "      <td>7.719473</td>\n",
       "      <td>0.281645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>65.120898</td>\n",
       "      <td>8.069752</td>\n",
       "      <td>0.214974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>83.694952</td>\n",
       "      <td>9.148495</td>\n",
       "      <td>-0.008934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>59.946684</td>\n",
       "      <td>7.742524</td>\n",
       "      <td>0.277349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>52.737748</td>\n",
       "      <td>7.262076</td>\n",
       "      <td>0.364252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>71.008493</td>\n",
       "      <td>8.426654</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>52.942552</td>\n",
       "      <td>7.276163</td>\n",
       "      <td>0.361783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>57.403712</td>\n",
       "      <td>7.576524</td>\n",
       "      <td>0.308004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>55.848812</td>\n",
       "      <td>7.473206</td>\n",
       "      <td>0.326748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>56.759333</td>\n",
       "      <td>7.533879</td>\n",
       "      <td>0.315772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>53.922991</td>\n",
       "      <td>7.343228</td>\n",
       "      <td>0.349964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>70.287263</td>\n",
       "      <td>8.383750</td>\n",
       "      <td>0.152694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>78.010986</td>\n",
       "      <td>8.832383</td>\n",
       "      <td>0.059586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>74.606198</td>\n",
       "      <td>8.637488</td>\n",
       "      <td>0.100630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>57.980202</td>\n",
       "      <td>7.614473</td>\n",
       "      <td>0.301055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>65.024697</td>\n",
       "      <td>8.063789</td>\n",
       "      <td>0.216134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>91.878352</td>\n",
       "      <td>9.585320</td>\n",
       "      <td>-0.107584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>65.554183</td>\n",
       "      <td>8.096554</td>\n",
       "      <td>0.209751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>57.588120</td>\n",
       "      <td>7.588684</td>\n",
       "      <td>0.305781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>62.827310</td>\n",
       "      <td>7.926368</td>\n",
       "      <td>0.242623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>55.672277</td>\n",
       "      <td>7.461386</td>\n",
       "      <td>0.328876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>55.138299</td>\n",
       "      <td>7.425517</td>\n",
       "      <td>0.335313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>48.760725</td>\n",
       "      <td>6.982888</td>\n",
       "      <td>0.412194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>63.788845</td>\n",
       "      <td>7.986792</td>\n",
       "      <td>0.231032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>53.442658</td>\n",
       "      <td>7.310449</td>\n",
       "      <td>0.355754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>56.767009</td>\n",
       "      <td>7.534388</td>\n",
       "      <td>0.315680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>44.335175</td>\n",
       "      <td>6.658466</td>\n",
       "      <td>0.465544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>55.461210</td>\n",
       "      <td>7.447228</td>\n",
       "      <td>0.331421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>82.255660</td>\n",
       "      <td>9.069491</td>\n",
       "      <td>0.008416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>49.742186</td>\n",
       "      <td>7.052814</td>\n",
       "      <td>0.400363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>54.623442</td>\n",
       "      <td>7.390767</td>\n",
       "      <td>0.341520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>58.667980</td>\n",
       "      <td>7.659503</td>\n",
       "      <td>0.292764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>62.324382</td>\n",
       "      <td>7.894579</td>\n",
       "      <td>0.248686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>56.879873</td>\n",
       "      <td>7.541875</td>\n",
       "      <td>0.314319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>59.437463</td>\n",
       "      <td>7.709570</td>\n",
       "      <td>0.283488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>59.803361</td>\n",
       "      <td>7.733263</td>\n",
       "      <td>0.279077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>60.156517</td>\n",
       "      <td>7.756063</td>\n",
       "      <td>0.274819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>63.591635</td>\n",
       "      <td>7.974436</td>\n",
       "      <td>0.233409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>63.510857</td>\n",
       "      <td>7.969370</td>\n",
       "      <td>0.234383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>63.550861</td>\n",
       "      <td>7.971879</td>\n",
       "      <td>0.233901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>53.791109</td>\n",
       "      <td>7.334242</td>\n",
       "      <td>0.351554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>58.399970</td>\n",
       "      <td>7.641987</td>\n",
       "      <td>0.295994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>60.879458</td>\n",
       "      <td>7.802529</td>\n",
       "      <td>0.266104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>130.441829</td>\n",
       "      <td>11.421113</td>\n",
       "      <td>-0.572463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>61.901210</td>\n",
       "      <td>7.867732</td>\n",
       "      <td>0.253787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>54.939164</td>\n",
       "      <td>7.412096</td>\n",
       "      <td>0.337714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>55.832222</td>\n",
       "      <td>7.472096</td>\n",
       "      <td>0.326948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>63.232795</td>\n",
       "      <td>7.951905</td>\n",
       "      <td>0.237735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>56.040012</td>\n",
       "      <td>7.485988</td>\n",
       "      <td>0.324443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>82.133540</td>\n",
       "      <td>9.062756</td>\n",
       "      <td>0.009889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  Activation  layer size         MSE       RMSE        R2\n",
       "0   0.001    4000           0           8   49.325946   7.023243  0.405381\n",
       "1   0.001    4000           0          25  103.101655  10.153899 -0.242880\n",
       "2   0.001    4000           0          64   85.387466   9.240534 -0.029337\n",
       "3   0.001    6000           0           8   50.349019   7.095704  0.393048\n",
       "4   0.001    6000           0          25   59.590267   7.719473  0.281645\n",
       "5   0.001    6000           0          64   65.120898   8.069752  0.214974\n",
       "6   0.001    8000           0           8   83.694952   9.148495 -0.008934\n",
       "7   0.001    8000           0          25   59.946684   7.742524  0.277349\n",
       "8   0.001    8000           0          64   52.737748   7.262076  0.364252\n",
       "9   0.002    4000           0           8   71.008493   8.426654  0.144000\n",
       "10  0.002    4000           0          25   52.942552   7.276163  0.361783\n",
       "11  0.002    4000           0          64   57.403712   7.576524  0.308004\n",
       "12  0.002    6000           0           8   55.848812   7.473206  0.326748\n",
       "13  0.002    6000           0          25   56.759333   7.533879  0.315772\n",
       "14  0.002    6000           0          64   53.922991   7.343228  0.349964\n",
       "15  0.002    8000           0           8   70.287263   8.383750  0.152694\n",
       "16  0.002    8000           0          25   78.010986   8.832383  0.059586\n",
       "17  0.002    8000           0          64   74.606198   8.637488  0.100630\n",
       "18  0.003    4000           0           8   57.980202   7.614473  0.301055\n",
       "19  0.003    4000           0          25   65.024697   8.063789  0.216134\n",
       "20  0.003    4000           0          64   91.878352   9.585320 -0.107584\n",
       "21  0.003    6000           0           8   65.554183   8.096554  0.209751\n",
       "22  0.003    6000           0          25   57.588120   7.588684  0.305781\n",
       "23  0.003    6000           0          64   62.827310   7.926368  0.242623\n",
       "24  0.003    8000           0           8   55.672277   7.461386  0.328876\n",
       "25  0.003    8000           0          25   55.138299   7.425517  0.335313\n",
       "26  0.003    8000           0          64   48.760725   6.982888  0.412194\n",
       "27  0.001    4000           1           8   63.788845   7.986792  0.231032\n",
       "28  0.001    4000           1          25   53.442658   7.310449  0.355754\n",
       "29  0.001    4000           1          64   56.767009   7.534388  0.315680\n",
       "30  0.001    6000           1           8   44.335175   6.658466  0.465544\n",
       "31  0.001    6000           1          25   55.461210   7.447228  0.331421\n",
       "32  0.001    6000           1          64   82.255660   9.069491  0.008416\n",
       "33  0.001    8000           1           8   49.742186   7.052814  0.400363\n",
       "34  0.001    8000           1          25   54.623442   7.390767  0.341520\n",
       "35  0.001    8000           1          64   58.667980   7.659503  0.292764\n",
       "36  0.002    4000           1           8   62.324382   7.894579  0.248686\n",
       "37  0.002    4000           1          25   56.879873   7.541875  0.314319\n",
       "38  0.002    4000           1          64   59.437463   7.709570  0.283488\n",
       "39  0.002    6000           1           8   59.803361   7.733263  0.279077\n",
       "40  0.002    6000           1          25   60.156517   7.756063  0.274819\n",
       "41  0.002    6000           1          64   63.591635   7.974436  0.233409\n",
       "42  0.002    8000           1           8   63.510857   7.969370  0.234383\n",
       "43  0.002    8000           1          25   63.550861   7.971879  0.233901\n",
       "44  0.002    8000           1          64   53.791109   7.334242  0.351554\n",
       "45  0.003    4000           1           8   58.399970   7.641987  0.295994\n",
       "46  0.003    4000           1          25   60.879458   7.802529  0.266104\n",
       "47  0.003    4000           1          64  130.441829  11.421113 -0.572463\n",
       "48  0.003    6000           1           8   61.901210   7.867732  0.253787\n",
       "49  0.003    6000           1          25   54.939164   7.412096  0.337714\n",
       "50  0.003    6000           1          64   55.832222   7.472096  0.326948\n",
       "51  0.003    8000           1           8   63.232795   7.951905  0.237735\n",
       "52  0.003    8000           1          25   56.040012   7.485988  0.324443\n",
       "53  0.003    8000           1          64   82.133540   9.062756  0.009889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(table_sgd,columns = ['LR','Epochs','Activation','layer size','MSE','RMSE','R2'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1df6f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd Sigmoid Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>44.335175</td>\n",
       "      <td>6.658466</td>\n",
       "      <td>0.465544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>49.742186</td>\n",
       "      <td>7.052814</td>\n",
       "      <td>0.400363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>53.442658</td>\n",
       "      <td>7.310449</td>\n",
       "      <td>0.355754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>53.791109</td>\n",
       "      <td>7.334242</td>\n",
       "      <td>0.351554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>54.623442</td>\n",
       "      <td>7.390767</td>\n",
       "      <td>0.341520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>54.939164</td>\n",
       "      <td>7.412096</td>\n",
       "      <td>0.337714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>55.461210</td>\n",
       "      <td>7.447228</td>\n",
       "      <td>0.331421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>55.832222</td>\n",
       "      <td>7.472096</td>\n",
       "      <td>0.326948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>56.040012</td>\n",
       "      <td>7.485988</td>\n",
       "      <td>0.324443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>56.767009</td>\n",
       "      <td>7.534388</td>\n",
       "      <td>0.315680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>56.879873</td>\n",
       "      <td>7.541875</td>\n",
       "      <td>0.314319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>58.399970</td>\n",
       "      <td>7.641987</td>\n",
       "      <td>0.295994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>58.667980</td>\n",
       "      <td>7.659503</td>\n",
       "      <td>0.292764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>59.437463</td>\n",
       "      <td>7.709570</td>\n",
       "      <td>0.283488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>59.803361</td>\n",
       "      <td>7.733263</td>\n",
       "      <td>0.279077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>60.156517</td>\n",
       "      <td>7.756063</td>\n",
       "      <td>0.274819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>60.879458</td>\n",
       "      <td>7.802529</td>\n",
       "      <td>0.266104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>61.901210</td>\n",
       "      <td>7.867732</td>\n",
       "      <td>0.253787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>62.324382</td>\n",
       "      <td>7.894579</td>\n",
       "      <td>0.248686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>63.232795</td>\n",
       "      <td>7.951905</td>\n",
       "      <td>0.237735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>63.510857</td>\n",
       "      <td>7.969370</td>\n",
       "      <td>0.234383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>63.550861</td>\n",
       "      <td>7.971879</td>\n",
       "      <td>0.233901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>63.591635</td>\n",
       "      <td>7.974436</td>\n",
       "      <td>0.233409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>63.788845</td>\n",
       "      <td>7.986792</td>\n",
       "      <td>0.231032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>82.133540</td>\n",
       "      <td>9.062756</td>\n",
       "      <td>0.009889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>82.255660</td>\n",
       "      <td>9.069491</td>\n",
       "      <td>0.008416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>130.441829</td>\n",
       "      <td>11.421113</td>\n",
       "      <td>-0.572463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size         MSE       RMSE        R2\n",
       "30  0.001    6000           8   44.335175   6.658466  0.465544\n",
       "33  0.001    8000           8   49.742186   7.052814  0.400363\n",
       "28  0.001    4000          25   53.442658   7.310449  0.355754\n",
       "44  0.002    8000          64   53.791109   7.334242  0.351554\n",
       "34  0.001    8000          25   54.623442   7.390767  0.341520\n",
       "49  0.003    6000          25   54.939164   7.412096  0.337714\n",
       "31  0.001    6000          25   55.461210   7.447228  0.331421\n",
       "50  0.003    6000          64   55.832222   7.472096  0.326948\n",
       "52  0.003    8000          25   56.040012   7.485988  0.324443\n",
       "29  0.001    4000          64   56.767009   7.534388  0.315680\n",
       "37  0.002    4000          25   56.879873   7.541875  0.314319\n",
       "45  0.003    4000           8   58.399970   7.641987  0.295994\n",
       "35  0.001    8000          64   58.667980   7.659503  0.292764\n",
       "38  0.002    4000          64   59.437463   7.709570  0.283488\n",
       "39  0.002    6000           8   59.803361   7.733263  0.279077\n",
       "40  0.002    6000          25   60.156517   7.756063  0.274819\n",
       "46  0.003    4000          25   60.879458   7.802529  0.266104\n",
       "48  0.003    6000           8   61.901210   7.867732  0.253787\n",
       "36  0.002    4000           8   62.324382   7.894579  0.248686\n",
       "51  0.003    8000           8   63.232795   7.951905  0.237735\n",
       "42  0.002    8000           8   63.510857   7.969370  0.234383\n",
       "43  0.002    8000          25   63.550861   7.971879  0.233901\n",
       "41  0.002    6000          64   63.591635   7.974436  0.233409\n",
       "27  0.001    4000           8   63.788845   7.986792  0.231032\n",
       "53  0.003    8000          64   82.133540   9.062756  0.009889\n",
       "32  0.001    6000          64   82.255660   9.069491  0.008416\n",
       "47  0.003    4000          64  130.441829  11.421113 -0.572463"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sgd Sigmoid Metrics\")\n",
    "df_sgd_sigmoid = table[table['Activation'] == 1].drop('Activation',axis = 1)\n",
    "df_sgd_sigmoid = df_sgd_sigmoid.sort_values(by='R2', ascending=False)\n",
    "df_sgd_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "389ee237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd tanh Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>layer size</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>48.760725</td>\n",
       "      <td>6.982888</td>\n",
       "      <td>0.412194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>49.325946</td>\n",
       "      <td>7.023243</td>\n",
       "      <td>0.405381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>50.349019</td>\n",
       "      <td>7.095704</td>\n",
       "      <td>0.393048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>52.737748</td>\n",
       "      <td>7.262076</td>\n",
       "      <td>0.364252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>52.942552</td>\n",
       "      <td>7.276163</td>\n",
       "      <td>0.361783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>53.922991</td>\n",
       "      <td>7.343228</td>\n",
       "      <td>0.349964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>55.138299</td>\n",
       "      <td>7.425517</td>\n",
       "      <td>0.335313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>55.672277</td>\n",
       "      <td>7.461386</td>\n",
       "      <td>0.328876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>55.848812</td>\n",
       "      <td>7.473206</td>\n",
       "      <td>0.326748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>56.759333</td>\n",
       "      <td>7.533879</td>\n",
       "      <td>0.315772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>57.403712</td>\n",
       "      <td>7.576524</td>\n",
       "      <td>0.308004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>57.588120</td>\n",
       "      <td>7.588684</td>\n",
       "      <td>0.305781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>57.980202</td>\n",
       "      <td>7.614473</td>\n",
       "      <td>0.301055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>25</td>\n",
       "      <td>59.590267</td>\n",
       "      <td>7.719473</td>\n",
       "      <td>0.281645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>59.946684</td>\n",
       "      <td>7.742524</td>\n",
       "      <td>0.277349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>62.827310</td>\n",
       "      <td>7.926368</td>\n",
       "      <td>0.242623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>65.024697</td>\n",
       "      <td>8.063789</td>\n",
       "      <td>0.216134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6000</td>\n",
       "      <td>64</td>\n",
       "      <td>65.120898</td>\n",
       "      <td>8.069752</td>\n",
       "      <td>0.214974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>65.554183</td>\n",
       "      <td>8.096554</td>\n",
       "      <td>0.209751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>70.287263</td>\n",
       "      <td>8.383750</td>\n",
       "      <td>0.152694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002</td>\n",
       "      <td>4000</td>\n",
       "      <td>8</td>\n",
       "      <td>71.008493</td>\n",
       "      <td>8.426654</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>64</td>\n",
       "      <td>74.606198</td>\n",
       "      <td>8.637488</td>\n",
       "      <td>0.100630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>8000</td>\n",
       "      <td>25</td>\n",
       "      <td>78.010986</td>\n",
       "      <td>8.832383</td>\n",
       "      <td>0.059586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>8000</td>\n",
       "      <td>8</td>\n",
       "      <td>83.694952</td>\n",
       "      <td>9.148495</td>\n",
       "      <td>-0.008934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>85.387466</td>\n",
       "      <td>9.240534</td>\n",
       "      <td>-0.029337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>91.878352</td>\n",
       "      <td>9.585320</td>\n",
       "      <td>-0.107584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>25</td>\n",
       "      <td>103.101655</td>\n",
       "      <td>10.153899</td>\n",
       "      <td>-0.242880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LR  Epochs  layer size         MSE       RMSE        R2\n",
       "26  0.003    8000          64   48.760725   6.982888  0.412194\n",
       "0   0.001    4000           8   49.325946   7.023243  0.405381\n",
       "3   0.001    6000           8   50.349019   7.095704  0.393048\n",
       "8   0.001    8000          64   52.737748   7.262076  0.364252\n",
       "10  0.002    4000          25   52.942552   7.276163  0.361783\n",
       "14  0.002    6000          64   53.922991   7.343228  0.349964\n",
       "25  0.003    8000          25   55.138299   7.425517  0.335313\n",
       "24  0.003    8000           8   55.672277   7.461386  0.328876\n",
       "12  0.002    6000           8   55.848812   7.473206  0.326748\n",
       "13  0.002    6000          25   56.759333   7.533879  0.315772\n",
       "11  0.002    4000          64   57.403712   7.576524  0.308004\n",
       "22  0.003    6000          25   57.588120   7.588684  0.305781\n",
       "18  0.003    4000           8   57.980202   7.614473  0.301055\n",
       "4   0.001    6000          25   59.590267   7.719473  0.281645\n",
       "7   0.001    8000          25   59.946684   7.742524  0.277349\n",
       "23  0.003    6000          64   62.827310   7.926368  0.242623\n",
       "19  0.003    4000          25   65.024697   8.063789  0.216134\n",
       "5   0.001    6000          64   65.120898   8.069752  0.214974\n",
       "21  0.003    6000           8   65.554183   8.096554  0.209751\n",
       "15  0.002    8000           8   70.287263   8.383750  0.152694\n",
       "9   0.002    4000           8   71.008493   8.426654  0.144000\n",
       "17  0.002    8000          64   74.606198   8.637488  0.100630\n",
       "16  0.002    8000          25   78.010986   8.832383  0.059586\n",
       "6   0.001    8000           8   83.694952   9.148495 -0.008934\n",
       "2   0.001    4000          64   85.387466   9.240534 -0.029337\n",
       "20  0.003    4000          64   91.878352   9.585320 -0.107584\n",
       "1   0.001    4000          25  103.101655  10.153899 -0.242880"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sgd tanh Metrics\")\n",
    "df_sgd_tanh = table[table['Activation'] == 0].drop('Activation',axis = 1)\n",
    "df_sgd_tanh = df_sgd_tanh.sort_values(by='R2', ascending=False)\n",
    "df_sgd_tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c252656",
   "metadata": {},
   "source": [
    "# best Architecture\n",
    "### Minibatch with layer size 25, lr = 0.003, activation = relu and trained for epochs 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6532d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Training => MSE : 25.6852\n",
      "VALIDATION\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => MSE : 14.581198\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => RMSE : 3.818534\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.824225\n"
     ]
    }
   ],
   "source": [
    "size = 25\n",
    "lr = 0.003\n",
    "epoch = 8000\n",
    "activation = [relu]\n",
    "\n",
    "regressor = MLP(input_size,output_size,num_layers,[size],activation,'minibatch',lr)\n",
    "#       Training\n",
    "regressor.training(x_training,y_train,epoch)\n",
    "#       Training metrics\n",
    "out = regressor.forward(x_training)\n",
    "mse_train = mse(y_train,out)\n",
    "print(\"TRAINING\")\n",
    "print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Training => MSE : {mse_train:.4f}\")\n",
    "\n",
    "#       Validation\n",
    "out = regressor.forward(x_validation)\n",
    "mse_val = mean_squared_error(y_val, out)\n",
    "rmse_val = mean_squared_error(y_val, out, squared=False)\n",
    "r2_val = r2_score(y_val, out)\n",
    "print(\"VALIDATION\")\n",
    "print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => MSE : {mse_val:.4f}\")\n",
    "print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => RMSE : {rmse_val:.4f}\")\n",
    "print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => R2 score : {r2_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d551d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => MSE : 20.473239\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => RMSE : 4.524736\n",
      "Epoch [8000], lr [0.003], activation [relu], size [25] Validation => R2 score : 0.753197\n"
     ]
    }
   ],
   "source": [
    "#       testing\n",
    "out = regressor.forward(x_testing)\n",
    "mse_val = mean_squared_error(y_test, out)\n",
    "rmse_val = mean_squared_error(y_test, out, squared=False)\n",
    "r2_val = r2_score(y_test, out)\n",
    "print(\"Testing\")\n",
    "print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => MSE : {mse_val:.4f}\")\n",
    "print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => RMSE : {rmse_val:.4f}\")\n",
    "print(f\"Epoch [{epoch}], lr [{lr}], activation [{activation_names[idx]}], size [{size}] Validation => R2 score : {r2_val:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7927b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa07ca5",
   "metadata": {},
   "source": [
    "# Generating training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db8b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - 1 Generated\n"
     ]
    }
   ],
   "source": [
    "training_sets = []\n",
    "batch_size = [1000]\n",
    "for idx,size in enumerate(batch_size):\n",
    "    training_data = torch.zeros((size,101))\n",
    "    for row in range(size):\n",
    "        training_data[row],_ = torch.sort(torch.randint(1,100,(101,)))\n",
    "        if torch.randint(0,2,(1,)).item() == 1:\n",
    "            training_data[row][0] = training_data[row][100] = 100\n",
    "        else:\n",
    "            training_data[row][0] = training_data[row][100] = 101\n",
    "\n",
    "    # One-hot encoding for the target variable -> (size,101,101)\n",
    "    target = torch.zeros(training_data.shape[0],training_data.shape[1],training_data.shape[1])\n",
    "    for row in range(target.shape[0]):\n",
    "        for seq in range(target.shape[1]):\n",
    "            target[row][seq][int(training_data[row][seq])-1] = 1.0\n",
    "    \n",
    "    training_sets.append(target)\n",
    "    print(f\"Training set - {idx+1} Generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c053b",
   "metadata": {},
   "source": [
    "# Generating Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2f395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set - 1 Generated\n",
      "Test set - 2 Generated\n",
      "Test set - 3 Generated\n",
      "Test set - 4 Generated\n",
      "Test set - 5 Generated\n",
      "Test set - 6 Generated\n",
      "Test set - 7 Generated\n",
      "Test set - 8 Generated\n",
      "Test set - 9 Generated\n",
      "Test set - 10 Generated\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "for dataset in range(10):\n",
    "    \n",
    "    test_data = torch.zeros((3000,101))\n",
    "    for row in range(3000):\n",
    "        test_data[row],_ = torch.sort(torch.randint(1,100,(101,)))\n",
    "        if torch.randint(0,2,(1,)).item() == 1:\n",
    "            test_data[row][0] = test_data[row][100] = 100\n",
    "        else:\n",
    "            test_data[row][0] = test_data[row][100] = 101\n",
    "\n",
    "    # test_data = test_data[torch.randperm(test_data.shape[0])]\n",
    "\n",
    "    # One-hot encoding for the target variable -> (3000,101,101)\n",
    "    target_test = torch.zeros(test_data.shape[0],test_data.shape[1],test_data.shape[1])\n",
    "    for row in range(target_test.shape[0]):\n",
    "        for seq in range(target_test.shape[1]):\n",
    "            target_test[row][seq][int(test_data[row][seq])-1] = 1.0\n",
    "    \n",
    "    test_datasets.append(target_test)\n",
    "    print(f\"Test set - {dataset+1} Generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446de2f8",
   "metadata": {},
   "source": [
    "# Models (RNN and LSTM)\n",
    "### Architecture\n",
    "- Input size kept to be 101\n",
    "- Number of layers = 1\n",
    "- Hidden size kept to be 150\n",
    "- Using batch gradient descent with training batch size 1500\n",
    "- Linear layer which compresses the hidden layer output to dimensions of the classes ie 101\n",
    "- Using Softmax to calculate the predicted probability of each class\n",
    "- KL Divergence as the loss criterion\n",
    "\n",
    "**Experimentation**\n",
    "Experimented with the hidden layer size and number of layers. Most achitectures performed well for lstm but RNN found it difficult to converge.\n",
    "\n",
    "**Conclusion**\n",
    "The actual output depends solely on the input { y(ap,a1,a2 .... ap-1) = ap } hence ideally the function must learn this one to one dependency between the inital input and final output. But since the sequence length is 100, models that face Problems to address long term dependency for reasons like vanishing gradients Eg RNN almost never converge. Models like LSTMs designed to address this converge well and in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4aefac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqPredictorRNN(nn.Module):\n",
    "    def __init__(self, input_size, batch_size, hidden_size,num_layers):\n",
    "        super(SeqPredictorRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,2)\n",
    "        self.linear_general = nn.Linear(hidden_size,101)\n",
    "        self.smax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, x,teacher_ratio):\n",
    "        self.initial_hidden = torch.rand(self.num_layers,x.shape[0],self.hidden_size)\n",
    "        outputs = []\n",
    "        hidden_states = []\n",
    "        for timestep in range(100):\n",
    "            h_t = []\n",
    "            if(timestep== 0):\n",
    "                h_t = self.rnn_cell(x[:,timestep], self.initial_hidden[0])\n",
    "            else:\n",
    "                input = []\n",
    "                if(torch.rand(1).item() < teacher_ratio):\n",
    "                    input = x[:,timestep]\n",
    "                else:\n",
    "                    input = torch.zeros_like(x[:,0])\n",
    "                    temp = torch.argmax(outputs[-1],dim=1)\n",
    "                    for row in range(input.shape[0]):\n",
    "                        input[row][temp[row]] = 1.0\n",
    "                    \n",
    "                h_t = self.rnn_cell(input, hidden_states[-1])\n",
    "            hidden_states.append(h_t)\n",
    "            if(timestep < 99):\n",
    "                out = self.smax(self.linear_general(h_t))\n",
    "            else:\n",
    "                out = self.smax(self.linear_general(h_t))\n",
    "            outputs.append(out)\n",
    "            \n",
    "#         _, final_hidden = self.rnn(x,self.initial_hidden)\n",
    "#         out = self.smax(self.linear(final_hidden[0]))\n",
    "        return outputs[-1]\n",
    "\n",
    "class SeqPredictorLSTM(nn.Module):\n",
    "    def __init__(self, input_size, batch_size, hidden_size,num_layers):\n",
    "        super(SeqPredictorLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,2)\n",
    "        self.linear_general = nn.Linear(hidden_size,101)\n",
    "        self.smax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, x,teacher_ratio):\n",
    "        self.initial_hidden = torch.rand(self.num_layers,x.shape[0],self.hidden_size)\n",
    "        self.initial_cell = torch.rand(self.num_layers,x.shape[0],self.hidden_size)\n",
    "\n",
    "        outputs = []\n",
    "        hidden_states = []\n",
    "        cell_states = []\n",
    "        for timestep in range(100):\n",
    "            h_t = []\n",
    "            c_t = []\n",
    "            if(timestep== 0):\n",
    "                (h_t,c_t) = self.lstm_cell(x[:,timestep], (self.initial_hidden[0],self.initial_cell[0]))\n",
    "            else:\n",
    "                input = []\n",
    "                if(torch.rand(1).item() < teacher_ratio):\n",
    "                    input = x[:,timestep]\n",
    "                else:\n",
    "                    input = torch.zeros_like(x[:,0])\n",
    "                    temp = torch.argmax(outputs[-1],dim=1)\n",
    "                    for row in range(input.shape[0]):\n",
    "                        input[row][temp[row]] = 1.0\n",
    "                    \n",
    "                (h_t,c_t) = self.lstm_cell(input, (hidden_states[-1],cell_states[-1]))\n",
    "            hidden_states.append(h_t)\n",
    "            cell_states.append(c_t)\n",
    "            if(timestep < 99):\n",
    "                out = self.smax(self.linear_general(h_t))\n",
    "            else:\n",
    "                out = self.smax(self.linear_general(h_t))\n",
    "            outputs.append(out)\n",
    "            \n",
    "#         _, final_hidden = self.rnn(x,self.initial_hidden)\n",
    "#         out = self.smax(self.linear(final_hidden[0]))\n",
    "        return outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c9100",
   "metadata": {},
   "source": [
    "# RNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb937cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 4.6638\n",
      "Epoch [2/1000], Loss: 4.5745\n",
      "Epoch [3/1000], Loss: 4.4862\n",
      "Epoch [4/1000], Loss: 4.4196\n",
      "Epoch [5/1000], Loss: 4.2960\n",
      "Epoch [6/1000], Loss: 4.1421\n",
      "Epoch [7/1000], Loss: 3.9121\n",
      "Epoch [8/1000], Loss: 3.5586\n",
      "Epoch [9/1000], Loss: 3.1037\n",
      "Epoch [10/1000], Loss: 2.6477\n",
      "Epoch [11/1000], Loss: 2.2668\n",
      "Epoch [12/1000], Loss: 1.9454\n",
      "Epoch [13/1000], Loss: 1.6664\n",
      "Epoch [14/1000], Loss: 1.5089\n",
      "Epoch [15/1000], Loss: 1.7562\n",
      "Epoch [16/1000], Loss: 2.7164\n",
      "Epoch [17/1000], Loss: 3.0413\n",
      "Epoch [18/1000], Loss: 3.8729\n",
      "Epoch [19/1000], Loss: 4.8348\n",
      "Epoch [20/1000], Loss: 4.9880\n",
      "Epoch [21/1000], Loss: 5.6641\n",
      "Epoch [22/1000], Loss: 6.0669\n",
      "Epoch [23/1000], Loss: 6.2175\n",
      "Epoch [24/1000], Loss: 6.5076\n",
      "Epoch [25/1000], Loss: 6.3117\n",
      "Epoch [26/1000], Loss: 6.1008\n",
      "Epoch [27/1000], Loss: 6.0234\n",
      "Epoch [28/1000], Loss: 5.9504\n",
      "Epoch [29/1000], Loss: 5.7576\n",
      "Epoch [30/1000], Loss: 5.7288\n",
      "Epoch [31/1000], Loss: 5.3265\n",
      "Epoch [32/1000], Loss: 5.0229\n",
      "Epoch [33/1000], Loss: 4.8098\n",
      "Epoch [34/1000], Loss: 4.7257\n",
      "Epoch [35/1000], Loss: 4.4746\n",
      "Epoch [36/1000], Loss: 4.3188\n",
      "Epoch [37/1000], Loss: 3.9873\n",
      "Epoch [38/1000], Loss: 3.9174\n",
      "Epoch [39/1000], Loss: 3.7234\n",
      "Epoch [40/1000], Loss: 3.6365\n",
      "Epoch [41/1000], Loss: 3.4354\n",
      "Epoch [42/1000], Loss: 3.4310\n",
      "Epoch [43/1000], Loss: 3.2522\n",
      "Epoch [44/1000], Loss: 3.0886\n",
      "Epoch [45/1000], Loss: 2.9124\n",
      "Epoch [46/1000], Loss: 2.8173\n",
      "Epoch [47/1000], Loss: 2.6720\n",
      "Epoch [48/1000], Loss: 2.6182\n",
      "Epoch [49/1000], Loss: 2.5595\n",
      "Epoch [50/1000], Loss: 2.4185\n",
      "Epoch [51/1000], Loss: 2.2434\n",
      "Epoch [52/1000], Loss: 2.1776\n",
      "Epoch [53/1000], Loss: 2.1112\n",
      "Epoch [54/1000], Loss: 2.0568\n",
      "Epoch [55/1000], Loss: 1.9351\n",
      "Epoch [56/1000], Loss: 1.8249\n",
      "Epoch [57/1000], Loss: 1.8409\n",
      "Epoch [58/1000], Loss: 1.7363\n",
      "Epoch [59/1000], Loss: 1.6505\n",
      "Epoch [60/1000], Loss: 1.5829\n",
      "Epoch [61/1000], Loss: 1.4395\n",
      "Epoch [62/1000], Loss: 1.3662\n",
      "Epoch [63/1000], Loss: 1.3633\n",
      "Epoch [64/1000], Loss: 1.3307\n",
      "Epoch [65/1000], Loss: 1.3544\n",
      "Epoch [66/1000], Loss: 1.2398\n",
      "Epoch [67/1000], Loss: 1.3377\n",
      "Epoch [68/1000], Loss: 1.2240\n",
      "Epoch [69/1000], Loss: 1.1820\n",
      "Epoch [70/1000], Loss: 1.2504\n",
      "Epoch [71/1000], Loss: 1.2183\n",
      "Epoch [72/1000], Loss: 1.3050\n",
      "Epoch [73/1000], Loss: 1.1496\n",
      "Epoch [74/1000], Loss: 1.0962\n",
      "Epoch [75/1000], Loss: 0.9566\n",
      "Epoch [76/1000], Loss: 0.9857\n",
      "Epoch [77/1000], Loss: 0.9833\n",
      "Epoch [78/1000], Loss: 0.9204\n",
      "Epoch [79/1000], Loss: 0.8087\n",
      "Epoch [80/1000], Loss: 0.8233\n",
      "Epoch [81/1000], Loss: 0.7713\n",
      "Epoch [82/1000], Loss: 0.7491\n",
      "Epoch [83/1000], Loss: 0.7775\n",
      "Epoch [84/1000], Loss: 0.7664\n",
      "Epoch [85/1000], Loss: 0.7372\n",
      "Epoch [86/1000], Loss: 0.7353\n",
      "Epoch [87/1000], Loss: 0.7455\n",
      "Epoch [88/1000], Loss: 0.7236\n",
      "Epoch [89/1000], Loss: 0.7320\n",
      "Epoch [90/1000], Loss: 0.7397\n",
      "Epoch [91/1000], Loss: 0.7485\n",
      "Epoch [92/1000], Loss: 0.7158\n",
      "Epoch [93/1000], Loss: 0.7573\n",
      "Epoch [94/1000], Loss: 0.7673\n",
      "Epoch [95/1000], Loss: 0.8203\n",
      "Epoch [96/1000], Loss: 0.7668\n",
      "Epoch [97/1000], Loss: 0.7553\n",
      "Epoch [98/1000], Loss: 0.7334\n",
      "Epoch [99/1000], Loss: 0.8093\n",
      "Epoch [100/1000], Loss: 0.7651\n",
      "Epoch [101/1000], Loss: 0.8081\n",
      "Epoch [102/1000], Loss: 0.7310\n",
      "Epoch [103/1000], Loss: 0.7741\n",
      "Epoch [104/1000], Loss: 0.7413\n",
      "Epoch [105/1000], Loss: 0.7743\n",
      "Epoch [106/1000], Loss: 0.7737\n",
      "Epoch [107/1000], Loss: 0.7295\n",
      "Epoch [108/1000], Loss: 0.7516\n",
      "Epoch [109/1000], Loss: 0.7400\n",
      "Epoch [110/1000], Loss: 0.7179\n",
      "Epoch [111/1000], Loss: 0.7067\n",
      "Epoch [112/1000], Loss: 0.7720\n",
      "Epoch [113/1000], Loss: 0.7390\n",
      "Epoch [114/1000], Loss: 0.7497\n",
      "Epoch [115/1000], Loss: 0.7165\n",
      "Epoch [116/1000], Loss: 0.7165\n",
      "Epoch [117/1000], Loss: 0.7162\n",
      "Epoch [118/1000], Loss: 0.7378\n",
      "Epoch [119/1000], Loss: 0.7160\n",
      "Epoch [120/1000], Loss: 0.7596\n",
      "Epoch [121/1000], Loss: 0.7269\n",
      "Epoch [122/1000], Loss: 0.7262\n",
      "Epoch [123/1000], Loss: 0.7261\n",
      "Epoch [124/1000], Loss: 0.7263\n",
      "Epoch [125/1000], Loss: 0.7808\n",
      "Epoch [126/1000], Loss: 0.7037\n",
      "Epoch [127/1000], Loss: 0.7484\n",
      "Epoch [128/1000], Loss: 0.7035\n",
      "Epoch [129/1000], Loss: 0.7033\n",
      "Epoch [130/1000], Loss: 0.7032\n",
      "Epoch [131/1000], Loss: 0.7030\n",
      "Epoch [132/1000], Loss: 0.7248\n",
      "Epoch [133/1000], Loss: 0.7028\n",
      "Epoch [134/1000], Loss: 0.7249\n",
      "Epoch [135/1000], Loss: 0.7025\n",
      "Epoch [136/1000], Loss: 0.7023\n",
      "Epoch [137/1000], Loss: 0.7134\n",
      "Epoch [138/1000], Loss: 0.7019\n",
      "Epoch [139/1000], Loss: 0.7128\n",
      "Epoch [140/1000], Loss: 0.7130\n",
      "Epoch [141/1000], Loss: 0.7016\n",
      "Epoch [142/1000], Loss: 0.7128\n",
      "Epoch [143/1000], Loss: 0.7239\n",
      "Epoch [144/1000], Loss: 0.7012\n",
      "Epoch [145/1000], Loss: 0.7122\n",
      "Epoch [146/1000], Loss: 0.7123\n",
      "Epoch [147/1000], Loss: 0.7119\n",
      "Epoch [148/1000], Loss: 0.7564\n",
      "Epoch [149/1000], Loss: 0.7006\n",
      "Epoch [150/1000], Loss: 0.7006\n",
      "Epoch [151/1000], Loss: 0.7343\n",
      "Epoch [152/1000], Loss: 0.7337\n",
      "Epoch [153/1000], Loss: 0.7119\n",
      "Epoch [154/1000], Loss: 0.7346\n",
      "Epoch [155/1000], Loss: 0.7002\n",
      "Epoch [156/1000], Loss: 0.7113\n",
      "Epoch [157/1000], Loss: 0.7229\n",
      "Epoch [158/1000], Loss: 0.7115\n",
      "Epoch [159/1000], Loss: 0.7000\n",
      "Epoch [160/1000], Loss: 0.6997\n",
      "Epoch [161/1000], Loss: 0.7114\n",
      "Epoch [162/1000], Loss: 0.7111\n",
      "Epoch [163/1000], Loss: 0.7109\n",
      "Epoch [164/1000], Loss: 0.6994\n",
      "Epoch [165/1000], Loss: 0.6996\n",
      "Epoch [166/1000], Loss: 0.7107\n",
      "Epoch [167/1000], Loss: 0.7106\n",
      "Epoch [168/1000], Loss: 0.6994\n",
      "Epoch [169/1000], Loss: 0.6993\n",
      "Epoch [170/1000], Loss: 0.7103\n",
      "Epoch [171/1000], Loss: 0.6989\n",
      "Epoch [172/1000], Loss: 0.6991\n",
      "Epoch [173/1000], Loss: 0.6988\n",
      "Epoch [174/1000], Loss: 0.6989\n",
      "Epoch [175/1000], Loss: 0.7106\n",
      "Epoch [176/1000], Loss: 0.6988\n",
      "Epoch [177/1000], Loss: 0.7101\n",
      "Epoch [178/1000], Loss: 0.7216\n",
      "Epoch [179/1000], Loss: 0.6986\n",
      "Epoch [180/1000], Loss: 0.6985\n",
      "Epoch [181/1000], Loss: 0.7100\n",
      "Epoch [182/1000], Loss: 0.6984\n",
      "Epoch [183/1000], Loss: 0.6983\n",
      "Epoch [184/1000], Loss: 0.7097\n",
      "Epoch [185/1000], Loss: 0.6982\n",
      "Epoch [186/1000], Loss: 0.7097\n",
      "Epoch [187/1000], Loss: 0.6981\n",
      "Epoch [188/1000], Loss: 0.6980\n",
      "Epoch [189/1000], Loss: 0.7094\n",
      "Epoch [190/1000], Loss: 0.6979\n",
      "Epoch [191/1000], Loss: 0.6979\n",
      "Epoch [192/1000], Loss: 0.6976\n",
      "Epoch [193/1000], Loss: 0.7094\n",
      "Epoch [194/1000], Loss: 0.7093\n",
      "Epoch [195/1000], Loss: 0.6977\n",
      "Epoch [196/1000], Loss: 0.6977\n",
      "Epoch [197/1000], Loss: 0.6976\n",
      "Epoch [198/1000], Loss: 0.6975\n",
      "Epoch [199/1000], Loss: 0.6975\n",
      "Epoch [200/1000], Loss: 0.7090\n",
      "Epoch [201/1000], Loss: 0.7438\n",
      "Epoch [202/1000], Loss: 0.7090\n",
      "Epoch [203/1000], Loss: 0.6973\n",
      "Epoch [204/1000], Loss: 0.7089\n",
      "Epoch [205/1000], Loss: 0.7092\n",
      "Epoch [206/1000], Loss: 0.7090\n",
      "Epoch [207/1000], Loss: 0.6972\n",
      "Epoch [208/1000], Loss: 0.6972\n",
      "Epoch [209/1000], Loss: 0.6972\n",
      "Epoch [210/1000], Loss: 0.6971\n",
      "Epoch [211/1000], Loss: 0.7088\n",
      "Epoch [212/1000], Loss: 0.6968\n",
      "Epoch [213/1000], Loss: 0.6970\n",
      "Epoch [214/1000], Loss: 0.6967\n",
      "Epoch [215/1000], Loss: 0.6970\n",
      "Epoch [216/1000], Loss: 0.6969\n",
      "Epoch [217/1000], Loss: 0.6969\n",
      "Epoch [218/1000], Loss: 0.6965\n",
      "Epoch [219/1000], Loss: 0.6968\n",
      "Epoch [220/1000], Loss: 0.6968\n",
      "Epoch [221/1000], Loss: 0.6967\n",
      "Epoch [222/1000], Loss: 0.6967\n",
      "Epoch [223/1000], Loss: 0.6967\n",
      "Epoch [224/1000], Loss: 0.7084\n",
      "Epoch [225/1000], Loss: 0.7084\n",
      "Epoch [226/1000], Loss: 0.6962\n",
      "Epoch [227/1000], Loss: 0.7085\n",
      "Epoch [228/1000], Loss: 0.6962\n",
      "Epoch [229/1000], Loss: 0.7088\n",
      "Epoch [230/1000], Loss: 0.6964\n",
      "Epoch [231/1000], Loss: 0.6964\n",
      "Epoch [232/1000], Loss: 0.6960\n",
      "Epoch [233/1000], Loss: 0.6960\n",
      "Epoch [234/1000], Loss: 0.7082\n",
      "Epoch [235/1000], Loss: 0.7201\n",
      "Epoch [236/1000], Loss: 0.7085\n",
      "Epoch [237/1000], Loss: 0.7200\n",
      "Epoch [238/1000], Loss: 0.7082\n",
      "Epoch [239/1000], Loss: 0.7080\n",
      "Epoch [240/1000], Loss: 0.7082\n",
      "Epoch [241/1000], Loss: 0.7082\n",
      "Epoch [242/1000], Loss: 0.6962\n",
      "Epoch [243/1000], Loss: 0.6958\n",
      "Epoch [244/1000], Loss: 0.6962\n",
      "Epoch [245/1000], Loss: 0.6962\n",
      "Epoch [246/1000], Loss: 0.6962\n",
      "Epoch [247/1000], Loss: 0.6961\n",
      "Epoch [248/1000], Loss: 0.6961\n",
      "Epoch [249/1000], Loss: 0.7198\n",
      "Epoch [250/1000], Loss: 0.6961\n",
      "Epoch [251/1000], Loss: 0.6956\n",
      "Epoch [252/1000], Loss: 0.7080\n",
      "Epoch [253/1000], Loss: 0.7075\n",
      "Epoch [254/1000], Loss: 0.6960\n",
      "Epoch [255/1000], Loss: 0.6960\n",
      "Epoch [256/1000], Loss: 0.6960\n",
      "Epoch [257/1000], Loss: 0.6960\n",
      "Epoch [258/1000], Loss: 0.6960\n",
      "Epoch [259/1000], Loss: 0.6954\n",
      "Epoch [260/1000], Loss: 0.6959\n",
      "Epoch [261/1000], Loss: 0.7079\n",
      "Epoch [262/1000], Loss: 0.6959\n",
      "Epoch [263/1000], Loss: 0.7080\n",
      "Epoch [264/1000], Loss: 0.6958\n",
      "Epoch [265/1000], Loss: 0.6958\n",
      "Epoch [266/1000], Loss: 0.6953\n",
      "Epoch [267/1000], Loss: 0.6958\n",
      "Epoch [268/1000], Loss: 0.7074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [269/1000], Loss: 0.6957\n",
      "Epoch [270/1000], Loss: 0.6957\n",
      "Epoch [271/1000], Loss: 0.6957\n",
      "Epoch [272/1000], Loss: 0.6957\n",
      "Epoch [273/1000], Loss: 0.6957\n",
      "Epoch [274/1000], Loss: 0.6956\n",
      "Epoch [275/1000], Loss: 0.6956\n",
      "Epoch [276/1000], Loss: 0.6951\n",
      "Epoch [277/1000], Loss: 0.6956\n",
      "Epoch [278/1000], Loss: 0.6950\n",
      "Epoch [279/1000], Loss: 0.6955\n",
      "Epoch [280/1000], Loss: 0.6955\n",
      "Epoch [281/1000], Loss: 0.6950\n",
      "Epoch [282/1000], Loss: 0.6955\n",
      "Epoch [283/1000], Loss: 0.7197\n",
      "Epoch [284/1000], Loss: 0.7198\n",
      "Epoch [285/1000], Loss: 0.6954\n",
      "Epoch [286/1000], Loss: 0.7075\n",
      "Epoch [287/1000], Loss: 0.6954\n",
      "Epoch [288/1000], Loss: 0.6954\n",
      "Epoch [289/1000], Loss: 0.6954\n",
      "Epoch [290/1000], Loss: 0.6953\n",
      "Epoch [291/1000], Loss: 0.6954\n",
      "Epoch [292/1000], Loss: 0.6953\n",
      "Epoch [293/1000], Loss: 0.6948\n",
      "Epoch [294/1000], Loss: 0.7071\n",
      "Epoch [295/1000], Loss: 0.6948\n",
      "Epoch [296/1000], Loss: 0.6953\n",
      "Epoch [297/1000], Loss: 0.6947\n",
      "Epoch [298/1000], Loss: 0.6953\n",
      "Epoch [299/1000], Loss: 0.7074\n",
      "Epoch [300/1000], Loss: 0.6952\n",
      "Epoch [301/1000], Loss: 0.6946\n",
      "Epoch [302/1000], Loss: 0.6952\n",
      "Epoch [303/1000], Loss: 0.6946\n",
      "Epoch [304/1000], Loss: 0.6952\n",
      "Epoch [305/1000], Loss: 0.6951\n",
      "Epoch [306/1000], Loss: 0.6951\n",
      "Epoch [307/1000], Loss: 0.6951\n",
      "Epoch [308/1000], Loss: 0.6945\n",
      "Epoch [309/1000], Loss: 0.6945\n",
      "Epoch [310/1000], Loss: 0.7196\n",
      "Epoch [311/1000], Loss: 0.6945\n",
      "Epoch [312/1000], Loss: 0.7073\n",
      "Epoch [313/1000], Loss: 0.6951\n",
      "Epoch [314/1000], Loss: 0.6950\n",
      "Epoch [315/1000], Loss: 0.6950\n",
      "Epoch [316/1000], Loss: 0.6950\n",
      "Epoch [317/1000], Loss: 0.7074\n",
      "Epoch [318/1000], Loss: 0.6944\n",
      "Epoch [319/1000], Loss: 0.6950\n",
      "Epoch [320/1000], Loss: 0.6943\n",
      "Epoch [321/1000], Loss: 0.6943\n",
      "Epoch [322/1000], Loss: 0.6949\n",
      "Epoch [323/1000], Loss: 0.6949\n",
      "Epoch [324/1000], Loss: 0.6943\n",
      "Epoch [325/1000], Loss: 0.6949\n",
      "Epoch [326/1000], Loss: 0.7071\n",
      "Epoch [327/1000], Loss: 0.6949\n",
      "Epoch [328/1000], Loss: 0.6949\n",
      "Epoch [329/1000], Loss: 0.6949\n",
      "Epoch [330/1000], Loss: 0.6942\n",
      "Epoch [331/1000], Loss: 0.6942\n",
      "Epoch [332/1000], Loss: 0.6948\n",
      "Epoch [333/1000], Loss: 0.6948\n",
      "Epoch [334/1000], Loss: 0.6948\n",
      "Epoch [335/1000], Loss: 0.6948\n",
      "Epoch [336/1000], Loss: 0.6941\n",
      "Epoch [337/1000], Loss: 0.6948\n",
      "Epoch [338/1000], Loss: 0.6948\n",
      "Epoch [339/1000], Loss: 0.6948\n",
      "Epoch [340/1000], Loss: 0.7070\n",
      "Epoch [341/1000], Loss: 0.6947\n",
      "Epoch [342/1000], Loss: 0.6947\n",
      "Epoch [343/1000], Loss: 0.6940\n",
      "Epoch [344/1000], Loss: 0.7066\n",
      "Epoch [345/1000], Loss: 0.6947\n",
      "Epoch [346/1000], Loss: 0.6947\n",
      "Epoch [347/1000], Loss: 0.7065\n",
      "Epoch [348/1000], Loss: 0.6940\n",
      "Epoch [349/1000], Loss: 0.6940\n",
      "Epoch [350/1000], Loss: 0.6946\n",
      "Epoch [351/1000], Loss: 0.6946\n",
      "Epoch [352/1000], Loss: 0.6947\n",
      "Epoch [353/1000], Loss: 0.6946\n",
      "Epoch [354/1000], Loss: 0.6946\n",
      "Epoch [355/1000], Loss: 0.6939\n",
      "Epoch [356/1000], Loss: 0.6939\n",
      "Epoch [357/1000], Loss: 0.6946\n",
      "Epoch [358/1000], Loss: 0.6946\n",
      "Epoch [359/1000], Loss: 0.6938\n",
      "Epoch [360/1000], Loss: 0.7072\n",
      "Epoch [361/1000], Loss: 0.6945\n",
      "Epoch [362/1000], Loss: 0.6945\n",
      "Epoch [363/1000], Loss: 0.7069\n",
      "Epoch [364/1000], Loss: 0.6945\n",
      "Epoch [365/1000], Loss: 0.6945\n",
      "Epoch [366/1000], Loss: 0.6945\n",
      "Epoch [367/1000], Loss: 0.6945\n",
      "Epoch [368/1000], Loss: 0.6945\n",
      "Epoch [369/1000], Loss: 0.6945\n",
      "Epoch [370/1000], Loss: 0.6945\n",
      "Epoch [371/1000], Loss: 0.6945\n",
      "Epoch [372/1000], Loss: 0.6944\n",
      "Epoch [373/1000], Loss: 0.6945\n",
      "Epoch [374/1000], Loss: 0.6945\n",
      "Epoch [375/1000], Loss: 0.6945\n",
      "Epoch [376/1000], Loss: 0.6945\n",
      "Epoch [377/1000], Loss: 0.7064\n",
      "Epoch [378/1000], Loss: 0.6944\n",
      "Epoch [379/1000], Loss: 0.6944\n",
      "Epoch [380/1000], Loss: 0.6936\n",
      "Epoch [381/1000], Loss: 0.6936\n",
      "Epoch [382/1000], Loss: 0.6936\n",
      "Epoch [383/1000], Loss: 0.7069\n",
      "Epoch [384/1000], Loss: 0.6943\n",
      "Epoch [385/1000], Loss: 0.6936\n",
      "Epoch [386/1000], Loss: 0.6936\n",
      "Epoch [387/1000], Loss: 0.6944\n",
      "Epoch [388/1000], Loss: 0.6944\n",
      "Epoch [389/1000], Loss: 0.6943\n",
      "Epoch [390/1000], Loss: 0.6943\n",
      "Epoch [391/1000], Loss: 0.6935\n",
      "Epoch [392/1000], Loss: 0.6943\n",
      "Epoch [393/1000], Loss: 0.6943\n",
      "Epoch [394/1000], Loss: 0.6935\n",
      "Epoch [395/1000], Loss: 0.6943\n",
      "Epoch [396/1000], Loss: 0.6943\n",
      "Epoch [397/1000], Loss: 0.6943\n",
      "Epoch [398/1000], Loss: 0.6943\n",
      "Epoch [399/1000], Loss: 0.6943\n",
      "Epoch [400/1000], Loss: 0.7200\n",
      "Epoch [401/1000], Loss: 0.6942\n",
      "Epoch [402/1000], Loss: 0.6943\n",
      "Epoch [403/1000], Loss: 0.6942\n",
      "Epoch [404/1000], Loss: 0.6943\n",
      "Epoch [405/1000], Loss: 0.6934\n",
      "Epoch [406/1000], Loss: 0.6934\n",
      "Epoch [407/1000], Loss: 0.6942\n",
      "Epoch [408/1000], Loss: 0.6942\n",
      "Epoch [409/1000], Loss: 0.6942\n",
      "Epoch [410/1000], Loss: 0.6942\n",
      "Epoch [411/1000], Loss: 0.6942\n",
      "Epoch [412/1000], Loss: 0.6942\n",
      "Epoch [413/1000], Loss: 0.6933\n",
      "Epoch [414/1000], Loss: 0.6933\n",
      "Epoch [415/1000], Loss: 0.6941\n",
      "Epoch [416/1000], Loss: 0.6932\n",
      "Epoch [417/1000], Loss: 0.6941\n",
      "Epoch [418/1000], Loss: 0.6933\n",
      "Epoch [419/1000], Loss: 0.6942\n",
      "Epoch [420/1000], Loss: 0.6941\n",
      "Epoch [421/1000], Loss: 0.7061\n",
      "Epoch [422/1000], Loss: 0.6932\n",
      "Epoch [423/1000], Loss: 0.7202\n",
      "Epoch [424/1000], Loss: 0.6941\n",
      "Epoch [425/1000], Loss: 0.6932\n",
      "Epoch [426/1000], Loss: 0.6941\n",
      "Epoch [427/1000], Loss: 0.6941\n",
      "Epoch [428/1000], Loss: 0.6941\n",
      "Epoch [429/1000], Loss: 0.6941\n",
      "Epoch [430/1000], Loss: 0.6932\n",
      "Epoch [431/1000], Loss: 0.7071\n",
      "Epoch [432/1000], Loss: 0.7069\n",
      "Epoch [433/1000], Loss: 0.6931\n",
      "Epoch [434/1000], Loss: 0.6940\n",
      "Epoch [435/1000], Loss: 0.6931\n",
      "Epoch [436/1000], Loss: 0.6930\n",
      "Epoch [437/1000], Loss: 0.6931\n",
      "Epoch [438/1000], Loss: 0.6941\n",
      "Epoch [439/1000], Loss: 0.6941\n",
      "Epoch [440/1000], Loss: 0.6941\n",
      "Epoch [441/1000], Loss: 0.6930\n",
      "Epoch [442/1000], Loss: 0.6930\n",
      "Epoch [443/1000], Loss: 0.6941\n",
      "Epoch [444/1000], Loss: 0.6941\n",
      "Epoch [445/1000], Loss: 0.6930\n",
      "Epoch [446/1000], Loss: 0.6941\n",
      "Epoch [447/1000], Loss: 0.6941\n",
      "Epoch [448/1000], Loss: 0.6940\n",
      "Epoch [449/1000], Loss: 0.6941\n",
      "Epoch [450/1000], Loss: 0.6930\n",
      "Epoch [451/1000], Loss: 0.6929\n",
      "Epoch [452/1000], Loss: 0.6941\n",
      "Epoch [453/1000], Loss: 0.6940\n",
      "Epoch [454/1000], Loss: 0.6940\n",
      "Epoch [455/1000], Loss: 0.6939\n",
      "Epoch [456/1000], Loss: 0.6940\n",
      "Epoch [457/1000], Loss: 0.7069\n",
      "Epoch [458/1000], Loss: 0.6929\n",
      "Epoch [459/1000], Loss: 0.6929\n",
      "Epoch [460/1000], Loss: 0.6940\n",
      "Epoch [461/1000], Loss: 0.7067\n",
      "Epoch [462/1000], Loss: 0.6940\n",
      "Epoch [463/1000], Loss: 0.6939\n",
      "Epoch [464/1000], Loss: 0.6928\n",
      "Epoch [465/1000], Loss: 0.6940\n",
      "Epoch [466/1000], Loss: 0.7188\n",
      "Epoch [467/1000], Loss: 0.7069\n",
      "Epoch [468/1000], Loss: 0.6938\n",
      "Epoch [469/1000], Loss: 0.6940\n",
      "Epoch [470/1000], Loss: 0.6940\n",
      "Epoch [471/1000], Loss: 0.6938\n",
      "Epoch [472/1000], Loss: 0.6940\n",
      "Epoch [473/1000], Loss: 0.6928\n",
      "Epoch [474/1000], Loss: 0.6938\n",
      "Epoch [475/1000], Loss: 0.6928\n",
      "Epoch [476/1000], Loss: 0.6940\n",
      "Epoch [477/1000], Loss: 0.6940\n",
      "Epoch [478/1000], Loss: 0.6940\n",
      "Epoch [479/1000], Loss: 0.6937\n",
      "Epoch [480/1000], Loss: 0.6940\n",
      "Epoch [481/1000], Loss: 0.6927\n",
      "Epoch [482/1000], Loss: 0.6940\n",
      "Epoch [483/1000], Loss: 0.6927\n",
      "Epoch [484/1000], Loss: 0.6926\n",
      "Epoch [485/1000], Loss: 0.6927\n",
      "Epoch [486/1000], Loss: 0.6927\n",
      "Epoch [487/1000], Loss: 0.6926\n",
      "Epoch [488/1000], Loss: 0.6939\n",
      "Epoch [489/1000], Loss: 0.6926\n",
      "Epoch [490/1000], Loss: 0.6936\n",
      "Epoch [491/1000], Loss: 0.6926\n",
      "Epoch [492/1000], Loss: 0.6925\n",
      "Epoch [493/1000], Loss: 0.6926\n",
      "Epoch [494/1000], Loss: 0.6939\n",
      "Epoch [495/1000], Loss: 0.6939\n",
      "Epoch [496/1000], Loss: 0.7068\n",
      "Epoch [497/1000], Loss: 0.6924\n",
      "Epoch [498/1000], Loss: 0.6939\n",
      "Epoch [499/1000], Loss: 0.6925\n",
      "Epoch [500/1000], Loss: 0.6939\n",
      "Epoch [501/1000], Loss: 0.6925\n",
      "Epoch [502/1000], Loss: 0.6939\n",
      "Epoch [503/1000], Loss: 0.6939\n",
      "Epoch [504/1000], Loss: 0.6937\n",
      "Epoch [505/1000], Loss: 0.6937\n",
      "Epoch [506/1000], Loss: 0.6939\n",
      "Epoch [507/1000], Loss: 0.6939\n",
      "Epoch [508/1000], Loss: 0.6939\n",
      "Epoch [509/1000], Loss: 0.6935\n",
      "Epoch [510/1000], Loss: 0.6924\n",
      "Epoch [511/1000], Loss: 0.6938\n",
      "Epoch [512/1000], Loss: 0.6938\n",
      "Epoch [513/1000], Loss: 0.7055\n",
      "Epoch [514/1000], Loss: 0.6935\n",
      "Epoch [515/1000], Loss: 0.6938\n",
      "Epoch [516/1000], Loss: 0.6938\n",
      "Epoch [517/1000], Loss: 0.6938\n",
      "Epoch [518/1000], Loss: 0.6935\n",
      "Epoch [519/1000], Loss: 0.6938\n",
      "Epoch [520/1000], Loss: 0.6938\n",
      "Epoch [521/1000], Loss: 0.7069\n",
      "Epoch [522/1000], Loss: 0.6938\n",
      "Epoch [523/1000], Loss: 0.6923\n",
      "Epoch [524/1000], Loss: 0.6935\n",
      "Epoch [525/1000], Loss: 0.6938\n",
      "Epoch [526/1000], Loss: 0.6938\n",
      "Epoch [527/1000], Loss: 0.6923\n",
      "Epoch [528/1000], Loss: 0.6934\n",
      "Epoch [529/1000], Loss: 0.6921\n",
      "Epoch [530/1000], Loss: 0.6938\n",
      "Epoch [531/1000], Loss: 0.6938\n",
      "Epoch [532/1000], Loss: 0.6938\n",
      "Epoch [533/1000], Loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [534/1000], Loss: 0.6922\n",
      "Epoch [535/1000], Loss: 0.6938\n",
      "Epoch [536/1000], Loss: 0.6922\n",
      "Epoch [537/1000], Loss: 0.6922\n",
      "Epoch [538/1000], Loss: 0.6922\n",
      "Epoch [539/1000], Loss: 0.6938\n",
      "Epoch [540/1000], Loss: 0.6922\n",
      "Epoch [541/1000], Loss: 0.6922\n",
      "Epoch [542/1000], Loss: 0.6921\n",
      "Epoch [543/1000], Loss: 0.6937\n",
      "Epoch [544/1000], Loss: 0.6937\n",
      "Epoch [545/1000], Loss: 0.6937\n",
      "Epoch [546/1000], Loss: 0.6935\n",
      "Epoch [547/1000], Loss: 0.6935\n",
      "Epoch [548/1000], Loss: 0.6937\n",
      "Epoch [549/1000], Loss: 0.6921\n",
      "Epoch [550/1000], Loss: 0.6937\n",
      "Epoch [551/1000], Loss: 0.6933\n",
      "Epoch [552/1000], Loss: 0.6921\n",
      "Epoch [553/1000], Loss: 0.6920\n",
      "Epoch [554/1000], Loss: 0.6937\n",
      "Epoch [555/1000], Loss: 0.6937\n",
      "Epoch [556/1000], Loss: 0.6919\n",
      "Epoch [557/1000], Loss: 0.6937\n",
      "Epoch [558/1000], Loss: 0.6920\n",
      "Epoch [559/1000], Loss: 0.6920\n",
      "Epoch [560/1000], Loss: 0.6934\n",
      "Epoch [561/1000], Loss: 0.6937\n",
      "Epoch [562/1000], Loss: 0.6920\n",
      "Epoch [563/1000], Loss: 0.6937\n",
      "Epoch [564/1000], Loss: 0.6937\n",
      "Epoch [565/1000], Loss: 0.6937\n",
      "Epoch [566/1000], Loss: 0.6919\n",
      "Epoch [567/1000], Loss: 0.6937\n",
      "Epoch [568/1000], Loss: 0.6937\n",
      "Epoch [569/1000], Loss: 0.6937\n",
      "Epoch [570/1000], Loss: 0.6919\n",
      "Epoch [571/1000], Loss: 0.6934\n",
      "Epoch [572/1000], Loss: 0.6919\n",
      "Epoch [573/1000], Loss: 0.6937\n",
      "Epoch [574/1000], Loss: 0.6917\n",
      "Epoch [575/1000], Loss: 0.6937\n",
      "Epoch [576/1000], Loss: 0.6936\n",
      "Epoch [577/1000], Loss: 0.6936\n",
      "Epoch [578/1000], Loss: 0.6936\n",
      "Epoch [579/1000], Loss: 0.6936\n",
      "Epoch [580/1000], Loss: 0.6936\n",
      "Epoch [581/1000], Loss: 0.6918\n",
      "Epoch [582/1000], Loss: 0.6936\n",
      "Epoch [583/1000], Loss: 0.6936\n",
      "Epoch [584/1000], Loss: 0.6918\n",
      "Epoch [585/1000], Loss: 0.7072\n",
      "Epoch [586/1000], Loss: 0.6936\n",
      "Epoch [587/1000], Loss: 0.6933\n",
      "Epoch [588/1000], Loss: 0.6936\n",
      "Epoch [589/1000], Loss: 0.6936\n",
      "Epoch [590/1000], Loss: 0.6917\n",
      "Epoch [591/1000], Loss: 0.6936\n",
      "Epoch [592/1000], Loss: 0.6936\n",
      "Epoch [593/1000], Loss: 0.6917\n",
      "Epoch [594/1000], Loss: 0.6936\n",
      "Epoch [595/1000], Loss: 0.6936\n",
      "Epoch [596/1000], Loss: 0.6936\n",
      "Epoch [597/1000], Loss: 0.6933\n",
      "Epoch [598/1000], Loss: 0.6915\n",
      "Epoch [599/1000], Loss: 0.7074\n",
      "Epoch [600/1000], Loss: 0.6917\n",
      "Epoch [601/1000], Loss: 0.6917\n",
      "Epoch [602/1000], Loss: 0.6936\n",
      "Epoch [603/1000], Loss: 0.6917\n",
      "Epoch [604/1000], Loss: 0.6935\n",
      "Epoch [605/1000], Loss: 0.6917\n",
      "Epoch [606/1000], Loss: 0.6932\n",
      "Epoch [607/1000], Loss: 0.6916\n",
      "Epoch [608/1000], Loss: 0.6915\n",
      "Epoch [609/1000], Loss: 0.6932\n",
      "Epoch [610/1000], Loss: 0.6916\n",
      "Epoch [611/1000], Loss: 0.6936\n",
      "Epoch [612/1000], Loss: 0.6936\n",
      "Epoch [613/1000], Loss: 0.6935\n",
      "Epoch [614/1000], Loss: 0.6936\n",
      "Epoch [615/1000], Loss: 0.6931\n",
      "Epoch [616/1000], Loss: 0.6931\n",
      "Epoch [617/1000], Loss: 0.6915\n",
      "Epoch [618/1000], Loss: 0.6936\n",
      "Epoch [619/1000], Loss: 0.6936\n",
      "Epoch [620/1000], Loss: 0.6936\n",
      "Epoch [621/1000], Loss: 0.7208\n",
      "Epoch [622/1000], Loss: 0.6935\n",
      "Epoch [623/1000], Loss: 0.6931\n",
      "Epoch [624/1000], Loss: 0.6931\n",
      "Epoch [625/1000], Loss: 0.6935\n",
      "Epoch [626/1000], Loss: 0.7068\n",
      "Epoch [627/1000], Loss: 0.6935\n",
      "Epoch [628/1000], Loss: 0.6936\n",
      "Epoch [629/1000], Loss: 0.6936\n",
      "Epoch [630/1000], Loss: 0.6930\n",
      "Epoch [631/1000], Loss: 0.6935\n",
      "Epoch [632/1000], Loss: 0.6937\n",
      "Epoch [633/1000], Loss: 0.6930\n",
      "Epoch [634/1000], Loss: 0.6915\n",
      "Epoch [635/1000], Loss: 0.6935\n",
      "Epoch [636/1000], Loss: 0.6915\n",
      "Epoch [637/1000], Loss: 0.6931\n",
      "Epoch [638/1000], Loss: 0.6931\n",
      "Epoch [639/1000], Loss: 0.6935\n",
      "Epoch [640/1000], Loss: 0.6936\n",
      "Epoch [641/1000], Loss: 0.6914\n",
      "Epoch [642/1000], Loss: 0.6935\n",
      "Epoch [643/1000], Loss: 0.6941\n",
      "Epoch [644/1000], Loss: 0.6915\n",
      "Epoch [645/1000], Loss: 0.6914\n",
      "Epoch [646/1000], Loss: 0.6912\n",
      "Epoch [647/1000], Loss: 0.6914\n",
      "Epoch [648/1000], Loss: 0.6935\n",
      "Epoch [649/1000], Loss: 0.6929\n",
      "Epoch [650/1000], Loss: 0.6935\n",
      "Epoch [651/1000], Loss: 0.6935\n",
      "Epoch [652/1000], Loss: 0.6930\n",
      "Epoch [653/1000], Loss: 0.6935\n",
      "Epoch [654/1000], Loss: 0.6911\n",
      "Epoch [655/1000], Loss: 0.6911\n",
      "Epoch [656/1000], Loss: 0.6935\n",
      "Epoch [657/1000], Loss: 0.6935\n",
      "Epoch [658/1000], Loss: 0.6935\n",
      "Epoch [659/1000], Loss: 0.6935\n",
      "Epoch [660/1000], Loss: 0.7481\n",
      "Epoch [661/1000], Loss: 0.6934\n",
      "Epoch [662/1000], Loss: 0.6935\n",
      "Epoch [663/1000], Loss: 0.6913\n",
      "Epoch [664/1000], Loss: 0.6935\n",
      "Epoch [665/1000], Loss: 0.6910\n",
      "Epoch [666/1000], Loss: 0.6929\n",
      "Epoch [667/1000], Loss: 0.6935\n",
      "Epoch [668/1000], Loss: 0.6935\n",
      "Epoch [669/1000], Loss: 0.6935\n",
      "Epoch [670/1000], Loss: 0.6934\n",
      "Epoch [671/1000], Loss: 0.6935\n",
      "Epoch [672/1000], Loss: 0.6935\n",
      "Epoch [673/1000], Loss: 0.6935\n",
      "Epoch [674/1000], Loss: 0.6935\n",
      "Epoch [675/1000], Loss: 0.6935\n",
      "Epoch [676/1000], Loss: 0.6912\n",
      "Epoch [677/1000], Loss: 0.6929\n",
      "Epoch [678/1000], Loss: 0.6929\n",
      "Epoch [679/1000], Loss: 0.6935\n",
      "Epoch [680/1000], Loss: 0.6913\n",
      "Epoch [681/1000], Loss: 0.6935\n",
      "Epoch [682/1000], Loss: 0.6929\n",
      "Epoch [683/1000], Loss: 0.6912\n",
      "Epoch [684/1000], Loss: 0.6929\n",
      "Epoch [685/1000], Loss: 0.6933\n",
      "Epoch [686/1000], Loss: 0.6912\n",
      "Epoch [687/1000], Loss: 0.6934\n",
      "Epoch [688/1000], Loss: 0.7069\n",
      "Epoch [689/1000], Loss: 0.6912\n",
      "Epoch [690/1000], Loss: 0.6935\n",
      "Epoch [691/1000], Loss: 0.6912\n",
      "Epoch [692/1000], Loss: 0.6912\n",
      "Epoch [693/1000], Loss: 0.6929\n",
      "Epoch [694/1000], Loss: 0.6911\n",
      "Epoch [695/1000], Loss: 0.6908\n",
      "Epoch [696/1000], Loss: 0.6911\n",
      "Epoch [697/1000], Loss: 0.6911\n",
      "Epoch [698/1000], Loss: 0.6934\n",
      "Epoch [699/1000], Loss: 0.6935\n",
      "Epoch [700/1000], Loss: 0.6935\n",
      "Epoch [701/1000], Loss: 0.6935\n",
      "Epoch [702/1000], Loss: 0.6928\n",
      "Epoch [703/1000], Loss: 0.6935\n",
      "Epoch [704/1000], Loss: 0.6935\n",
      "Epoch [705/1000], Loss: 0.6927\n",
      "Epoch [706/1000], Loss: 0.6908\n",
      "Epoch [707/1000], Loss: 0.6935\n",
      "Epoch [708/1000], Loss: 0.6911\n",
      "Epoch [709/1000], Loss: 0.6928\n",
      "Epoch [710/1000], Loss: 0.6928\n",
      "Epoch [711/1000], Loss: 0.6910\n",
      "Epoch [712/1000], Loss: 0.6910\n",
      "Epoch [713/1000], Loss: 0.6935\n",
      "Epoch [714/1000], Loss: 0.6927\n",
      "Epoch [715/1000], Loss: 0.6927\n",
      "Epoch [716/1000], Loss: 0.6926\n",
      "Epoch [717/1000], Loss: 0.6935\n",
      "Epoch [718/1000], Loss: 0.6935\n",
      "Epoch [719/1000], Loss: 0.6928\n",
      "Epoch [720/1000], Loss: 0.6927\n",
      "Epoch [721/1000], Loss: 0.6934\n",
      "Epoch [722/1000], Loss: 0.6932\n",
      "Epoch [723/1000], Loss: 0.6934\n",
      "Epoch [724/1000], Loss: 0.6932\n",
      "Epoch [725/1000], Loss: 0.6909\n",
      "Epoch [726/1000], Loss: 0.6926\n",
      "Epoch [727/1000], Loss: 0.6909\n",
      "Epoch [728/1000], Loss: 0.6910\n",
      "Epoch [729/1000], Loss: 0.6934\n",
      "Epoch [730/1000], Loss: 0.6934\n",
      "Epoch [731/1000], Loss: 0.6946\n",
      "Epoch [732/1000], Loss: 0.6926\n",
      "Epoch [733/1000], Loss: 0.6926\n",
      "Epoch [734/1000], Loss: 0.6934\n",
      "Epoch [735/1000], Loss: 0.6935\n",
      "Epoch [736/1000], Loss: 0.6926\n",
      "Epoch [737/1000], Loss: 0.6932\n",
      "Epoch [738/1000], Loss: 0.6908\n",
      "Epoch [739/1000], Loss: 0.6945\n",
      "Epoch [740/1000], Loss: 0.6926\n",
      "Epoch [741/1000], Loss: 0.7045\n",
      "Epoch [742/1000], Loss: 0.6934\n",
      "Epoch [743/1000], Loss: 0.6909\n",
      "Epoch [744/1000], Loss: 0.6905\n",
      "Epoch [745/1000], Loss: 0.6926\n",
      "Epoch [746/1000], Loss: 0.6934\n",
      "Epoch [747/1000], Loss: 0.6926\n",
      "Epoch [748/1000], Loss: 0.6932\n",
      "Epoch [749/1000], Loss: 0.6934\n",
      "Epoch [750/1000], Loss: 0.6908\n",
      "Epoch [751/1000], Loss: 0.6932\n",
      "Epoch [752/1000], Loss: 0.6934\n",
      "Epoch [753/1000], Loss: 0.6908\n",
      "Epoch [754/1000], Loss: 0.6926\n",
      "Epoch [755/1000], Loss: 0.6934\n",
      "Epoch [756/1000], Loss: 0.6934\n",
      "Epoch [757/1000], Loss: 0.6908\n",
      "Epoch [758/1000], Loss: 0.6908\n",
      "Epoch [759/1000], Loss: 0.6908\n",
      "Epoch [760/1000], Loss: 0.6925\n",
      "Epoch [761/1000], Loss: 0.6908\n",
      "Epoch [762/1000], Loss: 0.6907\n",
      "Epoch [763/1000], Loss: 0.6932\n",
      "Epoch [764/1000], Loss: 0.6908\n",
      "Epoch [765/1000], Loss: 0.6933\n",
      "Epoch [766/1000], Loss: 0.6925\n",
      "Epoch [767/1000], Loss: 0.6907\n",
      "Epoch [768/1000], Loss: 0.6933\n",
      "Epoch [769/1000], Loss: 0.6932\n",
      "Epoch [770/1000], Loss: 0.6933\n",
      "Epoch [771/1000], Loss: 0.6907\n",
      "Epoch [772/1000], Loss: 0.6933\n",
      "Epoch [773/1000], Loss: 0.6929\n",
      "Epoch [774/1000], Loss: 0.6902\n",
      "Epoch [775/1000], Loss: 0.6929\n",
      "Epoch [776/1000], Loss: 0.6924\n",
      "Epoch [777/1000], Loss: 0.6924\n",
      "Epoch [778/1000], Loss: 0.6934\n",
      "Epoch [779/1000], Loss: 0.6924\n",
      "Epoch [780/1000], Loss: 0.6902\n",
      "Epoch [781/1000], Loss: 0.6924\n",
      "Epoch [782/1000], Loss: 0.6924\n",
      "Epoch [783/1000], Loss: 0.6933\n",
      "Epoch [784/1000], Loss: 0.6923\n",
      "Epoch [785/1000], Loss: 0.6923\n",
      "Epoch [786/1000], Loss: 0.6934\n",
      "Epoch [787/1000], Loss: 0.6907\n",
      "Epoch [788/1000], Loss: 0.6933\n",
      "Epoch [789/1000], Loss: 0.6900\n",
      "Epoch [790/1000], Loss: 0.7201\n",
      "Epoch [791/1000], Loss: 0.6906\n",
      "Epoch [792/1000], Loss: 0.6926\n",
      "Epoch [793/1000], Loss: 0.6922\n",
      "Epoch [794/1000], Loss: 0.6935\n",
      "Epoch [795/1000], Loss: 0.6934\n",
      "Epoch [796/1000], Loss: 0.6933\n",
      "Epoch [797/1000], Loss: 0.6941\n",
      "Epoch [798/1000], Loss: 0.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [799/1000], Loss: 0.6924\n",
      "Epoch [800/1000], Loss: 0.6906\n",
      "Epoch [801/1000], Loss: 0.6935\n",
      "Epoch [802/1000], Loss: 0.6935\n",
      "Epoch [803/1000], Loss: 0.6934\n",
      "Epoch [804/1000], Loss: 0.6923\n",
      "Epoch [805/1000], Loss: 0.6937\n",
      "Epoch [806/1000], Loss: 0.6923\n",
      "Epoch [807/1000], Loss: 0.6929\n",
      "Epoch [808/1000], Loss: 0.6934\n",
      "Epoch [809/1000], Loss: 0.6935\n",
      "Epoch [810/1000], Loss: 0.6905\n",
      "Epoch [811/1000], Loss: 0.6933\n",
      "Epoch [812/1000], Loss: 0.6938\n",
      "Epoch [813/1000], Loss: 0.6906\n",
      "Epoch [814/1000], Loss: 0.6905\n",
      "Epoch [815/1000], Loss: 0.6922\n",
      "Epoch [816/1000], Loss: 0.6934\n",
      "Epoch [817/1000], Loss: 0.6934\n",
      "Epoch [818/1000], Loss: 0.6906\n",
      "Epoch [819/1000], Loss: 0.6933\n",
      "Epoch [820/1000], Loss: 0.6928\n",
      "Epoch [821/1000], Loss: 0.6904\n",
      "Epoch [822/1000], Loss: 0.6933\n",
      "Epoch [823/1000], Loss: 0.6904\n",
      "Epoch [824/1000], Loss: 0.6933\n",
      "Epoch [825/1000], Loss: 0.6931\n",
      "Epoch [826/1000], Loss: 0.6932\n",
      "Epoch [827/1000], Loss: 0.6904\n",
      "Epoch [828/1000], Loss: 0.6932\n",
      "Epoch [829/1000], Loss: 0.6933\n",
      "Epoch [830/1000], Loss: 0.6933\n",
      "Epoch [831/1000], Loss: 0.6933\n",
      "Epoch [832/1000], Loss: 0.6933\n",
      "Epoch [833/1000], Loss: 0.6933\n",
      "Epoch [834/1000], Loss: 0.6905\n",
      "Epoch [835/1000], Loss: 0.6933\n",
      "Epoch [836/1000], Loss: 0.6932\n",
      "Epoch [837/1000], Loss: 0.7039\n",
      "Epoch [838/1000], Loss: 0.6933\n",
      "Epoch [839/1000], Loss: 0.6932\n",
      "Epoch [840/1000], Loss: 0.6927\n",
      "Epoch [841/1000], Loss: 0.6921\n",
      "Epoch [842/1000], Loss: 0.7052\n",
      "Epoch [843/1000], Loss: 0.6934\n",
      "Epoch [844/1000], Loss: 0.6933\n",
      "Epoch [845/1000], Loss: 0.6898\n",
      "Epoch [846/1000], Loss: 0.6921\n",
      "Epoch [847/1000], Loss: 0.6922\n",
      "Epoch [848/1000], Loss: 0.6927\n",
      "Epoch [849/1000], Loss: 0.6898\n",
      "Epoch [850/1000], Loss: 0.6934\n",
      "Epoch [851/1000], Loss: 0.6932\n",
      "Epoch [852/1000], Loss: 0.6904\n",
      "Epoch [853/1000], Loss: 0.6904\n",
      "Epoch [854/1000], Loss: 0.6944\n",
      "Epoch [855/1000], Loss: 0.6904\n",
      "Epoch [856/1000], Loss: 0.6920\n",
      "Epoch [857/1000], Loss: 0.6934\n",
      "Epoch [858/1000], Loss: 0.6934\n",
      "Epoch [859/1000], Loss: 0.6903\n",
      "Epoch [860/1000], Loss: 0.6933\n",
      "Epoch [861/1000], Loss: 0.6936\n",
      "Epoch [862/1000], Loss: 0.6904\n",
      "Epoch [863/1000], Loss: 0.6904\n",
      "Epoch [864/1000], Loss: 0.6918\n",
      "Epoch [865/1000], Loss: 0.6934\n",
      "Epoch [866/1000], Loss: 0.6919\n",
      "Epoch [867/1000], Loss: 0.6904\n",
      "Epoch [868/1000], Loss: 0.6895\n",
      "Epoch [869/1000], Loss: 0.6940\n",
      "Epoch [870/1000], Loss: 0.6919\n",
      "Epoch [871/1000], Loss: 0.6933\n",
      "Epoch [872/1000], Loss: 0.6932\n",
      "Epoch [873/1000], Loss: 0.6905\n",
      "Epoch [874/1000], Loss: 0.6932\n",
      "Epoch [875/1000], Loss: 0.6933\n",
      "Epoch [876/1000], Loss: 0.6919\n",
      "Epoch [877/1000], Loss: 0.6895\n",
      "Epoch [878/1000], Loss: 0.6903\n",
      "Epoch [879/1000], Loss: 0.6919\n",
      "Epoch [880/1000], Loss: 0.6932\n",
      "Epoch [881/1000], Loss: 0.6917\n",
      "Epoch [882/1000], Loss: 0.6916\n",
      "Epoch [883/1000], Loss: 0.6903\n",
      "Epoch [884/1000], Loss: 0.6900\n",
      "Epoch [885/1000], Loss: 0.6930\n",
      "Epoch [886/1000], Loss: 0.6929\n",
      "Epoch [887/1000], Loss: 0.6916\n",
      "Epoch [888/1000], Loss: 0.6933\n",
      "Epoch [889/1000], Loss: 0.6933\n",
      "Epoch [890/1000], Loss: 0.6930\n",
      "Epoch [891/1000], Loss: 0.6892\n",
      "Epoch [892/1000], Loss: 0.6900\n",
      "Epoch [893/1000], Loss: 0.6893\n",
      "Epoch [894/1000], Loss: 0.6931\n",
      "Epoch [895/1000], Loss: 0.6931\n",
      "Epoch [896/1000], Loss: 0.6934\n",
      "Epoch [897/1000], Loss: 0.6915\n",
      "Epoch [898/1000], Loss: 0.6933\n",
      "Epoch [899/1000], Loss: 0.6917\n",
      "Epoch [900/1000], Loss: 0.6928\n",
      "Epoch [901/1000], Loss: 0.6914\n",
      "Epoch [902/1000], Loss: 0.6903\n",
      "Epoch [903/1000], Loss: 0.6901\n",
      "Epoch [904/1000], Loss: 0.6916\n",
      "Epoch [905/1000], Loss: 0.6891\n",
      "Epoch [906/1000], Loss: 0.6903\n",
      "Epoch [907/1000], Loss: 0.6914\n",
      "Epoch [908/1000], Loss: 0.6913\n",
      "Epoch [909/1000], Loss: 0.6902\n",
      "Epoch [910/1000], Loss: 0.6933\n",
      "Epoch [911/1000], Loss: 0.6911\n",
      "Epoch [912/1000], Loss: 0.6902\n",
      "Epoch [913/1000], Loss: 0.6927\n",
      "Epoch [914/1000], Loss: 0.6912\n",
      "Epoch [915/1000], Loss: 0.6933\n",
      "Epoch [916/1000], Loss: 0.6891\n",
      "Epoch [917/1000], Loss: 0.6933\n",
      "Epoch [918/1000], Loss: 0.6902\n",
      "Epoch [919/1000], Loss: 0.6932\n",
      "Epoch [920/1000], Loss: 0.6926\n",
      "Epoch [921/1000], Loss: 0.6902\n",
      "Epoch [922/1000], Loss: 0.6927\n",
      "Epoch [923/1000], Loss: 0.7051\n",
      "Epoch [924/1000], Loss: 0.6902\n",
      "Epoch [925/1000], Loss: 0.6930\n",
      "Epoch [926/1000], Loss: 0.6926\n",
      "Epoch [927/1000], Loss: 0.6911\n",
      "Epoch [928/1000], Loss: 0.6898\n",
      "Epoch [929/1000], Loss: 0.6924\n",
      "Epoch [930/1000], Loss: 0.6933\n",
      "Epoch [931/1000], Loss: 0.6926\n",
      "Epoch [932/1000], Loss: 0.6909\n",
      "Epoch [933/1000], Loss: 0.6927\n",
      "Epoch [934/1000], Loss: 0.6933\n",
      "Epoch [935/1000], Loss: 0.6913\n",
      "Epoch [936/1000], Loss: 0.6908\n",
      "Epoch [937/1000], Loss: 0.6933\n",
      "Epoch [938/1000], Loss: 0.6912\n",
      "Epoch [939/1000], Loss: 0.6909\n",
      "Epoch [940/1000], Loss: 0.6928\n",
      "Epoch [941/1000], Loss: 0.6907\n",
      "Epoch [942/1000], Loss: 0.6902\n",
      "Epoch [943/1000], Loss: 0.6910\n",
      "Epoch [944/1000], Loss: 0.6906\n",
      "Epoch [945/1000], Loss: 0.6887\n",
      "Epoch [946/1000], Loss: 0.6906\n",
      "Epoch [947/1000], Loss: 0.6902\n",
      "Epoch [948/1000], Loss: 0.6902\n",
      "Epoch [949/1000], Loss: 0.6936\n",
      "Epoch [950/1000], Loss: 0.6933\n",
      "Epoch [951/1000], Loss: 0.6909\n",
      "Epoch [952/1000], Loss: 0.6934\n",
      "Epoch [953/1000], Loss: 0.6906\n",
      "Epoch [954/1000], Loss: 0.6930\n",
      "Epoch [955/1000], Loss: 0.6909\n",
      "Epoch [956/1000], Loss: 0.6880\n",
      "Epoch [957/1000], Loss: 0.6905\n",
      "Epoch [958/1000], Loss: 0.6923\n",
      "Epoch [959/1000], Loss: 0.6882\n",
      "Epoch [960/1000], Loss: 0.6926\n",
      "Epoch [961/1000], Loss: 0.6903\n",
      "Epoch [962/1000], Loss: 0.6883\n",
      "Epoch [963/1000], Loss: 0.6932\n",
      "Epoch [964/1000], Loss: 0.6894\n",
      "Epoch [965/1000], Loss: 0.6896\n",
      "Epoch [966/1000], Loss: 0.6919\n",
      "Epoch [967/1000], Loss: 0.6891\n",
      "Epoch [968/1000], Loss: 0.6900\n",
      "Epoch [969/1000], Loss: 0.6905\n",
      "Epoch [970/1000], Loss: 0.6901\n",
      "Epoch [971/1000], Loss: 0.6898\n",
      "Epoch [972/1000], Loss: 0.6917\n",
      "Epoch [973/1000], Loss: 0.6932\n",
      "Epoch [974/1000], Loss: 0.6916\n",
      "Epoch [975/1000], Loss: 0.6933\n",
      "Epoch [976/1000], Loss: 0.6941\n",
      "Epoch [977/1000], Loss: 0.6905\n",
      "Epoch [978/1000], Loss: 0.6935\n",
      "Epoch [979/1000], Loss: 0.6908\n",
      "Epoch [980/1000], Loss: 0.6930\n",
      "Epoch [981/1000], Loss: 0.6880\n",
      "Epoch [982/1000], Loss: 0.6921\n",
      "Epoch [983/1000], Loss: 0.6932\n",
      "Epoch [984/1000], Loss: 0.6889\n",
      "Epoch [985/1000], Loss: 0.6900\n",
      "Epoch [986/1000], Loss: 0.6896\n",
      "Epoch [987/1000], Loss: 0.6871\n",
      "Epoch [988/1000], Loss: 0.6918\n",
      "Epoch [989/1000], Loss: 0.6934\n",
      "Epoch [990/1000], Loss: 0.6915\n",
      "Epoch [991/1000], Loss: 0.6933\n",
      "Epoch [992/1000], Loss: 0.6871\n",
      "Epoch [993/1000], Loss: 0.6889\n",
      "Epoch [994/1000], Loss: 0.6884\n",
      "Epoch [995/1000], Loss: 0.6883\n",
      "Epoch [996/1000], Loss: 0.6880\n",
      "Epoch [997/1000], Loss: 0.6884\n",
      "Epoch [998/1000], Loss: 0.6932\n",
      "Epoch [999/1000], Loss: 0.6877\n",
      "Epoch [1000/1000], Loss: 0.6883\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for idx,training_data in enumerate(training_sets):\n",
    "    model_rnn = SeqPredictorRNN(101,training_data.shape[0],150,1)\n",
    "    criterion = nn.KLDivLoss(reduction = \"batchmean\")\n",
    "    optimizer = optim.Adam(model_rnn.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model_rnn(training_data[:,:-1],1.0)\n",
    "        loss = criterion(output, training_data[:,-1])\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff815e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1000),[los.item() for los in losses])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"RNN Loss VS Epoch for Training batch size 1500\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41d7d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average(over batch) no. of Wrong predictions in set - 0 : 51.3000%\n",
      "Average(over batch) no. of Wrong predictions in set - 1 : 50.2667%\n",
      "Average(over batch) no. of Wrong predictions in set - 2 : 50.7667%\n",
      "Average(over batch) no. of Wrong predictions in set - 3 : 51.1000%\n",
      "Average(over batch) no. of Wrong predictions in set - 4 : 48.9000%\n",
      "Average(over batch) no. of Wrong predictions in set - 5 : 49.7333%\n",
      "Average(over batch) no. of Wrong predictions in set - 6 : 49.5000%\n",
      "Average(over batch) no. of Wrong predictions in set - 7 : 50.7667%\n",
      "Average(over batch) no. of Wrong predictions in set - 8 : 48.5000%\n",
      "Average(over batch) no. of Wrong predictions in set - 9 : 50.2000%\n"
     ]
    }
   ],
   "source": [
    "for idx,test in enumerate(test_datasets):\n",
    "    model_rnn.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model_rnn(test[:,:-1],0.0)\n",
    "        predictions = torch.argmax(output,dim=1)\n",
    "        actual = torch.argmax(test[:,-1],dim=1)\n",
    "        wrong_pred = torch.where(predictions != actual,1.0,0.0)\n",
    "        print(f'Average(over batch) no. of Wrong predictions in set - {idx} : {100*(torch.sum(wrong_pred) / wrong_pred.shape[0]):.4f}%')\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2ac52",
   "metadata": {},
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43225e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 4.6221\n",
      "Epoch [2/1000], Loss: 4.5895\n",
      "Epoch [3/1000], Loss: 4.5555\n",
      "Epoch [4/1000], Loss: 4.5193\n",
      "Epoch [5/1000], Loss: 4.4792\n",
      "Epoch [6/1000], Loss: 4.4333\n",
      "Epoch [7/1000], Loss: 4.3787\n",
      "Epoch [8/1000], Loss: 4.3110\n",
      "Epoch [9/1000], Loss: 4.2224\n",
      "Epoch [10/1000], Loss: 4.0979\n",
      "Epoch [11/1000], Loss: 3.9022\n",
      "Epoch [12/1000], Loss: 3.5383\n",
      "Epoch [13/1000], Loss: 2.8607\n",
      "Epoch [14/1000], Loss: 2.2399\n",
      "Epoch [15/1000], Loss: 1.8256\n",
      "Epoch [16/1000], Loss: 1.5251\n",
      "Epoch [17/1000], Loss: 1.2965\n",
      "Epoch [18/1000], Loss: 1.1233\n",
      "Epoch [19/1000], Loss: 0.9957\n",
      "Epoch [20/1000], Loss: 0.9046\n",
      "Epoch [21/1000], Loss: 0.8411\n",
      "Epoch [22/1000], Loss: 0.7976\n",
      "Epoch [23/1000], Loss: 0.7679\n",
      "Epoch [24/1000], Loss: 0.7475\n",
      "Epoch [25/1000], Loss: 0.7334\n",
      "Epoch [26/1000], Loss: 0.7234\n",
      "Epoch [27/1000], Loss: 0.7163\n",
      "Epoch [28/1000], Loss: 0.7110\n",
      "Epoch [29/1000], Loss: 0.7072\n",
      "Epoch [30/1000], Loss: 0.7043\n",
      "Epoch [31/1000], Loss: 0.7022\n",
      "Epoch [32/1000], Loss: 0.7007\n",
      "Epoch [33/1000], Loss: 0.6995\n",
      "Epoch [34/1000], Loss: 0.6986\n",
      "Epoch [35/1000], Loss: 0.6979\n",
      "Epoch [36/1000], Loss: 0.6972\n",
      "Epoch [37/1000], Loss: 0.6966\n",
      "Epoch [38/1000], Loss: 0.6962\n",
      "Epoch [39/1000], Loss: 0.6958\n",
      "Epoch [40/1000], Loss: 0.6955\n",
      "Epoch [41/1000], Loss: 0.6953\n",
      "Epoch [42/1000], Loss: 0.6951\n",
      "Epoch [43/1000], Loss: 0.6950\n",
      "Epoch [44/1000], Loss: 0.6948\n",
      "Epoch [45/1000], Loss: 0.6947\n",
      "Epoch [46/1000], Loss: 0.6945\n",
      "Epoch [47/1000], Loss: 0.6944\n",
      "Epoch [48/1000], Loss: 0.6943\n",
      "Epoch [49/1000], Loss: 0.6943\n",
      "Epoch [50/1000], Loss: 0.6942\n",
      "Epoch [51/1000], Loss: 0.6941\n",
      "Epoch [52/1000], Loss: 0.6941\n",
      "Epoch [53/1000], Loss: 0.6940\n",
      "Epoch [54/1000], Loss: 0.6939\n",
      "Epoch [55/1000], Loss: 0.6939\n",
      "Epoch [56/1000], Loss: 0.6939\n",
      "Epoch [57/1000], Loss: 0.6938\n",
      "Epoch [58/1000], Loss: 0.6938\n",
      "Epoch [59/1000], Loss: 0.6937\n",
      "Epoch [60/1000], Loss: 0.6937\n",
      "Epoch [61/1000], Loss: 0.6937\n",
      "Epoch [62/1000], Loss: 0.6936\n",
      "Epoch [63/1000], Loss: 0.6936\n",
      "Epoch [64/1000], Loss: 0.6936\n",
      "Epoch [65/1000], Loss: 0.6936\n",
      "Epoch [66/1000], Loss: 0.6935\n",
      "Epoch [67/1000], Loss: 0.6935\n",
      "Epoch [68/1000], Loss: 0.6935\n",
      "Epoch [69/1000], Loss: 0.6934\n",
      "Epoch [70/1000], Loss: 0.6934\n",
      "Epoch [71/1000], Loss: 0.6934\n",
      "Epoch [72/1000], Loss: 0.6933\n",
      "Epoch [73/1000], Loss: 0.6933\n",
      "Epoch [74/1000], Loss: 0.6933\n",
      "Epoch [75/1000], Loss: 0.6933\n",
      "Epoch [76/1000], Loss: 0.6932\n",
      "Epoch [77/1000], Loss: 0.6932\n",
      "Epoch [78/1000], Loss: 0.6932\n",
      "Epoch [79/1000], Loss: 0.6932\n",
      "Epoch [80/1000], Loss: 0.6931\n",
      "Epoch [81/1000], Loss: 0.6931\n",
      "Epoch [82/1000], Loss: 0.6931\n",
      "Epoch [83/1000], Loss: 0.6931\n",
      "Epoch [84/1000], Loss: 0.6930\n",
      "Epoch [85/1000], Loss: 0.6930\n",
      "Epoch [86/1000], Loss: 0.6930\n",
      "Epoch [87/1000], Loss: 0.6930\n",
      "Epoch [88/1000], Loss: 0.6929\n",
      "Epoch [89/1000], Loss: 0.6929\n",
      "Epoch [90/1000], Loss: 0.6929\n",
      "Epoch [91/1000], Loss: 0.6929\n",
      "Epoch [92/1000], Loss: 0.6928\n",
      "Epoch [93/1000], Loss: 0.6928\n",
      "Epoch [94/1000], Loss: 0.6928\n",
      "Epoch [95/1000], Loss: 0.6928\n",
      "Epoch [96/1000], Loss: 0.6927\n",
      "Epoch [97/1000], Loss: 0.6927\n",
      "Epoch [98/1000], Loss: 0.6927\n",
      "Epoch [99/1000], Loss: 0.6926\n",
      "Epoch [100/1000], Loss: 0.6926\n",
      "Epoch [101/1000], Loss: 0.6926\n",
      "Epoch [102/1000], Loss: 0.6926\n",
      "Epoch [103/1000], Loss: 0.6925\n",
      "Epoch [104/1000], Loss: 0.6925\n",
      "Epoch [105/1000], Loss: 0.6925\n",
      "Epoch [106/1000], Loss: 0.6924\n",
      "Epoch [107/1000], Loss: 0.6924\n",
      "Epoch [108/1000], Loss: 0.6924\n",
      "Epoch [109/1000], Loss: 0.6924\n",
      "Epoch [110/1000], Loss: 0.6923\n",
      "Epoch [111/1000], Loss: 0.6923\n",
      "Epoch [112/1000], Loss: 0.6923\n",
      "Epoch [113/1000], Loss: 0.6922\n",
      "Epoch [114/1000], Loss: 0.6922\n",
      "Epoch [115/1000], Loss: 0.6922\n",
      "Epoch [116/1000], Loss: 0.6921\n",
      "Epoch [117/1000], Loss: 0.6921\n",
      "Epoch [118/1000], Loss: 0.6921\n",
      "Epoch [119/1000], Loss: 0.6921\n",
      "Epoch [120/1000], Loss: 0.6920\n",
      "Epoch [121/1000], Loss: 0.6920\n",
      "Epoch [122/1000], Loss: 0.6920\n",
      "Epoch [123/1000], Loss: 0.6919\n",
      "Epoch [124/1000], Loss: 0.6919\n",
      "Epoch [125/1000], Loss: 0.6919\n",
      "Epoch [126/1000], Loss: 0.6918\n",
      "Epoch [127/1000], Loss: 0.6918\n",
      "Epoch [128/1000], Loss: 0.6918\n",
      "Epoch [129/1000], Loss: 0.6917\n",
      "Epoch [130/1000], Loss: 0.6917\n",
      "Epoch [131/1000], Loss: 0.6917\n",
      "Epoch [132/1000], Loss: 0.6916\n",
      "Epoch [133/1000], Loss: 0.6916\n",
      "Epoch [134/1000], Loss: 0.6916\n",
      "Epoch [135/1000], Loss: 0.6916\n",
      "Epoch [136/1000], Loss: 0.6915\n",
      "Epoch [137/1000], Loss: 0.6915\n",
      "Epoch [138/1000], Loss: 0.6915\n",
      "Epoch [139/1000], Loss: 0.6914\n",
      "Epoch [140/1000], Loss: 0.6914\n",
      "Epoch [141/1000], Loss: 0.6914\n",
      "Epoch [142/1000], Loss: 0.6913\n",
      "Epoch [143/1000], Loss: 0.6913\n",
      "Epoch [144/1000], Loss: 0.6912\n",
      "Epoch [145/1000], Loss: 0.6912\n",
      "Epoch [146/1000], Loss: 0.6911\n",
      "Epoch [147/1000], Loss: 0.6911\n",
      "Epoch [148/1000], Loss: 0.6911\n",
      "Epoch [149/1000], Loss: 0.6912\n",
      "Epoch [150/1000], Loss: 0.6911\n",
      "Epoch [151/1000], Loss: 0.6910\n",
      "Epoch [152/1000], Loss: 0.6909\n",
      "Epoch [153/1000], Loss: 0.6910\n",
      "Epoch [154/1000], Loss: 0.6909\n",
      "Epoch [155/1000], Loss: 0.6908\n",
      "Epoch [156/1000], Loss: 0.6908\n",
      "Epoch [157/1000], Loss: 0.6908\n",
      "Epoch [158/1000], Loss: 0.6907\n",
      "Epoch [159/1000], Loss: 0.6906\n",
      "Epoch [160/1000], Loss: 0.6905\n",
      "Epoch [161/1000], Loss: 0.6904\n",
      "Epoch [162/1000], Loss: 0.6910\n",
      "Epoch [163/1000], Loss: 0.6948\n",
      "Epoch [164/1000], Loss: 0.6920\n",
      "Epoch [165/1000], Loss: 0.6931\n",
      "Epoch [166/1000], Loss: 0.6906\n",
      "Epoch [167/1000], Loss: 0.6912\n",
      "Epoch [168/1000], Loss: 0.6922\n",
      "Epoch [169/1000], Loss: 0.6912\n",
      "Epoch [170/1000], Loss: 0.6906\n",
      "Epoch [171/1000], Loss: 0.6911\n",
      "Epoch [172/1000], Loss: 0.6916\n",
      "Epoch [173/1000], Loss: 0.6912\n",
      "Epoch [174/1000], Loss: 0.6907\n",
      "Epoch [175/1000], Loss: 0.6908\n",
      "Epoch [176/1000], Loss: 0.6912\n",
      "Epoch [177/1000], Loss: 0.6911\n",
      "Epoch [178/1000], Loss: 0.6908\n",
      "Epoch [179/1000], Loss: 0.6907\n",
      "Epoch [180/1000], Loss: 0.6908\n",
      "Epoch [181/1000], Loss: 0.6909\n",
      "Epoch [182/1000], Loss: 0.6908\n",
      "Epoch [183/1000], Loss: 0.6906\n",
      "Epoch [184/1000], Loss: 0.6906\n",
      "Epoch [185/1000], Loss: 0.6907\n",
      "Epoch [186/1000], Loss: 0.6906\n",
      "Epoch [187/1000], Loss: 0.6905\n",
      "Epoch [188/1000], Loss: 0.6904\n",
      "Epoch [189/1000], Loss: 0.6904\n",
      "Epoch [190/1000], Loss: 0.6904\n",
      "Epoch [191/1000], Loss: 0.6903\n",
      "Epoch [192/1000], Loss: 0.6902\n",
      "Epoch [193/1000], Loss: 0.6902\n",
      "Epoch [194/1000], Loss: 0.6902\n",
      "Epoch [195/1000], Loss: 0.6901\n",
      "Epoch [196/1000], Loss: 0.6900\n",
      "Epoch [197/1000], Loss: 0.6900\n",
      "Epoch [198/1000], Loss: 0.6899\n",
      "Epoch [199/1000], Loss: 0.6898\n",
      "Epoch [200/1000], Loss: 0.6898\n",
      "Epoch [201/1000], Loss: 0.6898\n",
      "Epoch [202/1000], Loss: 0.6897\n",
      "Epoch [203/1000], Loss: 0.6896\n",
      "Epoch [204/1000], Loss: 0.6896\n",
      "Epoch [205/1000], Loss: 0.6895\n",
      "Epoch [206/1000], Loss: 0.6894\n",
      "Epoch [207/1000], Loss: 0.6894\n",
      "Epoch [208/1000], Loss: 0.6893\n",
      "Epoch [209/1000], Loss: 0.6892\n",
      "Epoch [210/1000], Loss: 0.6891\n",
      "Epoch [211/1000], Loss: 0.6890\n",
      "Epoch [212/1000], Loss: 0.6889\n",
      "Epoch [213/1000], Loss: 0.6889\n",
      "Epoch [214/1000], Loss: 0.6889\n",
      "Epoch [215/1000], Loss: 0.6898\n",
      "Epoch [216/1000], Loss: 0.6952\n",
      "Epoch [217/1000], Loss: 0.6884\n",
      "Epoch [218/1000], Loss: 0.6950\n",
      "Epoch [219/1000], Loss: 0.6906\n",
      "Epoch [220/1000], Loss: 0.6929\n",
      "Epoch [221/1000], Loss: 0.6903\n",
      "Epoch [222/1000], Loss: 0.6898\n",
      "Epoch [223/1000], Loss: 0.6918\n",
      "Epoch [224/1000], Loss: 0.6918\n",
      "Epoch [225/1000], Loss: 0.6902\n",
      "Epoch [226/1000], Loss: 0.6899\n",
      "Epoch [227/1000], Loss: 0.6908\n",
      "Epoch [228/1000], Loss: 0.6912\n",
      "Epoch [229/1000], Loss: 0.6905\n",
      "Epoch [230/1000], Loss: 0.6899\n",
      "Epoch [231/1000], Loss: 0.6901\n",
      "Epoch [232/1000], Loss: 0.6906\n",
      "Epoch [233/1000], Loss: 0.6905\n",
      "Epoch [234/1000], Loss: 0.6900\n",
      "Epoch [235/1000], Loss: 0.6898\n",
      "Epoch [236/1000], Loss: 0.6901\n",
      "Epoch [237/1000], Loss: 0.6903\n",
      "Epoch [238/1000], Loss: 0.6900\n",
      "Epoch [239/1000], Loss: 0.6897\n",
      "Epoch [240/1000], Loss: 0.6897\n",
      "Epoch [241/1000], Loss: 0.6899\n",
      "Epoch [242/1000], Loss: 0.6899\n",
      "Epoch [243/1000], Loss: 0.6897\n",
      "Epoch [244/1000], Loss: 0.6895\n",
      "Epoch [245/1000], Loss: 0.6896\n",
      "Epoch [246/1000], Loss: 0.6896\n",
      "Epoch [247/1000], Loss: 0.6895\n",
      "Epoch [248/1000], Loss: 0.6894\n",
      "Epoch [249/1000], Loss: 0.6894\n",
      "Epoch [250/1000], Loss: 0.6894\n",
      "Epoch [251/1000], Loss: 0.6894\n",
      "Epoch [252/1000], Loss: 0.6892\n",
      "Epoch [253/1000], Loss: 0.6892\n",
      "Epoch [254/1000], Loss: 0.6892\n",
      "Epoch [255/1000], Loss: 0.6892\n",
      "Epoch [256/1000], Loss: 0.6890\n",
      "Epoch [257/1000], Loss: 0.6890\n",
      "Epoch [258/1000], Loss: 0.6890\n",
      "Epoch [259/1000], Loss: 0.6889\n",
      "Epoch [260/1000], Loss: 0.6888\n",
      "Epoch [261/1000], Loss: 0.6888\n",
      "Epoch [262/1000], Loss: 0.6887\n",
      "Epoch [263/1000], Loss: 0.6886\n",
      "Epoch [264/1000], Loss: 0.6885\n",
      "Epoch [265/1000], Loss: 0.6885\n",
      "Epoch [266/1000], Loss: 0.6883\n",
      "Epoch [267/1000], Loss: 0.6882\n",
      "Epoch [268/1000], Loss: 0.6881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [269/1000], Loss: 0.6879\n",
      "Epoch [270/1000], Loss: 0.6878\n",
      "Epoch [271/1000], Loss: 0.6876\n",
      "Epoch [272/1000], Loss: 0.6875\n",
      "Epoch [273/1000], Loss: 0.6873\n",
      "Epoch [274/1000], Loss: 0.6870\n",
      "Epoch [275/1000], Loss: 0.6868\n",
      "Epoch [276/1000], Loss: 0.6868\n",
      "Epoch [277/1000], Loss: 0.6890\n",
      "Epoch [278/1000], Loss: 0.7036\n",
      "Epoch [279/1000], Loss: 0.6927\n",
      "Epoch [280/1000], Loss: 0.6865\n",
      "Epoch [281/1000], Loss: 0.6945\n",
      "Epoch [282/1000], Loss: 0.6871\n",
      "Epoch [283/1000], Loss: 0.6903\n",
      "Epoch [284/1000], Loss: 0.6868\n",
      "Epoch [285/1000], Loss: 0.6894\n",
      "Epoch [286/1000], Loss: 0.6873\n",
      "Epoch [287/1000], Loss: 0.6880\n",
      "Epoch [288/1000], Loss: 0.6886\n",
      "Epoch [289/1000], Loss: 0.6874\n",
      "Epoch [290/1000], Loss: 0.6879\n",
      "Epoch [291/1000], Loss: 0.6883\n",
      "Epoch [292/1000], Loss: 0.6875\n",
      "Epoch [293/1000], Loss: 0.6877\n",
      "Epoch [294/1000], Loss: 0.6880\n",
      "Epoch [295/1000], Loss: 0.6874\n",
      "Epoch [296/1000], Loss: 0.6873\n",
      "Epoch [297/1000], Loss: 0.6876\n",
      "Epoch [298/1000], Loss: 0.6871\n",
      "Epoch [299/1000], Loss: 0.6870\n",
      "Epoch [300/1000], Loss: 0.6871\n",
      "Epoch [301/1000], Loss: 0.6865\n",
      "Epoch [302/1000], Loss: 0.6866\n",
      "Epoch [303/1000], Loss: 0.6863\n",
      "Epoch [304/1000], Loss: 0.6860\n",
      "Epoch [305/1000], Loss: 0.6859\n",
      "Epoch [306/1000], Loss: 0.6855\n",
      "Epoch [307/1000], Loss: 0.6852\n",
      "Epoch [308/1000], Loss: 0.6853\n",
      "Epoch [309/1000], Loss: 0.6846\n",
      "Epoch [310/1000], Loss: 0.6841\n",
      "Epoch [311/1000], Loss: 0.6839\n",
      "Epoch [312/1000], Loss: 0.6848\n",
      "Epoch [313/1000], Loss: 0.6966\n",
      "Epoch [314/1000], Loss: 0.7025\n",
      "Epoch [315/1000], Loss: 0.6833\n",
      "Epoch [316/1000], Loss: 0.7026\n",
      "Epoch [317/1000], Loss: 0.6846\n",
      "Epoch [318/1000], Loss: 0.7055\n",
      "Epoch [319/1000], Loss: 0.6880\n",
      "Epoch [320/1000], Loss: 0.6940\n",
      "Epoch [321/1000], Loss: 0.6979\n",
      "Epoch [322/1000], Loss: 0.6901\n",
      "Epoch [323/1000], Loss: 0.6872\n",
      "Epoch [324/1000], Loss: 0.6926\n",
      "Epoch [325/1000], Loss: 0.6944\n",
      "Epoch [326/1000], Loss: 0.6907\n",
      "Epoch [327/1000], Loss: 0.6880\n",
      "Epoch [328/1000], Loss: 0.6893\n",
      "Epoch [329/1000], Loss: 0.6916\n",
      "Epoch [330/1000], Loss: 0.6917\n",
      "Epoch [331/1000], Loss: 0.6898\n",
      "Epoch [332/1000], Loss: 0.6886\n",
      "Epoch [333/1000], Loss: 0.6891\n",
      "Epoch [334/1000], Loss: 0.6903\n",
      "Epoch [335/1000], Loss: 0.6905\n",
      "Epoch [336/1000], Loss: 0.6896\n",
      "Epoch [337/1000], Loss: 0.6887\n",
      "Epoch [338/1000], Loss: 0.6888\n",
      "Epoch [339/1000], Loss: 0.6894\n",
      "Epoch [340/1000], Loss: 0.6897\n",
      "Epoch [341/1000], Loss: 0.6892\n",
      "Epoch [342/1000], Loss: 0.6886\n",
      "Epoch [343/1000], Loss: 0.6885\n",
      "Epoch [344/1000], Loss: 0.6888\n",
      "Epoch [345/1000], Loss: 0.6890\n",
      "Epoch [346/1000], Loss: 0.6888\n",
      "Epoch [347/1000], Loss: 0.6883\n",
      "Epoch [348/1000], Loss: 0.6881\n",
      "Epoch [349/1000], Loss: 0.6882\n",
      "Epoch [350/1000], Loss: 0.6883\n",
      "Epoch [351/1000], Loss: 0.6880\n",
      "Epoch [352/1000], Loss: 0.6876\n",
      "Epoch [353/1000], Loss: 0.6875\n",
      "Epoch [354/1000], Loss: 0.6875\n",
      "Epoch [355/1000], Loss: 0.6874\n",
      "Epoch [356/1000], Loss: 0.6870\n",
      "Epoch [357/1000], Loss: 0.6866\n",
      "Epoch [358/1000], Loss: 0.6865\n",
      "Epoch [359/1000], Loss: 0.6863\n",
      "Epoch [360/1000], Loss: 0.6859\n",
      "Epoch [361/1000], Loss: 0.6856\n",
      "Epoch [362/1000], Loss: 0.6856\n",
      "Epoch [363/1000], Loss: 0.6852\n",
      "Epoch [364/1000], Loss: 0.6849\n",
      "Epoch [365/1000], Loss: 0.6848\n",
      "Epoch [366/1000], Loss: 0.6844\n",
      "Epoch [367/1000], Loss: 0.6843\n",
      "Epoch [368/1000], Loss: 0.6839\n",
      "Epoch [369/1000], Loss: 0.6837\n",
      "Epoch [370/1000], Loss: 0.6833\n",
      "Epoch [371/1000], Loss: 0.6832\n",
      "Epoch [372/1000], Loss: 0.6827\n",
      "Epoch [373/1000], Loss: 0.6826\n",
      "Epoch [374/1000], Loss: 0.6824\n",
      "Epoch [375/1000], Loss: 0.6820\n",
      "Epoch [376/1000], Loss: 0.6816\n",
      "Epoch [377/1000], Loss: 0.6814\n",
      "Epoch [378/1000], Loss: 0.6815\n",
      "Epoch [379/1000], Loss: 0.6835\n",
      "Epoch [380/1000], Loss: 0.6957\n",
      "Epoch [381/1000], Loss: 0.6945\n",
      "Epoch [382/1000], Loss: 0.6871\n",
      "Epoch [383/1000], Loss: 0.6804\n",
      "Epoch [384/1000], Loss: 0.6831\n",
      "Epoch [385/1000], Loss: 0.6902\n",
      "Epoch [386/1000], Loss: 0.6806\n",
      "Epoch [387/1000], Loss: 0.6911\n",
      "Epoch [388/1000], Loss: 0.6905\n",
      "Epoch [389/1000], Loss: 0.6897\n",
      "Epoch [390/1000], Loss: 0.6839\n",
      "Epoch [391/1000], Loss: 0.6869\n",
      "Epoch [392/1000], Loss: 0.6849\n",
      "Epoch [393/1000], Loss: 0.6882\n",
      "Epoch [394/1000], Loss: 0.6838\n",
      "Epoch [395/1000], Loss: 0.6856\n",
      "Epoch [396/1000], Loss: 0.6854\n",
      "Epoch [397/1000], Loss: 0.6834\n",
      "Epoch [398/1000], Loss: 0.6858\n",
      "Epoch [399/1000], Loss: 0.6839\n",
      "Epoch [400/1000], Loss: 0.6830\n",
      "Epoch [401/1000], Loss: 0.6846\n",
      "Epoch [402/1000], Loss: 0.6820\n",
      "Epoch [403/1000], Loss: 0.6837\n",
      "Epoch [404/1000], Loss: 0.6818\n",
      "Epoch [405/1000], Loss: 0.6828\n",
      "Epoch [406/1000], Loss: 0.6816\n",
      "Epoch [407/1000], Loss: 0.6822\n",
      "Epoch [408/1000], Loss: 0.6813\n",
      "Epoch [409/1000], Loss: 0.6821\n",
      "Epoch [410/1000], Loss: 0.6808\n",
      "Epoch [411/1000], Loss: 0.6821\n",
      "Epoch [412/1000], Loss: 0.6802\n",
      "Epoch [413/1000], Loss: 0.6814\n",
      "Epoch [414/1000], Loss: 0.6802\n",
      "Epoch [415/1000], Loss: 0.6799\n",
      "Epoch [416/1000], Loss: 0.6805\n",
      "Epoch [417/1000], Loss: 0.6792\n",
      "Epoch [418/1000], Loss: 0.6787\n",
      "Epoch [419/1000], Loss: 0.6796\n",
      "Epoch [420/1000], Loss: 0.6800\n",
      "Epoch [421/1000], Loss: 0.6788\n",
      "Epoch [422/1000], Loss: 0.6782\n",
      "Epoch [423/1000], Loss: 0.6781\n",
      "Epoch [424/1000], Loss: 0.6821\n",
      "Epoch [425/1000], Loss: 0.6938\n",
      "Epoch [426/1000], Loss: 0.7039\n",
      "Epoch [427/1000], Loss: 0.6878\n",
      "Epoch [428/1000], Loss: 0.7272\n",
      "Epoch [429/1000], Loss: 0.7179\n",
      "Epoch [430/1000], Loss: 0.6924\n",
      "Epoch [431/1000], Loss: 0.7070\n",
      "Epoch [432/1000], Loss: 0.6847\n",
      "Epoch [433/1000], Loss: 0.6974\n",
      "Epoch [434/1000], Loss: 0.6964\n",
      "Epoch [435/1000], Loss: 0.6808\n",
      "Epoch [436/1000], Loss: 0.6917\n",
      "Epoch [437/1000], Loss: 0.6915\n",
      "Epoch [438/1000], Loss: 0.6837\n",
      "Epoch [439/1000], Loss: 0.6842\n",
      "Epoch [440/1000], Loss: 0.6895\n",
      "Epoch [441/1000], Loss: 0.6874\n",
      "Epoch [442/1000], Loss: 0.6838\n",
      "Epoch [443/1000], Loss: 0.6850\n",
      "Epoch [444/1000], Loss: 0.6875\n",
      "Epoch [445/1000], Loss: 0.6873\n",
      "Epoch [446/1000], Loss: 0.6853\n",
      "Epoch [447/1000], Loss: 0.6843\n",
      "Epoch [448/1000], Loss: 0.6854\n",
      "Epoch [449/1000], Loss: 0.6864\n",
      "Epoch [450/1000], Loss: 0.6855\n",
      "Epoch [451/1000], Loss: 0.6840\n",
      "Epoch [452/1000], Loss: 0.6841\n",
      "Epoch [453/1000], Loss: 0.6849\n",
      "Epoch [454/1000], Loss: 0.6846\n",
      "Epoch [455/1000], Loss: 0.6834\n",
      "Epoch [456/1000], Loss: 0.6831\n",
      "Epoch [457/1000], Loss: 0.6838\n",
      "Epoch [458/1000], Loss: 0.6834\n",
      "Epoch [459/1000], Loss: 0.6823\n",
      "Epoch [460/1000], Loss: 0.6826\n",
      "Epoch [461/1000], Loss: 0.6828\n",
      "Epoch [462/1000], Loss: 0.6818\n",
      "Epoch [463/1000], Loss: 0.6816\n",
      "Epoch [464/1000], Loss: 0.6819\n",
      "Epoch [465/1000], Loss: 0.6811\n",
      "Epoch [466/1000], Loss: 0.6809\n",
      "Epoch [467/1000], Loss: 0.6811\n",
      "Epoch [468/1000], Loss: 0.6804\n",
      "Epoch [469/1000], Loss: 0.6803\n",
      "Epoch [470/1000], Loss: 0.6803\n",
      "Epoch [471/1000], Loss: 0.6797\n",
      "Epoch [472/1000], Loss: 0.6799\n",
      "Epoch [473/1000], Loss: 0.6794\n",
      "Epoch [474/1000], Loss: 0.6793\n",
      "Epoch [475/1000], Loss: 0.6791\n",
      "Epoch [476/1000], Loss: 0.6787\n",
      "Epoch [477/1000], Loss: 0.6787\n",
      "Epoch [478/1000], Loss: 0.6782\n",
      "Epoch [479/1000], Loss: 0.6782\n",
      "Epoch [480/1000], Loss: 0.6778\n",
      "Epoch [481/1000], Loss: 0.6777\n",
      "Epoch [482/1000], Loss: 0.6773\n",
      "Epoch [483/1000], Loss: 0.6771\n",
      "Epoch [484/1000], Loss: 0.6768\n",
      "Epoch [485/1000], Loss: 0.6764\n",
      "Epoch [486/1000], Loss: 0.6762\n",
      "Epoch [487/1000], Loss: 0.6757\n",
      "Epoch [488/1000], Loss: 0.6752\n",
      "Epoch [489/1000], Loss: 0.6749\n",
      "Epoch [490/1000], Loss: 0.6745\n",
      "Epoch [491/1000], Loss: 0.6737\n",
      "Epoch [492/1000], Loss: 0.6730\n",
      "Epoch [493/1000], Loss: 0.6722\n",
      "Epoch [494/1000], Loss: 0.6722\n",
      "Epoch [495/1000], Loss: 0.6798\n",
      "Epoch [496/1000], Loss: 0.7094\n",
      "Epoch [497/1000], Loss: 0.6752\n",
      "Epoch [498/1000], Loss: 0.7339\n",
      "Epoch [499/1000], Loss: 0.7296\n",
      "Epoch [500/1000], Loss: 0.7107\n",
      "Epoch [501/1000], Loss: 0.6939\n",
      "Epoch [502/1000], Loss: 0.6916\n",
      "Epoch [503/1000], Loss: 0.7018\n",
      "Epoch [504/1000], Loss: 0.7122\n",
      "Epoch [505/1000], Loss: 0.7130\n",
      "Epoch [506/1000], Loss: 0.7047\n",
      "Epoch [507/1000], Loss: 0.6949\n",
      "Epoch [508/1000], Loss: 0.6909\n",
      "Epoch [509/1000], Loss: 0.6941\n",
      "Epoch [510/1000], Loss: 0.6999\n",
      "Epoch [511/1000], Loss: 0.7027\n",
      "Epoch [512/1000], Loss: 0.7003\n",
      "Epoch [513/1000], Loss: 0.6952\n",
      "Epoch [514/1000], Loss: 0.6915\n",
      "Epoch [515/1000], Loss: 0.6914\n",
      "Epoch [516/1000], Loss: 0.6940\n",
      "Epoch [517/1000], Loss: 0.6965\n",
      "Epoch [518/1000], Loss: 0.6966\n",
      "Epoch [519/1000], Loss: 0.6945\n",
      "Epoch [520/1000], Loss: 0.6920\n",
      "Epoch [521/1000], Loss: 0.6910\n",
      "Epoch [522/1000], Loss: 0.6917\n",
      "Epoch [523/1000], Loss: 0.6932\n",
      "Epoch [524/1000], Loss: 0.6939\n",
      "Epoch [525/1000], Loss: 0.6934\n",
      "Epoch [526/1000], Loss: 0.6921\n",
      "Epoch [527/1000], Loss: 0.6911\n",
      "Epoch [528/1000], Loss: 0.6910\n",
      "Epoch [529/1000], Loss: 0.6916\n",
      "Epoch [530/1000], Loss: 0.6923\n",
      "Epoch [531/1000], Loss: 0.6923\n",
      "Epoch [532/1000], Loss: 0.6918\n",
      "Epoch [533/1000], Loss: 0.6912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [534/1000], Loss: 0.6909\n",
      "Epoch [535/1000], Loss: 0.6910\n",
      "Epoch [536/1000], Loss: 0.6914\n",
      "Epoch [537/1000], Loss: 0.6916\n",
      "Epoch [538/1000], Loss: 0.6914\n",
      "Epoch [539/1000], Loss: 0.6911\n",
      "Epoch [540/1000], Loss: 0.6908\n",
      "Epoch [541/1000], Loss: 0.6908\n",
      "Epoch [542/1000], Loss: 0.6909\n",
      "Epoch [543/1000], Loss: 0.6911\n",
      "Epoch [544/1000], Loss: 0.6911\n",
      "Epoch [545/1000], Loss: 0.6909\n",
      "Epoch [546/1000], Loss: 0.6908\n",
      "Epoch [547/1000], Loss: 0.6907\n",
      "Epoch [548/1000], Loss: 0.6907\n",
      "Epoch [549/1000], Loss: 0.6908\n",
      "Epoch [550/1000], Loss: 0.6908\n",
      "Epoch [551/1000], Loss: 0.6908\n",
      "Epoch [552/1000], Loss: 0.6907\n",
      "Epoch [553/1000], Loss: 0.6906\n",
      "Epoch [554/1000], Loss: 0.6906\n",
      "Epoch [555/1000], Loss: 0.6906\n",
      "Epoch [556/1000], Loss: 0.6906\n",
      "Epoch [557/1000], Loss: 0.6906\n",
      "Epoch [558/1000], Loss: 0.6905\n",
      "Epoch [559/1000], Loss: 0.6905\n",
      "Epoch [560/1000], Loss: 0.6905\n",
      "Epoch [561/1000], Loss: 0.6905\n",
      "Epoch [562/1000], Loss: 0.6905\n",
      "Epoch [563/1000], Loss: 0.6905\n",
      "Epoch [564/1000], Loss: 0.6904\n",
      "Epoch [565/1000], Loss: 0.6904\n",
      "Epoch [566/1000], Loss: 0.6904\n",
      "Epoch [567/1000], Loss: 0.6903\n",
      "Epoch [568/1000], Loss: 0.6903\n",
      "Epoch [569/1000], Loss: 0.6903\n",
      "Epoch [570/1000], Loss: 0.6903\n",
      "Epoch [571/1000], Loss: 0.6903\n",
      "Epoch [572/1000], Loss: 0.6903\n",
      "Epoch [573/1000], Loss: 0.6902\n",
      "Epoch [574/1000], Loss: 0.6902\n",
      "Epoch [575/1000], Loss: 0.6902\n",
      "Epoch [576/1000], Loss: 0.6902\n",
      "Epoch [577/1000], Loss: 0.6902\n",
      "Epoch [578/1000], Loss: 0.6902\n",
      "Epoch [579/1000], Loss: 0.6901\n",
      "Epoch [580/1000], Loss: 0.6901\n",
      "Epoch [581/1000], Loss: 0.6901\n",
      "Epoch [582/1000], Loss: 0.6901\n",
      "Epoch [583/1000], Loss: 0.6901\n",
      "Epoch [584/1000], Loss: 0.6901\n",
      "Epoch [585/1000], Loss: 0.6900\n",
      "Epoch [586/1000], Loss: 0.6900\n",
      "Epoch [587/1000], Loss: 0.6900\n",
      "Epoch [588/1000], Loss: 0.6900\n",
      "Epoch [589/1000], Loss: 0.6900\n",
      "Epoch [590/1000], Loss: 0.6900\n",
      "Epoch [591/1000], Loss: 0.6899\n",
      "Epoch [592/1000], Loss: 0.6899\n",
      "Epoch [593/1000], Loss: 0.6899\n",
      "Epoch [594/1000], Loss: 0.6899\n",
      "Epoch [595/1000], Loss: 0.6899\n",
      "Epoch [596/1000], Loss: 0.6899\n",
      "Epoch [597/1000], Loss: 0.6898\n",
      "Epoch [598/1000], Loss: 0.6898\n",
      "Epoch [599/1000], Loss: 0.6898\n",
      "Epoch [600/1000], Loss: 0.6898\n",
      "Epoch [601/1000], Loss: 0.6898\n",
      "Epoch [602/1000], Loss: 0.6898\n",
      "Epoch [603/1000], Loss: 0.6898\n",
      "Epoch [604/1000], Loss: 0.6897\n",
      "Epoch [605/1000], Loss: 0.6897\n",
      "Epoch [606/1000], Loss: 0.6897\n",
      "Epoch [607/1000], Loss: 0.6897\n",
      "Epoch [608/1000], Loss: 0.6897\n",
      "Epoch [609/1000], Loss: 0.6897\n",
      "Epoch [610/1000], Loss: 0.6897\n",
      "Epoch [611/1000], Loss: 0.6896\n",
      "Epoch [612/1000], Loss: 0.6896\n",
      "Epoch [613/1000], Loss: 0.6896\n",
      "Epoch [614/1000], Loss: 0.6896\n",
      "Epoch [615/1000], Loss: 0.6896\n",
      "Epoch [616/1000], Loss: 0.6896\n",
      "Epoch [617/1000], Loss: 0.6896\n",
      "Epoch [618/1000], Loss: 0.6895\n",
      "Epoch [619/1000], Loss: 0.6895\n",
      "Epoch [620/1000], Loss: 0.6895\n",
      "Epoch [621/1000], Loss: 0.6895\n",
      "Epoch [622/1000], Loss: 0.6895\n",
      "Epoch [623/1000], Loss: 0.6895\n",
      "Epoch [624/1000], Loss: 0.6895\n",
      "Epoch [625/1000], Loss: 0.6894\n",
      "Epoch [626/1000], Loss: 0.6894\n",
      "Epoch [627/1000], Loss: 0.6894\n",
      "Epoch [628/1000], Loss: 0.6894\n",
      "Epoch [629/1000], Loss: 0.6894\n",
      "Epoch [630/1000], Loss: 0.6894\n",
      "Epoch [631/1000], Loss: 0.6894\n",
      "Epoch [632/1000], Loss: 0.6893\n",
      "Epoch [633/1000], Loss: 0.6893\n",
      "Epoch [634/1000], Loss: 0.6893\n",
      "Epoch [635/1000], Loss: 0.6893\n",
      "Epoch [636/1000], Loss: 0.6893\n",
      "Epoch [637/1000], Loss: 0.6893\n",
      "Epoch [638/1000], Loss: 0.6893\n",
      "Epoch [639/1000], Loss: 0.6893\n",
      "Epoch [640/1000], Loss: 0.6892\n",
      "Epoch [641/1000], Loss: 0.6892\n",
      "Epoch [642/1000], Loss: 0.6892\n",
      "Epoch [643/1000], Loss: 0.6892\n",
      "Epoch [644/1000], Loss: 0.6892\n",
      "Epoch [645/1000], Loss: 0.6892\n",
      "Epoch [646/1000], Loss: 0.6892\n",
      "Epoch [647/1000], Loss: 0.6891\n",
      "Epoch [648/1000], Loss: 0.6891\n",
      "Epoch [649/1000], Loss: 0.6891\n",
      "Epoch [650/1000], Loss: 0.6891\n",
      "Epoch [651/1000], Loss: 0.6891\n",
      "Epoch [652/1000], Loss: 0.6891\n",
      "Epoch [653/1000], Loss: 0.6891\n",
      "Epoch [654/1000], Loss: 0.6891\n",
      "Epoch [655/1000], Loss: 0.6890\n",
      "Epoch [656/1000], Loss: 0.6890\n",
      "Epoch [657/1000], Loss: 0.6890\n",
      "Epoch [658/1000], Loss: 0.6890\n",
      "Epoch [659/1000], Loss: 0.6890\n",
      "Epoch [660/1000], Loss: 0.6890\n",
      "Epoch [661/1000], Loss: 0.6890\n",
      "Epoch [662/1000], Loss: 0.6890\n",
      "Epoch [663/1000], Loss: 0.6889\n",
      "Epoch [664/1000], Loss: 0.6889\n",
      "Epoch [665/1000], Loss: 0.6889\n",
      "Epoch [666/1000], Loss: 0.6889\n",
      "Epoch [667/1000], Loss: 0.6889\n",
      "Epoch [668/1000], Loss: 0.6889\n",
      "Epoch [669/1000], Loss: 0.6889\n",
      "Epoch [670/1000], Loss: 0.6889\n",
      "Epoch [671/1000], Loss: 0.6888\n",
      "Epoch [672/1000], Loss: 0.6888\n",
      "Epoch [673/1000], Loss: 0.6888\n",
      "Epoch [674/1000], Loss: 0.6888\n",
      "Epoch [675/1000], Loss: 0.6888\n",
      "Epoch [676/1000], Loss: 0.6888\n",
      "Epoch [677/1000], Loss: 0.6888\n",
      "Epoch [678/1000], Loss: 0.6888\n",
      "Epoch [679/1000], Loss: 0.6887\n",
      "Epoch [680/1000], Loss: 0.6887\n",
      "Epoch [681/1000], Loss: 0.6887\n",
      "Epoch [682/1000], Loss: 0.6887\n",
      "Epoch [683/1000], Loss: 0.6887\n",
      "Epoch [684/1000], Loss: 0.6887\n",
      "Epoch [685/1000], Loss: 0.6887\n",
      "Epoch [686/1000], Loss: 0.6887\n",
      "Epoch [687/1000], Loss: 0.6886\n",
      "Epoch [688/1000], Loss: 0.6886\n",
      "Epoch [689/1000], Loss: 0.6886\n",
      "Epoch [690/1000], Loss: 0.6886\n",
      "Epoch [691/1000], Loss: 0.6886\n",
      "Epoch [692/1000], Loss: 0.6886\n",
      "Epoch [693/1000], Loss: 0.6886\n",
      "Epoch [694/1000], Loss: 0.6886\n",
      "Epoch [695/1000], Loss: 0.6885\n",
      "Epoch [696/1000], Loss: 0.6885\n",
      "Epoch [697/1000], Loss: 0.6885\n",
      "Epoch [698/1000], Loss: 0.6885\n",
      "Epoch [699/1000], Loss: 0.6885\n",
      "Epoch [700/1000], Loss: 0.6885\n",
      "Epoch [701/1000], Loss: 0.6885\n",
      "Epoch [702/1000], Loss: 0.6885\n",
      "Epoch [703/1000], Loss: 0.6884\n",
      "Epoch [704/1000], Loss: 0.6884\n",
      "Epoch [705/1000], Loss: 0.6884\n",
      "Epoch [706/1000], Loss: 0.6884\n",
      "Epoch [707/1000], Loss: 0.6884\n",
      "Epoch [708/1000], Loss: 0.6884\n",
      "Epoch [709/1000], Loss: 0.6884\n",
      "Epoch [710/1000], Loss: 0.6884\n",
      "Epoch [711/1000], Loss: 0.6883\n",
      "Epoch [712/1000], Loss: 0.6883\n",
      "Epoch [713/1000], Loss: 0.6883\n",
      "Epoch [714/1000], Loss: 0.6883\n",
      "Epoch [715/1000], Loss: 0.6883\n",
      "Epoch [716/1000], Loss: 0.6883\n",
      "Epoch [717/1000], Loss: 0.6883\n",
      "Epoch [718/1000], Loss: 0.6883\n",
      "Epoch [719/1000], Loss: 0.6882\n",
      "Epoch [720/1000], Loss: 0.6882\n",
      "Epoch [721/1000], Loss: 0.6882\n",
      "Epoch [722/1000], Loss: 0.6882\n",
      "Epoch [723/1000], Loss: 0.6882\n",
      "Epoch [724/1000], Loss: 0.6882\n",
      "Epoch [725/1000], Loss: 0.6882\n",
      "Epoch [726/1000], Loss: 0.6881\n",
      "Epoch [727/1000], Loss: 0.6881\n",
      "Epoch [728/1000], Loss: 0.6881\n",
      "Epoch [729/1000], Loss: 0.6881\n",
      "Epoch [730/1000], Loss: 0.6881\n",
      "Epoch [731/1000], Loss: 0.6881\n",
      "Epoch [732/1000], Loss: 0.6881\n",
      "Epoch [733/1000], Loss: 0.6880\n",
      "Epoch [734/1000], Loss: 0.6880\n",
      "Epoch [735/1000], Loss: 0.6880\n",
      "Epoch [736/1000], Loss: 0.6880\n",
      "Epoch [737/1000], Loss: 0.6880\n",
      "Epoch [738/1000], Loss: 0.6880\n",
      "Epoch [739/1000], Loss: 0.6879\n",
      "Epoch [740/1000], Loss: 0.6879\n",
      "Epoch [741/1000], Loss: 0.6879\n",
      "Epoch [742/1000], Loss: 0.6879\n",
      "Epoch [743/1000], Loss: 0.6879\n",
      "Epoch [744/1000], Loss: 0.6879\n",
      "Epoch [745/1000], Loss: 0.6878\n",
      "Epoch [746/1000], Loss: 0.6878\n",
      "Epoch [747/1000], Loss: 0.6878\n",
      "Epoch [748/1000], Loss: 0.6878\n",
      "Epoch [749/1000], Loss: 0.6878\n",
      "Epoch [750/1000], Loss: 0.6878\n",
      "Epoch [751/1000], Loss: 0.6877\n",
      "Epoch [752/1000], Loss: 0.6877\n",
      "Epoch [753/1000], Loss: 0.6877\n",
      "Epoch [754/1000], Loss: 0.6877\n",
      "Epoch [755/1000], Loss: 0.6877\n",
      "Epoch [756/1000], Loss: 0.6876\n",
      "Epoch [757/1000], Loss: 0.6876\n",
      "Epoch [758/1000], Loss: 0.6876\n",
      "Epoch [759/1000], Loss: 0.6876\n",
      "Epoch [760/1000], Loss: 0.6876\n",
      "Epoch [761/1000], Loss: 0.6875\n",
      "Epoch [762/1000], Loss: 0.6875\n",
      "Epoch [763/1000], Loss: 0.6875\n",
      "Epoch [764/1000], Loss: 0.6875\n",
      "Epoch [765/1000], Loss: 0.6874\n",
      "Epoch [766/1000], Loss: 0.6874\n",
      "Epoch [767/1000], Loss: 0.6874\n",
      "Epoch [768/1000], Loss: 0.6874\n",
      "Epoch [769/1000], Loss: 0.6873\n",
      "Epoch [770/1000], Loss: 0.6873\n",
      "Epoch [771/1000], Loss: 0.6873\n",
      "Epoch [772/1000], Loss: 0.6872\n",
      "Epoch [773/1000], Loss: 0.6872\n",
      "Epoch [774/1000], Loss: 0.6872\n",
      "Epoch [775/1000], Loss: 0.6871\n",
      "Epoch [776/1000], Loss: 0.6871\n",
      "Epoch [777/1000], Loss: 0.6871\n",
      "Epoch [778/1000], Loss: 0.6870\n",
      "Epoch [779/1000], Loss: 0.6870\n",
      "Epoch [780/1000], Loss: 0.6870\n",
      "Epoch [781/1000], Loss: 0.6869\n",
      "Epoch [782/1000], Loss: 0.6869\n",
      "Epoch [783/1000], Loss: 0.6868\n",
      "Epoch [784/1000], Loss: 0.6868\n",
      "Epoch [785/1000], Loss: 0.6867\n",
      "Epoch [786/1000], Loss: 0.6867\n",
      "Epoch [787/1000], Loss: 0.6866\n",
      "Epoch [788/1000], Loss: 0.6866\n",
      "Epoch [789/1000], Loss: 0.6865\n",
      "Epoch [790/1000], Loss: 0.6865\n",
      "Epoch [791/1000], Loss: 0.6864\n",
      "Epoch [792/1000], Loss: 0.6863\n",
      "Epoch [793/1000], Loss: 0.6863\n",
      "Epoch [794/1000], Loss: 0.6862\n",
      "Epoch [795/1000], Loss: 0.6861\n",
      "Epoch [796/1000], Loss: 0.6861\n",
      "Epoch [797/1000], Loss: 0.6860\n",
      "Epoch [798/1000], Loss: 0.6859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [799/1000], Loss: 0.6858\n",
      "Epoch [800/1000], Loss: 0.6857\n",
      "Epoch [801/1000], Loss: 0.6855\n",
      "Epoch [802/1000], Loss: 0.6854\n",
      "Epoch [803/1000], Loss: 0.6853\n",
      "Epoch [804/1000], Loss: 0.6851\n",
      "Epoch [805/1000], Loss: 0.6848\n",
      "Epoch [806/1000], Loss: 0.6844\n",
      "Epoch [807/1000], Loss: 0.6839\n",
      "Epoch [808/1000], Loss: 0.6831\n",
      "Epoch [809/1000], Loss: 0.6842\n",
      "Epoch [810/1000], Loss: 0.6932\n",
      "Epoch [811/1000], Loss: 0.6899\n",
      "Epoch [812/1000], Loss: 0.6884\n",
      "Epoch [813/1000], Loss: 0.6884\n",
      "Epoch [814/1000], Loss: 0.6894\n",
      "Epoch [815/1000], Loss: 0.6897\n",
      "Epoch [816/1000], Loss: 0.6889\n",
      "Epoch [817/1000], Loss: 0.6882\n",
      "Epoch [818/1000], Loss: 0.6884\n",
      "Epoch [819/1000], Loss: 0.6890\n",
      "Epoch [820/1000], Loss: 0.6890\n",
      "Epoch [821/1000], Loss: 0.6884\n",
      "Epoch [822/1000], Loss: 0.6881\n",
      "Epoch [823/1000], Loss: 0.6884\n",
      "Epoch [824/1000], Loss: 0.6886\n",
      "Epoch [825/1000], Loss: 0.6885\n",
      "Epoch [826/1000], Loss: 0.6881\n",
      "Epoch [827/1000], Loss: 0.6880\n",
      "Epoch [828/1000], Loss: 0.6882\n",
      "Epoch [829/1000], Loss: 0.6883\n",
      "Epoch [830/1000], Loss: 0.6881\n",
      "Epoch [831/1000], Loss: 0.6879\n",
      "Epoch [832/1000], Loss: 0.6879\n",
      "Epoch [833/1000], Loss: 0.6881\n",
      "Epoch [834/1000], Loss: 0.6880\n",
      "Epoch [835/1000], Loss: 0.6878\n",
      "Epoch [836/1000], Loss: 0.6878\n",
      "Epoch [837/1000], Loss: 0.6878\n",
      "Epoch [838/1000], Loss: 0.6878\n",
      "Epoch [839/1000], Loss: 0.6877\n",
      "Epoch [840/1000], Loss: 0.6876\n",
      "Epoch [841/1000], Loss: 0.6876\n",
      "Epoch [842/1000], Loss: 0.6876\n",
      "Epoch [843/1000], Loss: 0.6876\n",
      "Epoch [844/1000], Loss: 0.6875\n",
      "Epoch [845/1000], Loss: 0.6875\n",
      "Epoch [846/1000], Loss: 0.6875\n",
      "Epoch [847/1000], Loss: 0.6874\n",
      "Epoch [848/1000], Loss: 0.6873\n",
      "Epoch [849/1000], Loss: 0.6873\n",
      "Epoch [850/1000], Loss: 0.6873\n",
      "Epoch [851/1000], Loss: 0.6872\n",
      "Epoch [852/1000], Loss: 0.6872\n",
      "Epoch [853/1000], Loss: 0.6872\n",
      "Epoch [854/1000], Loss: 0.6872\n",
      "Epoch [855/1000], Loss: 0.6872\n",
      "Epoch [856/1000], Loss: 0.6872\n",
      "Epoch [857/1000], Loss: 0.6871\n",
      "Epoch [858/1000], Loss: 0.6871\n",
      "Epoch [859/1000], Loss: 0.6871\n",
      "Epoch [860/1000], Loss: 0.6871\n",
      "Epoch [861/1000], Loss: 0.6870\n",
      "Epoch [862/1000], Loss: 0.6870\n",
      "Epoch [863/1000], Loss: 0.6870\n",
      "Epoch [864/1000], Loss: 0.6870\n",
      "Epoch [865/1000], Loss: 0.6870\n",
      "Epoch [866/1000], Loss: 0.6870\n",
      "Epoch [867/1000], Loss: 0.6870\n",
      "Epoch [868/1000], Loss: 0.6869\n",
      "Epoch [869/1000], Loss: 0.6869\n",
      "Epoch [870/1000], Loss: 0.6869\n",
      "Epoch [871/1000], Loss: 0.6869\n",
      "Epoch [872/1000], Loss: 0.6869\n",
      "Epoch [873/1000], Loss: 0.6869\n",
      "Epoch [874/1000], Loss: 0.6868\n",
      "Epoch [875/1000], Loss: 0.6868\n",
      "Epoch [876/1000], Loss: 0.6868\n",
      "Epoch [877/1000], Loss: 0.6868\n",
      "Epoch [878/1000], Loss: 0.6868\n",
      "Epoch [879/1000], Loss: 0.6867\n",
      "Epoch [880/1000], Loss: 0.6867\n",
      "Epoch [881/1000], Loss: 0.6867\n",
      "Epoch [882/1000], Loss: 0.6867\n",
      "Epoch [883/1000], Loss: 0.6867\n",
      "Epoch [884/1000], Loss: 0.6866\n",
      "Epoch [885/1000], Loss: 0.6866\n",
      "Epoch [886/1000], Loss: 0.6866\n",
      "Epoch [887/1000], Loss: 0.6866\n",
      "Epoch [888/1000], Loss: 0.6865\n",
      "Epoch [889/1000], Loss: 0.6865\n",
      "Epoch [890/1000], Loss: 0.6865\n",
      "Epoch [891/1000], Loss: 0.6865\n",
      "Epoch [892/1000], Loss: 0.6864\n",
      "Epoch [893/1000], Loss: 0.6864\n",
      "Epoch [894/1000], Loss: 0.6864\n",
      "Epoch [895/1000], Loss: 0.6864\n",
      "Epoch [896/1000], Loss: 0.6863\n",
      "Epoch [897/1000], Loss: 0.6863\n",
      "Epoch [898/1000], Loss: 0.6863\n",
      "Epoch [899/1000], Loss: 0.6862\n",
      "Epoch [900/1000], Loss: 0.6862\n",
      "Epoch [901/1000], Loss: 0.6862\n",
      "Epoch [902/1000], Loss: 0.6862\n",
      "Epoch [903/1000], Loss: 0.6861\n",
      "Epoch [904/1000], Loss: 0.6861\n",
      "Epoch [905/1000], Loss: 0.6860\n",
      "Epoch [906/1000], Loss: 0.6860\n",
      "Epoch [907/1000], Loss: 0.6860\n",
      "Epoch [908/1000], Loss: 0.6859\n",
      "Epoch [909/1000], Loss: 0.6859\n",
      "Epoch [910/1000], Loss: 0.6858\n",
      "Epoch [911/1000], Loss: 0.6858\n",
      "Epoch [912/1000], Loss: 0.6857\n",
      "Epoch [913/1000], Loss: 0.6856\n",
      "Epoch [914/1000], Loss: 0.6856\n",
      "Epoch [915/1000], Loss: 0.6855\n",
      "Epoch [916/1000], Loss: 0.6854\n",
      "Epoch [917/1000], Loss: 0.6853\n",
      "Epoch [918/1000], Loss: 0.6852\n",
      "Epoch [919/1000], Loss: 0.6851\n",
      "Epoch [920/1000], Loss: 0.6850\n",
      "Epoch [921/1000], Loss: 0.6849\n",
      "Epoch [922/1000], Loss: 0.6848\n",
      "Epoch [923/1000], Loss: 0.6846\n",
      "Epoch [924/1000], Loss: 0.6844\n",
      "Epoch [925/1000], Loss: 0.6842\n",
      "Epoch [926/1000], Loss: 0.6840\n",
      "Epoch [927/1000], Loss: 0.6837\n",
      "Epoch [928/1000], Loss: 0.6834\n",
      "Epoch [929/1000], Loss: 0.6830\n",
      "Epoch [930/1000], Loss: 0.6826\n",
      "Epoch [931/1000], Loss: 0.6821\n",
      "Epoch [932/1000], Loss: 0.6815\n",
      "Epoch [933/1000], Loss: 0.6809\n",
      "Epoch [934/1000], Loss: 0.6851\n",
      "Epoch [935/1000], Loss: 0.7006\n",
      "Epoch [936/1000], Loss: 0.6934\n",
      "Epoch [937/1000], Loss: 0.6834\n",
      "Epoch [938/1000], Loss: 0.6934\n",
      "Epoch [939/1000], Loss: 0.6957\n",
      "Epoch [940/1000], Loss: 0.6852\n",
      "Epoch [941/1000], Loss: 0.6858\n",
      "Epoch [942/1000], Loss: 0.6922\n",
      "Epoch [943/1000], Loss: 0.6898\n",
      "Epoch [944/1000], Loss: 0.6839\n",
      "Epoch [945/1000], Loss: 0.6860\n",
      "Epoch [946/1000], Loss: 0.6896\n",
      "Epoch [947/1000], Loss: 0.6859\n",
      "Epoch [948/1000], Loss: 0.6834\n",
      "Epoch [949/1000], Loss: 0.6862\n",
      "Epoch [950/1000], Loss: 0.6868\n",
      "Epoch [951/1000], Loss: 0.6835\n",
      "Epoch [952/1000], Loss: 0.6832\n",
      "Epoch [953/1000], Loss: 0.6855\n",
      "Epoch [954/1000], Loss: 0.6839\n",
      "Epoch [955/1000], Loss: 0.6819\n",
      "Epoch [956/1000], Loss: 0.6835\n",
      "Epoch [957/1000], Loss: 0.6830\n",
      "Epoch [958/1000], Loss: 0.6809\n",
      "Epoch [959/1000], Loss: 0.6824\n",
      "Epoch [960/1000], Loss: 0.6814\n",
      "Epoch [961/1000], Loss: 0.6802\n",
      "Epoch [962/1000], Loss: 0.6815\n",
      "Epoch [963/1000], Loss: 0.6792\n",
      "Epoch [964/1000], Loss: 0.6806\n",
      "Epoch [965/1000], Loss: 0.6785\n",
      "Epoch [966/1000], Loss: 0.6801\n",
      "Epoch [967/1000], Loss: 0.6776\n",
      "Epoch [968/1000], Loss: 0.6786\n",
      "Epoch [969/1000], Loss: 0.6785\n",
      "Epoch [970/1000], Loss: 0.6767\n",
      "Epoch [971/1000], Loss: 0.6750\n",
      "Epoch [972/1000], Loss: 0.6737\n",
      "Epoch [973/1000], Loss: 0.6720\n",
      "Epoch [974/1000], Loss: 0.6699\n",
      "Epoch [975/1000], Loss: 0.6950\n",
      "Epoch [976/1000], Loss: 0.7018\n",
      "Epoch [977/1000], Loss: 0.6598\n",
      "Epoch [978/1000], Loss: 0.6558\n",
      "Epoch [979/1000], Loss: 0.7068\n",
      "Epoch [980/1000], Loss: 0.6941\n",
      "Epoch [981/1000], Loss: 0.6856\n",
      "Epoch [982/1000], Loss: 0.6929\n",
      "Epoch [983/1000], Loss: 0.6998\n",
      "Epoch [984/1000], Loss: 0.6944\n",
      "Epoch [985/1000], Loss: 0.6868\n",
      "Epoch [986/1000], Loss: 0.6879\n",
      "Epoch [987/1000], Loss: 0.6934\n",
      "Epoch [988/1000], Loss: 0.6939\n",
      "Epoch [989/1000], Loss: 0.6893\n",
      "Epoch [990/1000], Loss: 0.6864\n",
      "Epoch [991/1000], Loss: 0.6886\n",
      "Epoch [992/1000], Loss: 0.6913\n",
      "Epoch [993/1000], Loss: 0.6902\n",
      "Epoch [994/1000], Loss: 0.6872\n",
      "Epoch [995/1000], Loss: 0.6865\n",
      "Epoch [996/1000], Loss: 0.6882\n",
      "Epoch [997/1000], Loss: 0.6891\n",
      "Epoch [998/1000], Loss: 0.6876\n",
      "Epoch [999/1000], Loss: 0.6859\n",
      "Epoch [1000/1000], Loss: 0.6862\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for idx,training_data in enumerate(training_sets):\n",
    "    model_lstm = SeqPredictorLSTM(101,training_data.shape[0],150,1)\n",
    "    criterion = nn.KLDivLoss(reduction = \"batchmean\")\n",
    "    optimizer = optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model_lstm(training_data[:,:-1],1.0)\n",
    "        loss = criterion(output, training_data[:,-1])\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e4a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.6882\n",
      "Epoch [2/1000], Loss: 0.6882\n",
      "Epoch [3/1000], Loss: 0.6882\n",
      "Epoch [4/1000], Loss: 0.6882\n",
      "Epoch [5/1000], Loss: 0.6882\n",
      "Epoch [6/1000], Loss: 0.6882\n",
      "Epoch [7/1000], Loss: 0.6882\n",
      "Epoch [8/1000], Loss: 0.6882\n",
      "Epoch [9/1000], Loss: 0.6882\n",
      "Epoch [10/1000], Loss: 0.6882\n",
      "Epoch [11/1000], Loss: 0.6881\n",
      "Epoch [12/1000], Loss: 0.6881\n",
      "Epoch [13/1000], Loss: 0.6881\n",
      "Epoch [14/1000], Loss: 0.6881\n",
      "Epoch [15/1000], Loss: 0.6881\n",
      "Epoch [16/1000], Loss: 0.6881\n",
      "Epoch [17/1000], Loss: 0.6881\n",
      "Epoch [18/1000], Loss: 0.6881\n",
      "Epoch [19/1000], Loss: 0.6881\n",
      "Epoch [20/1000], Loss: 0.6881\n",
      "Epoch [21/1000], Loss: 0.6881\n",
      "Epoch [22/1000], Loss: 0.6881\n",
      "Epoch [23/1000], Loss: 0.6881\n",
      "Epoch [24/1000], Loss: 0.6881\n",
      "Epoch [25/1000], Loss: 0.6881\n",
      "Epoch [26/1000], Loss: 0.6881\n",
      "Epoch [27/1000], Loss: 0.6881\n",
      "Epoch [28/1000], Loss: 0.6881\n",
      "Epoch [29/1000], Loss: 0.6881\n",
      "Epoch [30/1000], Loss: 0.6881\n",
      "Epoch [31/1000], Loss: 0.6880\n",
      "Epoch [32/1000], Loss: 0.6880\n",
      "Epoch [33/1000], Loss: 0.6880\n",
      "Epoch [34/1000], Loss: 0.6880\n",
      "Epoch [35/1000], Loss: 0.6880\n",
      "Epoch [36/1000], Loss: 0.6880\n",
      "Epoch [37/1000], Loss: 0.6880\n",
      "Epoch [38/1000], Loss: 0.6880\n",
      "Epoch [39/1000], Loss: 0.6880\n",
      "Epoch [40/1000], Loss: 0.6880\n",
      "Epoch [41/1000], Loss: 0.6880\n",
      "Epoch [42/1000], Loss: 0.6880\n",
      "Epoch [43/1000], Loss: 0.6880\n",
      "Epoch [44/1000], Loss: 0.6880\n",
      "Epoch [45/1000], Loss: 0.6880\n",
      "Epoch [46/1000], Loss: 0.6880\n",
      "Epoch [47/1000], Loss: 0.6880\n",
      "Epoch [48/1000], Loss: 0.6880\n",
      "Epoch [49/1000], Loss: 0.6880\n",
      "Epoch [50/1000], Loss: 0.6879\n",
      "Epoch [51/1000], Loss: 0.6879\n",
      "Epoch [52/1000], Loss: 0.6879\n",
      "Epoch [53/1000], Loss: 0.6879\n",
      "Epoch [54/1000], Loss: 0.6879\n",
      "Epoch [55/1000], Loss: 0.6879\n",
      "Epoch [56/1000], Loss: 0.6879\n",
      "Epoch [57/1000], Loss: 0.6879\n",
      "Epoch [58/1000], Loss: 0.6879\n",
      "Epoch [59/1000], Loss: 0.6879\n",
      "Epoch [60/1000], Loss: 0.6879\n",
      "Epoch [61/1000], Loss: 0.6879\n",
      "Epoch [62/1000], Loss: 0.6879\n",
      "Epoch [63/1000], Loss: 0.6879\n",
      "Epoch [64/1000], Loss: 0.6879\n",
      "Epoch [65/1000], Loss: 0.6879\n",
      "Epoch [66/1000], Loss: 0.6879\n",
      "Epoch [67/1000], Loss: 0.6879\n",
      "Epoch [68/1000], Loss: 0.6878\n",
      "Epoch [69/1000], Loss: 0.6878\n",
      "Epoch [70/1000], Loss: 0.6878\n",
      "Epoch [71/1000], Loss: 0.6878\n",
      "Epoch [72/1000], Loss: 0.6878\n",
      "Epoch [73/1000], Loss: 0.6878\n",
      "Epoch [74/1000], Loss: 0.6878\n",
      "Epoch [75/1000], Loss: 0.6878\n",
      "Epoch [76/1000], Loss: 0.6878\n",
      "Epoch [77/1000], Loss: 0.6878\n",
      "Epoch [78/1000], Loss: 0.6878\n",
      "Epoch [79/1000], Loss: 0.6878\n",
      "Epoch [80/1000], Loss: 0.6878\n",
      "Epoch [81/1000], Loss: 0.6878\n",
      "Epoch [82/1000], Loss: 0.6878\n",
      "Epoch [83/1000], Loss: 0.6878\n",
      "Epoch [84/1000], Loss: 0.6878\n",
      "Epoch [85/1000], Loss: 0.6878\n",
      "Epoch [86/1000], Loss: 0.6877\n",
      "Epoch [87/1000], Loss: 0.6877\n",
      "Epoch [88/1000], Loss: 0.6877\n",
      "Epoch [89/1000], Loss: 0.6877\n",
      "Epoch [90/1000], Loss: 0.6877\n",
      "Epoch [91/1000], Loss: 0.6877\n",
      "Epoch [92/1000], Loss: 0.6877\n",
      "Epoch [93/1000], Loss: 0.6877\n",
      "Epoch [94/1000], Loss: 0.6877\n",
      "Epoch [95/1000], Loss: 0.6877\n",
      "Epoch [96/1000], Loss: 0.6877\n",
      "Epoch [97/1000], Loss: 0.6877\n",
      "Epoch [98/1000], Loss: 0.6877\n",
      "Epoch [99/1000], Loss: 0.6877\n",
      "Epoch [100/1000], Loss: 0.6877\n",
      "Epoch [101/1000], Loss: 0.6877\n",
      "Epoch [102/1000], Loss: 0.6876\n",
      "Epoch [103/1000], Loss: 0.6876\n",
      "Epoch [104/1000], Loss: 0.6876\n",
      "Epoch [105/1000], Loss: 0.6876\n",
      "Epoch [106/1000], Loss: 0.6876\n",
      "Epoch [107/1000], Loss: 0.6876\n",
      "Epoch [108/1000], Loss: 0.6876\n",
      "Epoch [109/1000], Loss: 0.6876\n",
      "Epoch [110/1000], Loss: 0.6876\n",
      "Epoch [111/1000], Loss: 0.6876\n",
      "Epoch [112/1000], Loss: 0.6876\n",
      "Epoch [113/1000], Loss: 0.6876\n",
      "Epoch [114/1000], Loss: 0.6876\n",
      "Epoch [115/1000], Loss: 0.6876\n",
      "Epoch [116/1000], Loss: 0.6876\n",
      "Epoch [117/1000], Loss: 0.6876\n",
      "Epoch [118/1000], Loss: 0.6875\n",
      "Epoch [119/1000], Loss: 0.6875\n",
      "Epoch [120/1000], Loss: 0.6875\n",
      "Epoch [121/1000], Loss: 0.6875\n",
      "Epoch [122/1000], Loss: 0.6875\n",
      "Epoch [123/1000], Loss: 0.6875\n",
      "Epoch [124/1000], Loss: 0.6875\n",
      "Epoch [125/1000], Loss: 0.6875\n",
      "Epoch [126/1000], Loss: 0.6875\n",
      "Epoch [127/1000], Loss: 0.6875\n",
      "Epoch [128/1000], Loss: 0.6875\n",
      "Epoch [129/1000], Loss: 0.6875\n",
      "Epoch [130/1000], Loss: 0.6875\n",
      "Epoch [131/1000], Loss: 0.6875\n",
      "Epoch [132/1000], Loss: 0.6875\n",
      "Epoch [133/1000], Loss: 0.6874\n",
      "Epoch [134/1000], Loss: 0.6874\n",
      "Epoch [135/1000], Loss: 0.6874\n",
      "Epoch [136/1000], Loss: 0.6874\n",
      "Epoch [137/1000], Loss: 0.6874\n",
      "Epoch [138/1000], Loss: 0.6874\n",
      "Epoch [139/1000], Loss: 0.6874\n",
      "Epoch [140/1000], Loss: 0.6874\n",
      "Epoch [141/1000], Loss: 0.6874\n",
      "Epoch [142/1000], Loss: 0.6874\n",
      "Epoch [143/1000], Loss: 0.6874\n",
      "Epoch [144/1000], Loss: 0.6874\n",
      "Epoch [145/1000], Loss: 0.6874\n",
      "Epoch [146/1000], Loss: 0.6874\n",
      "Epoch [147/1000], Loss: 0.6873\n",
      "Epoch [148/1000], Loss: 0.6873\n",
      "Epoch [149/1000], Loss: 0.6873\n",
      "Epoch [150/1000], Loss: 0.6873\n",
      "Epoch [151/1000], Loss: 0.6873\n",
      "Epoch [152/1000], Loss: 0.6873\n",
      "Epoch [153/1000], Loss: 0.6873\n",
      "Epoch [154/1000], Loss: 0.6873\n",
      "Epoch [155/1000], Loss: 0.6873\n",
      "Epoch [156/1000], Loss: 0.6873\n",
      "Epoch [157/1000], Loss: 0.6873\n",
      "Epoch [158/1000], Loss: 0.6873\n",
      "Epoch [159/1000], Loss: 0.6873\n",
      "Epoch [160/1000], Loss: 0.6873\n",
      "Epoch [161/1000], Loss: 0.6872\n",
      "Epoch [162/1000], Loss: 0.6872\n",
      "Epoch [163/1000], Loss: 0.6872\n",
      "Epoch [164/1000], Loss: 0.6872\n",
      "Epoch [165/1000], Loss: 0.6872\n",
      "Epoch [166/1000], Loss: 0.6872\n",
      "Epoch [167/1000], Loss: 0.6872\n",
      "Epoch [168/1000], Loss: 0.6872\n",
      "Epoch [169/1000], Loss: 0.6872\n",
      "Epoch [170/1000], Loss: 0.6872\n",
      "Epoch [171/1000], Loss: 0.6872\n",
      "Epoch [172/1000], Loss: 0.6872\n",
      "Epoch [173/1000], Loss: 0.6872\n",
      "Epoch [174/1000], Loss: 0.6871\n",
      "Epoch [175/1000], Loss: 0.6871\n",
      "Epoch [176/1000], Loss: 0.6871\n",
      "Epoch [177/1000], Loss: 0.6871\n",
      "Epoch [178/1000], Loss: 0.6871\n",
      "Epoch [179/1000], Loss: 0.6871\n",
      "Epoch [180/1000], Loss: 0.6871\n",
      "Epoch [181/1000], Loss: 0.6871\n",
      "Epoch [182/1000], Loss: 0.6871\n",
      "Epoch [183/1000], Loss: 0.6871\n",
      "Epoch [184/1000], Loss: 0.6871\n",
      "Epoch [185/1000], Loss: 0.6871\n",
      "Epoch [186/1000], Loss: 0.6871\n",
      "Epoch [187/1000], Loss: 0.6870\n",
      "Epoch [188/1000], Loss: 0.6870\n",
      "Epoch [189/1000], Loss: 0.6870\n",
      "Epoch [190/1000], Loss: 0.6870\n",
      "Epoch [191/1000], Loss: 0.6870\n",
      "Epoch [192/1000], Loss: 0.6870\n",
      "Epoch [193/1000], Loss: 0.6870\n",
      "Epoch [194/1000], Loss: 0.6870\n",
      "Epoch [195/1000], Loss: 0.6870\n",
      "Epoch [196/1000], Loss: 0.6870\n",
      "Epoch [197/1000], Loss: 0.6870\n",
      "Epoch [198/1000], Loss: 0.6870\n",
      "Epoch [199/1000], Loss: 0.6869\n",
      "Epoch [200/1000], Loss: 0.6869\n",
      "Epoch [201/1000], Loss: 0.6869\n",
      "Epoch [202/1000], Loss: 0.6869\n",
      "Epoch [203/1000], Loss: 0.6869\n",
      "Epoch [204/1000], Loss: 0.6869\n",
      "Epoch [205/1000], Loss: 0.6869\n",
      "Epoch [206/1000], Loss: 0.6869\n",
      "Epoch [207/1000], Loss: 0.6869\n",
      "Epoch [208/1000], Loss: 0.6869\n",
      "Epoch [209/1000], Loss: 0.6869\n",
      "Epoch [210/1000], Loss: 0.6868\n",
      "Epoch [211/1000], Loss: 0.6868\n",
      "Epoch [212/1000], Loss: 0.6868\n",
      "Epoch [213/1000], Loss: 0.6868\n",
      "Epoch [214/1000], Loss: 0.6868\n",
      "Epoch [215/1000], Loss: 0.6868\n",
      "Epoch [216/1000], Loss: 0.6868\n",
      "Epoch [217/1000], Loss: 0.6868\n",
      "Epoch [218/1000], Loss: 0.6868\n",
      "Epoch [219/1000], Loss: 0.6868\n",
      "Epoch [220/1000], Loss: 0.6868\n",
      "Epoch [221/1000], Loss: 0.6867\n",
      "Epoch [222/1000], Loss: 0.6867\n",
      "Epoch [223/1000], Loss: 0.6867\n",
      "Epoch [224/1000], Loss: 0.6867\n",
      "Epoch [225/1000], Loss: 0.6867\n",
      "Epoch [226/1000], Loss: 0.6867\n",
      "Epoch [227/1000], Loss: 0.6867\n",
      "Epoch [228/1000], Loss: 0.6867\n",
      "Epoch [229/1000], Loss: 0.6867\n",
      "Epoch [230/1000], Loss: 0.6867\n",
      "Epoch [231/1000], Loss: 0.6867\n",
      "Epoch [232/1000], Loss: 0.6866\n",
      "Epoch [233/1000], Loss: 0.6866\n",
      "Epoch [234/1000], Loss: 0.6866\n",
      "Epoch [235/1000], Loss: 0.6866\n",
      "Epoch [236/1000], Loss: 0.6866\n",
      "Epoch [237/1000], Loss: 0.6866\n",
      "Epoch [238/1000], Loss: 0.6866\n",
      "Epoch [239/1000], Loss: 0.6866\n",
      "Epoch [240/1000], Loss: 0.6866\n",
      "Epoch [241/1000], Loss: 0.6866\n",
      "Epoch [242/1000], Loss: 0.6865\n",
      "Epoch [243/1000], Loss: 0.6865\n",
      "Epoch [244/1000], Loss: 0.6865\n",
      "Epoch [245/1000], Loss: 0.6865\n",
      "Epoch [246/1000], Loss: 0.6865\n",
      "Epoch [247/1000], Loss: 0.6865\n",
      "Epoch [248/1000], Loss: 0.6865\n",
      "Epoch [249/1000], Loss: 0.6865\n",
      "Epoch [250/1000], Loss: 0.6865\n",
      "Epoch [251/1000], Loss: 0.6865\n",
      "Epoch [252/1000], Loss: 0.6864\n",
      "Epoch [253/1000], Loss: 0.6864\n",
      "Epoch [254/1000], Loss: 0.6864\n",
      "Epoch [255/1000], Loss: 0.6864\n",
      "Epoch [256/1000], Loss: 0.6864\n",
      "Epoch [257/1000], Loss: 0.6864\n",
      "Epoch [258/1000], Loss: 0.6864\n",
      "Epoch [259/1000], Loss: 0.6864\n",
      "Epoch [260/1000], Loss: 0.6864\n",
      "Epoch [261/1000], Loss: 0.6864\n",
      "Epoch [262/1000], Loss: 0.6863\n",
      "Epoch [263/1000], Loss: 0.6863\n",
      "Epoch [264/1000], Loss: 0.6863\n",
      "Epoch [265/1000], Loss: 0.6863\n",
      "Epoch [266/1000], Loss: 0.6863\n",
      "Epoch [267/1000], Loss: 0.6863\n",
      "Epoch [268/1000], Loss: 0.6863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [269/1000], Loss: 0.6863\n",
      "Epoch [270/1000], Loss: 0.6863\n",
      "Epoch [271/1000], Loss: 0.6862\n",
      "Epoch [272/1000], Loss: 0.6862\n",
      "Epoch [273/1000], Loss: 0.6862\n",
      "Epoch [274/1000], Loss: 0.6862\n",
      "Epoch [275/1000], Loss: 0.6862\n",
      "Epoch [276/1000], Loss: 0.6862\n",
      "Epoch [277/1000], Loss: 0.6862\n",
      "Epoch [278/1000], Loss: 0.6862\n",
      "Epoch [279/1000], Loss: 0.6862\n",
      "Epoch [280/1000], Loss: 0.6861\n",
      "Epoch [281/1000], Loss: 0.6861\n",
      "Epoch [282/1000], Loss: 0.6861\n",
      "Epoch [283/1000], Loss: 0.6861\n",
      "Epoch [284/1000], Loss: 0.6861\n",
      "Epoch [285/1000], Loss: 0.6861\n",
      "Epoch [286/1000], Loss: 0.6861\n",
      "Epoch [287/1000], Loss: 0.6861\n",
      "Epoch [288/1000], Loss: 0.6861\n",
      "Epoch [289/1000], Loss: 0.6860\n",
      "Epoch [290/1000], Loss: 0.6860\n",
      "Epoch [291/1000], Loss: 0.6860\n",
      "Epoch [292/1000], Loss: 0.6860\n",
      "Epoch [293/1000], Loss: 0.6860\n",
      "Epoch [294/1000], Loss: 0.6860\n",
      "Epoch [295/1000], Loss: 0.6860\n",
      "Epoch [296/1000], Loss: 0.6860\n",
      "Epoch [297/1000], Loss: 0.6860\n",
      "Epoch [298/1000], Loss: 0.6859\n",
      "Epoch [299/1000], Loss: 0.6859\n",
      "Epoch [300/1000], Loss: 0.6859\n",
      "Epoch [301/1000], Loss: 0.6859\n",
      "Epoch [302/1000], Loss: 0.6859\n",
      "Epoch [303/1000], Loss: 0.6859\n",
      "Epoch [304/1000], Loss: 0.6859\n",
      "Epoch [305/1000], Loss: 0.6859\n",
      "Epoch [306/1000], Loss: 0.6858\n",
      "Epoch [307/1000], Loss: 0.6858\n",
      "Epoch [308/1000], Loss: 0.6858\n",
      "Epoch [309/1000], Loss: 0.6858\n",
      "Epoch [310/1000], Loss: 0.6858\n",
      "Epoch [311/1000], Loss: 0.6858\n",
      "Epoch [312/1000], Loss: 0.6858\n",
      "Epoch [313/1000], Loss: 0.6858\n",
      "Epoch [314/1000], Loss: 0.6857\n",
      "Epoch [315/1000], Loss: 0.6857\n",
      "Epoch [316/1000], Loss: 0.6857\n",
      "Epoch [317/1000], Loss: 0.6857\n",
      "Epoch [318/1000], Loss: 0.6857\n",
      "Epoch [319/1000], Loss: 0.6857\n",
      "Epoch [320/1000], Loss: 0.6857\n",
      "Epoch [321/1000], Loss: 0.6857\n",
      "Epoch [322/1000], Loss: 0.6856\n",
      "Epoch [323/1000], Loss: 0.6856\n",
      "Epoch [324/1000], Loss: 0.6856\n",
      "Epoch [325/1000], Loss: 0.6856\n",
      "Epoch [326/1000], Loss: 0.6856\n",
      "Epoch [327/1000], Loss: 0.6856\n",
      "Epoch [328/1000], Loss: 0.6856\n",
      "Epoch [329/1000], Loss: 0.6856\n",
      "Epoch [330/1000], Loss: 0.6855\n",
      "Epoch [331/1000], Loss: 0.6855\n",
      "Epoch [332/1000], Loss: 0.6855\n",
      "Epoch [333/1000], Loss: 0.6855\n",
      "Epoch [334/1000], Loss: 0.6855\n",
      "Epoch [335/1000], Loss: 0.6855\n",
      "Epoch [336/1000], Loss: 0.6855\n",
      "Epoch [337/1000], Loss: 0.6855\n",
      "Epoch [338/1000], Loss: 0.6854\n",
      "Epoch [339/1000], Loss: 0.6854\n",
      "Epoch [340/1000], Loss: 0.6854\n",
      "Epoch [341/1000], Loss: 0.6854\n",
      "Epoch [342/1000], Loss: 0.6854\n",
      "Epoch [343/1000], Loss: 0.6854\n",
      "Epoch [344/1000], Loss: 0.6854\n",
      "Epoch [345/1000], Loss: 0.6853\n",
      "Epoch [346/1000], Loss: 0.6853\n",
      "Epoch [347/1000], Loss: 0.6853\n",
      "Epoch [348/1000], Loss: 0.6853\n",
      "Epoch [349/1000], Loss: 0.6853\n",
      "Epoch [350/1000], Loss: 0.6853\n",
      "Epoch [351/1000], Loss: 0.6853\n",
      "Epoch [352/1000], Loss: 0.6852\n",
      "Epoch [353/1000], Loss: 0.6852\n",
      "Epoch [354/1000], Loss: 0.6852\n",
      "Epoch [355/1000], Loss: 0.6852\n",
      "Epoch [356/1000], Loss: 0.6852\n",
      "Epoch [357/1000], Loss: 0.6852\n",
      "Epoch [358/1000], Loss: 0.6852\n",
      "Epoch [359/1000], Loss: 0.6852\n",
      "Epoch [360/1000], Loss: 0.6851\n",
      "Epoch [361/1000], Loss: 0.6851\n",
      "Epoch [362/1000], Loss: 0.6851\n",
      "Epoch [363/1000], Loss: 0.6851\n",
      "Epoch [364/1000], Loss: 0.6851\n",
      "Epoch [365/1000], Loss: 0.6851\n",
      "Epoch [366/1000], Loss: 0.6850\n",
      "Epoch [367/1000], Loss: 0.6850\n",
      "Epoch [368/1000], Loss: 0.6850\n",
      "Epoch [369/1000], Loss: 0.6850\n",
      "Epoch [370/1000], Loss: 0.6850\n",
      "Epoch [371/1000], Loss: 0.6850\n",
      "Epoch [372/1000], Loss: 0.6850\n",
      "Epoch [373/1000], Loss: 0.6849\n",
      "Epoch [374/1000], Loss: 0.6849\n",
      "Epoch [375/1000], Loss: 0.6849\n",
      "Epoch [376/1000], Loss: 0.6849\n",
      "Epoch [377/1000], Loss: 0.6849\n",
      "Epoch [378/1000], Loss: 0.6849\n",
      "Epoch [379/1000], Loss: 0.6849\n",
      "Epoch [380/1000], Loss: 0.6848\n",
      "Epoch [381/1000], Loss: 0.6848\n",
      "Epoch [382/1000], Loss: 0.6848\n",
      "Epoch [383/1000], Loss: 0.6848\n",
      "Epoch [384/1000], Loss: 0.6848\n",
      "Epoch [385/1000], Loss: 0.6848\n",
      "Epoch [386/1000], Loss: 0.6847\n",
      "Epoch [387/1000], Loss: 0.6847\n",
      "Epoch [388/1000], Loss: 0.6847\n",
      "Epoch [389/1000], Loss: 0.6847\n",
      "Epoch [390/1000], Loss: 0.6847\n",
      "Epoch [391/1000], Loss: 0.6847\n",
      "Epoch [392/1000], Loss: 0.6846\n",
      "Epoch [393/1000], Loss: 0.6846\n",
      "Epoch [394/1000], Loss: 0.6846\n",
      "Epoch [395/1000], Loss: 0.6846\n",
      "Epoch [396/1000], Loss: 0.6846\n",
      "Epoch [397/1000], Loss: 0.6846\n",
      "Epoch [398/1000], Loss: 0.6845\n",
      "Epoch [399/1000], Loss: 0.6845\n",
      "Epoch [400/1000], Loss: 0.6845\n",
      "Epoch [401/1000], Loss: 0.6845\n",
      "Epoch [402/1000], Loss: 0.6845\n",
      "Epoch [403/1000], Loss: 0.6845\n",
      "Epoch [404/1000], Loss: 0.6844\n",
      "Epoch [405/1000], Loss: 0.6844\n",
      "Epoch [406/1000], Loss: 0.6844\n",
      "Epoch [407/1000], Loss: 0.6844\n",
      "Epoch [408/1000], Loss: 0.6844\n",
      "Epoch [409/1000], Loss: 0.6844\n",
      "Epoch [410/1000], Loss: 0.6843\n",
      "Epoch [411/1000], Loss: 0.6843\n",
      "Epoch [412/1000], Loss: 0.6843\n",
      "Epoch [413/1000], Loss: 0.6843\n",
      "Epoch [414/1000], Loss: 0.6843\n",
      "Epoch [415/1000], Loss: 0.6843\n",
      "Epoch [416/1000], Loss: 0.6842\n",
      "Epoch [417/1000], Loss: 0.6842\n",
      "Epoch [418/1000], Loss: 0.6842\n",
      "Epoch [419/1000], Loss: 0.6842\n",
      "Epoch [420/1000], Loss: 0.6842\n",
      "Epoch [421/1000], Loss: 0.6841\n",
      "Epoch [422/1000], Loss: 0.6841\n",
      "Epoch [423/1000], Loss: 0.6841\n",
      "Epoch [424/1000], Loss: 0.6841\n",
      "Epoch [425/1000], Loss: 0.6841\n",
      "Epoch [426/1000], Loss: 0.6841\n",
      "Epoch [427/1000], Loss: 0.6840\n",
      "Epoch [428/1000], Loss: 0.6840\n",
      "Epoch [429/1000], Loss: 0.6840\n",
      "Epoch [430/1000], Loss: 0.6840\n",
      "Epoch [431/1000], Loss: 0.6840\n",
      "Epoch [432/1000], Loss: 0.6839\n",
      "Epoch [433/1000], Loss: 0.6839\n",
      "Epoch [434/1000], Loss: 0.6839\n",
      "Epoch [435/1000], Loss: 0.6839\n",
      "Epoch [436/1000], Loss: 0.6839\n",
      "Epoch [437/1000], Loss: 0.6838\n",
      "Epoch [438/1000], Loss: 0.6838\n",
      "Epoch [439/1000], Loss: 0.6838\n",
      "Epoch [440/1000], Loss: 0.6838\n",
      "Epoch [441/1000], Loss: 0.6837\n",
      "Epoch [442/1000], Loss: 0.6837\n",
      "Epoch [443/1000], Loss: 0.6837\n",
      "Epoch [444/1000], Loss: 0.6837\n",
      "Epoch [445/1000], Loss: 0.6837\n",
      "Epoch [446/1000], Loss: 0.6836\n",
      "Epoch [447/1000], Loss: 0.6836\n",
      "Epoch [448/1000], Loss: 0.6836\n",
      "Epoch [449/1000], Loss: 0.6836\n",
      "Epoch [450/1000], Loss: 0.6835\n",
      "Epoch [451/1000], Loss: 0.6835\n",
      "Epoch [452/1000], Loss: 0.6835\n",
      "Epoch [453/1000], Loss: 0.6835\n",
      "Epoch [454/1000], Loss: 0.6835\n",
      "Epoch [455/1000], Loss: 0.6834\n",
      "Epoch [456/1000], Loss: 0.6834\n",
      "Epoch [457/1000], Loss: 0.6834\n",
      "Epoch [458/1000], Loss: 0.6834\n",
      "Epoch [459/1000], Loss: 0.6833\n",
      "Epoch [460/1000], Loss: 0.6833\n",
      "Epoch [461/1000], Loss: 0.6833\n",
      "Epoch [462/1000], Loss: 0.6832\n",
      "Epoch [463/1000], Loss: 0.6832\n",
      "Epoch [464/1000], Loss: 0.6832\n",
      "Epoch [465/1000], Loss: 0.6832\n",
      "Epoch [466/1000], Loss: 0.6831\n",
      "Epoch [467/1000], Loss: 0.6831\n",
      "Epoch [468/1000], Loss: 0.6831\n",
      "Epoch [469/1000], Loss: 0.6830\n",
      "Epoch [470/1000], Loss: 0.6830\n",
      "Epoch [471/1000], Loss: 0.6830\n",
      "Epoch [472/1000], Loss: 0.6829\n",
      "Epoch [473/1000], Loss: 0.6829\n",
      "Epoch [474/1000], Loss: 0.6829\n",
      "Epoch [475/1000], Loss: 0.6828\n",
      "Epoch [476/1000], Loss: 0.6828\n",
      "Epoch [477/1000], Loss: 0.6827\n",
      "Epoch [478/1000], Loss: 0.6827\n",
      "Epoch [479/1000], Loss: 0.6827\n",
      "Epoch [480/1000], Loss: 0.6826\n",
      "Epoch [481/1000], Loss: 0.6826\n",
      "Epoch [482/1000], Loss: 0.6825\n",
      "Epoch [483/1000], Loss: 0.6825\n",
      "Epoch [484/1000], Loss: 0.6824\n",
      "Epoch [485/1000], Loss: 0.6824\n",
      "Epoch [486/1000], Loss: 0.6823\n",
      "Epoch [487/1000], Loss: 0.6823\n",
      "Epoch [488/1000], Loss: 0.6822\n",
      "Epoch [489/1000], Loss: 0.6822\n",
      "Epoch [490/1000], Loss: 0.6821\n",
      "Epoch [491/1000], Loss: 0.6821\n",
      "Epoch [492/1000], Loss: 0.6820\n",
      "Epoch [493/1000], Loss: 0.6820\n",
      "Epoch [494/1000], Loss: 0.6819\n",
      "Epoch [495/1000], Loss: 0.6819\n",
      "Epoch [496/1000], Loss: 0.6818\n",
      "Epoch [497/1000], Loss: 0.6818\n",
      "Epoch [498/1000], Loss: 0.6817\n",
      "Epoch [499/1000], Loss: 0.6817\n",
      "Epoch [500/1000], Loss: 0.6816\n",
      "Epoch [501/1000], Loss: 0.6815\n",
      "Epoch [502/1000], Loss: 0.6815\n",
      "Epoch [503/1000], Loss: 0.6814\n",
      "Epoch [504/1000], Loss: 0.6814\n",
      "Epoch [505/1000], Loss: 0.6813\n",
      "Epoch [506/1000], Loss: 0.6812\n",
      "Epoch [507/1000], Loss: 0.6812\n",
      "Epoch [508/1000], Loss: 0.6811\n",
      "Epoch [509/1000], Loss: 0.6811\n",
      "Epoch [510/1000], Loss: 0.6810\n",
      "Epoch [511/1000], Loss: 0.6809\n",
      "Epoch [512/1000], Loss: 0.6809\n",
      "Epoch [513/1000], Loss: 0.6808\n",
      "Epoch [514/1000], Loss: 0.6808\n",
      "Epoch [515/1000], Loss: 0.6807\n",
      "Epoch [516/1000], Loss: 0.6806\n",
      "Epoch [517/1000], Loss: 0.6806\n",
      "Epoch [518/1000], Loss: 0.6805\n",
      "Epoch [519/1000], Loss: 0.6804\n",
      "Epoch [520/1000], Loss: 0.6804\n",
      "Epoch [521/1000], Loss: 0.6803\n",
      "Epoch [522/1000], Loss: 0.6802\n",
      "Epoch [523/1000], Loss: 0.6802\n",
      "Epoch [524/1000], Loss: 0.6801\n",
      "Epoch [525/1000], Loss: 0.6800\n",
      "Epoch [526/1000], Loss: 0.6800\n",
      "Epoch [527/1000], Loss: 0.6799\n",
      "Epoch [528/1000], Loss: 0.6798\n",
      "Epoch [529/1000], Loss: 0.6798\n",
      "Epoch [530/1000], Loss: 0.6797\n",
      "Epoch [531/1000], Loss: 0.6796\n",
      "Epoch [532/1000], Loss: 0.6796\n",
      "Epoch [533/1000], Loss: 0.6795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [534/1000], Loss: 0.6794\n",
      "Epoch [535/1000], Loss: 0.6793\n",
      "Epoch [536/1000], Loss: 0.6793\n",
      "Epoch [537/1000], Loss: 0.6792\n",
      "Epoch [538/1000], Loss: 0.6791\n",
      "Epoch [539/1000], Loss: 0.6791\n",
      "Epoch [540/1000], Loss: 0.6790\n",
      "Epoch [541/1000], Loss: 0.6789\n",
      "Epoch [542/1000], Loss: 0.6788\n",
      "Epoch [543/1000], Loss: 0.6788\n",
      "Epoch [544/1000], Loss: 0.6787\n",
      "Epoch [545/1000], Loss: 0.6786\n",
      "Epoch [546/1000], Loss: 0.6786\n",
      "Epoch [547/1000], Loss: 0.6785\n",
      "Epoch [548/1000], Loss: 0.6784\n",
      "Epoch [549/1000], Loss: 0.6783\n",
      "Epoch [550/1000], Loss: 0.6783\n",
      "Epoch [551/1000], Loss: 0.6782\n",
      "Epoch [552/1000], Loss: 0.6781\n",
      "Epoch [553/1000], Loss: 0.6780\n",
      "Epoch [554/1000], Loss: 0.6780\n",
      "Epoch [555/1000], Loss: 0.6779\n",
      "Epoch [556/1000], Loss: 0.6778\n",
      "Epoch [557/1000], Loss: 0.6777\n",
      "Epoch [558/1000], Loss: 0.6777\n",
      "Epoch [559/1000], Loss: 0.6776\n",
      "Epoch [560/1000], Loss: 0.6775\n",
      "Epoch [561/1000], Loss: 0.6774\n",
      "Epoch [562/1000], Loss: 0.6774\n",
      "Epoch [563/1000], Loss: 0.6773\n",
      "Epoch [564/1000], Loss: 0.6772\n",
      "Epoch [565/1000], Loss: 0.6771\n",
      "Epoch [566/1000], Loss: 0.6770\n",
      "Epoch [567/1000], Loss: 0.6770\n",
      "Epoch [568/1000], Loss: 0.6769\n",
      "Epoch [569/1000], Loss: 0.6768\n",
      "Epoch [570/1000], Loss: 0.6767\n",
      "Epoch [571/1000], Loss: 0.6766\n",
      "Epoch [572/1000], Loss: 0.6766\n",
      "Epoch [573/1000], Loss: 0.6765\n",
      "Epoch [574/1000], Loss: 0.6764\n",
      "Epoch [575/1000], Loss: 0.6763\n",
      "Epoch [576/1000], Loss: 0.6762\n",
      "Epoch [577/1000], Loss: 0.6762\n",
      "Epoch [578/1000], Loss: 0.6761\n",
      "Epoch [579/1000], Loss: 0.6760\n",
      "Epoch [580/1000], Loss: 0.6759\n",
      "Epoch [581/1000], Loss: 0.6758\n",
      "Epoch [582/1000], Loss: 0.6757\n",
      "Epoch [583/1000], Loss: 0.6756\n",
      "Epoch [584/1000], Loss: 0.6756\n",
      "Epoch [585/1000], Loss: 0.6755\n",
      "Epoch [586/1000], Loss: 0.6754\n",
      "Epoch [587/1000], Loss: 0.6753\n",
      "Epoch [588/1000], Loss: 0.6752\n",
      "Epoch [589/1000], Loss: 0.6753\n",
      "Epoch [590/1000], Loss: 0.6754\n",
      "Epoch [591/1000], Loss: 0.6751\n",
      "Epoch [592/1000], Loss: 0.6749\n",
      "Epoch [593/1000], Loss: 0.6750\n",
      "Epoch [594/1000], Loss: 0.6747\n",
      "Epoch [595/1000], Loss: 0.6747\n",
      "Epoch [596/1000], Loss: 0.6746\n",
      "Epoch [597/1000], Loss: 0.6745\n",
      "Epoch [598/1000], Loss: 0.6745\n",
      "Epoch [599/1000], Loss: 0.6743\n",
      "Epoch [600/1000], Loss: 0.6743\n",
      "Epoch [601/1000], Loss: 0.6741\n",
      "Epoch [602/1000], Loss: 0.6740\n",
      "Epoch [603/1000], Loss: 0.6740\n",
      "Epoch [604/1000], Loss: 0.6738\n",
      "Epoch [605/1000], Loss: 0.6738\n",
      "Epoch [606/1000], Loss: 0.6736\n",
      "Epoch [607/1000], Loss: 0.6736\n",
      "Epoch [608/1000], Loss: 0.6735\n",
      "Epoch [609/1000], Loss: 0.6733\n",
      "Epoch [610/1000], Loss: 0.6733\n",
      "Epoch [611/1000], Loss: 0.6732\n",
      "Epoch [612/1000], Loss: 0.6731\n",
      "Epoch [613/1000], Loss: 0.6730\n",
      "Epoch [614/1000], Loss: 0.6728\n",
      "Epoch [615/1000], Loss: 0.6728\n",
      "Epoch [616/1000], Loss: 0.6727\n",
      "Epoch [617/1000], Loss: 0.6725\n",
      "Epoch [618/1000], Loss: 0.6724\n",
      "Epoch [619/1000], Loss: 0.6723\n",
      "Epoch [620/1000], Loss: 0.6722\n",
      "Epoch [621/1000], Loss: 0.6721\n",
      "Epoch [622/1000], Loss: 0.6720\n",
      "Epoch [623/1000], Loss: 0.6719\n",
      "Epoch [624/1000], Loss: 0.6718\n",
      "Epoch [625/1000], Loss: 0.6716\n",
      "Epoch [626/1000], Loss: 0.6715\n",
      "Epoch [627/1000], Loss: 0.6714\n",
      "Epoch [628/1000], Loss: 0.6713\n",
      "Epoch [629/1000], Loss: 0.6712\n",
      "Epoch [630/1000], Loss: 0.6710\n",
      "Epoch [631/1000], Loss: 0.6709\n",
      "Epoch [632/1000], Loss: 0.6708\n",
      "Epoch [633/1000], Loss: 0.6707\n",
      "Epoch [634/1000], Loss: 0.6705\n",
      "Epoch [635/1000], Loss: 0.6704\n",
      "Epoch [636/1000], Loss: 0.6703\n",
      "Epoch [637/1000], Loss: 0.6701\n",
      "Epoch [638/1000], Loss: 0.6700\n",
      "Epoch [639/1000], Loss: 0.6699\n",
      "Epoch [640/1000], Loss: 0.6697\n",
      "Epoch [641/1000], Loss: 0.6696\n",
      "Epoch [642/1000], Loss: 0.6695\n",
      "Epoch [643/1000], Loss: 0.6695\n",
      "Epoch [644/1000], Loss: 0.6696\n",
      "Epoch [645/1000], Loss: 0.6697\n",
      "Epoch [646/1000], Loss: 0.6693\n",
      "Epoch [647/1000], Loss: 0.6687\n",
      "Epoch [648/1000], Loss: 0.6689\n",
      "Epoch [649/1000], Loss: 0.6690\n",
      "Epoch [650/1000], Loss: 0.6684\n",
      "Epoch [651/1000], Loss: 0.6683\n",
      "Epoch [652/1000], Loss: 0.6685\n",
      "Epoch [653/1000], Loss: 0.6680\n",
      "Epoch [654/1000], Loss: 0.6678\n",
      "Epoch [655/1000], Loss: 0.6679\n",
      "Epoch [656/1000], Loss: 0.6676\n",
      "Epoch [657/1000], Loss: 0.6674\n",
      "Epoch [658/1000], Loss: 0.6674\n",
      "Epoch [659/1000], Loss: 0.6672\n",
      "Epoch [660/1000], Loss: 0.6669\n",
      "Epoch [661/1000], Loss: 0.6669\n",
      "Epoch [662/1000], Loss: 0.6668\n",
      "Epoch [663/1000], Loss: 0.6666\n",
      "Epoch [664/1000], Loss: 0.6663\n",
      "Epoch [665/1000], Loss: 0.6663\n",
      "Epoch [666/1000], Loss: 0.6662\n",
      "Epoch [667/1000], Loss: 0.6660\n",
      "Epoch [668/1000], Loss: 0.6658\n",
      "Epoch [669/1000], Loss: 0.6656\n",
      "Epoch [670/1000], Loss: 0.6655\n",
      "Epoch [671/1000], Loss: 0.6654\n",
      "Epoch [672/1000], Loss: 0.6653\n",
      "Epoch [673/1000], Loss: 0.6651\n",
      "Epoch [674/1000], Loss: 0.6649\n",
      "Epoch [675/1000], Loss: 0.6647\n",
      "Epoch [676/1000], Loss: 0.6645\n",
      "Epoch [677/1000], Loss: 0.6643\n",
      "Epoch [678/1000], Loss: 0.6641\n",
      "Epoch [679/1000], Loss: 0.6640\n",
      "Epoch [680/1000], Loss: 0.6639\n",
      "Epoch [681/1000], Loss: 0.6642\n",
      "Epoch [682/1000], Loss: 0.6653\n",
      "Epoch [683/1000], Loss: 0.6671\n",
      "Epoch [684/1000], Loss: 0.6644\n",
      "Epoch [685/1000], Loss: 0.6631\n",
      "Epoch [686/1000], Loss: 0.6647\n",
      "Epoch [687/1000], Loss: 0.6634\n",
      "Epoch [688/1000], Loss: 0.6624\n",
      "Epoch [689/1000], Loss: 0.6635\n",
      "Epoch [690/1000], Loss: 0.6629\n",
      "Epoch [691/1000], Loss: 0.6618\n",
      "Epoch [692/1000], Loss: 0.6623\n",
      "Epoch [693/1000], Loss: 0.6621\n",
      "Epoch [694/1000], Loss: 0.6611\n",
      "Epoch [695/1000], Loss: 0.6608\n",
      "Epoch [696/1000], Loss: 0.6608\n",
      "Epoch [697/1000], Loss: 0.6601\n",
      "Epoch [698/1000], Loss: 0.6586\n",
      "Epoch [699/1000], Loss: 0.6562\n",
      "Epoch [700/1000], Loss: 0.6529\n",
      "Epoch [701/1000], Loss: 0.6524\n",
      "Epoch [702/1000], Loss: 0.6675\n",
      "Epoch [703/1000], Loss: 0.6202\n",
      "Epoch [704/1000], Loss: 0.6512\n",
      "Epoch [705/1000], Loss: 0.5813\n",
      "Epoch [706/1000], Loss: 0.5429\n",
      "Epoch [707/1000], Loss: 0.5076\n",
      "Epoch [708/1000], Loss: 0.4452\n",
      "Epoch [709/1000], Loss: 0.4411\n",
      "Epoch [710/1000], Loss: 0.3774\n",
      "Epoch [711/1000], Loss: 0.3634\n",
      "Epoch [712/1000], Loss: 0.3177\n",
      "Epoch [713/1000], Loss: 0.2947\n",
      "Epoch [714/1000], Loss: 0.2763\n",
      "Epoch [715/1000], Loss: 0.2512\n",
      "Epoch [716/1000], Loss: 0.2386\n",
      "Epoch [717/1000], Loss: 0.2140\n",
      "Epoch [718/1000], Loss: 0.1901\n",
      "Epoch [719/1000], Loss: 0.1731\n",
      "Epoch [720/1000], Loss: 0.1531\n",
      "Epoch [721/1000], Loss: 0.1336\n",
      "Epoch [722/1000], Loss: 0.1141\n",
      "Epoch [723/1000], Loss: 0.1236\n",
      "Epoch [724/1000], Loss: 0.1348\n",
      "Epoch [725/1000], Loss: 0.3490\n",
      "Epoch [726/1000], Loss: 0.1422\n",
      "Epoch [727/1000], Loss: 0.1107\n",
      "Epoch [728/1000], Loss: 0.1747\n",
      "Epoch [729/1000], Loss: 0.2111\n",
      "Epoch [730/1000], Loss: 0.1387\n",
      "Epoch [731/1000], Loss: 0.0852\n",
      "Epoch [732/1000], Loss: 0.0718\n",
      "Epoch [733/1000], Loss: 0.0839\n",
      "Epoch [734/1000], Loss: 0.0978\n",
      "Epoch [735/1000], Loss: 0.0882\n",
      "Epoch [736/1000], Loss: 0.0594\n",
      "Epoch [737/1000], Loss: 0.0417\n",
      "Epoch [738/1000], Loss: 0.0342\n",
      "Epoch [739/1000], Loss: 0.0314\n",
      "Epoch [740/1000], Loss: 0.0336\n",
      "Epoch [741/1000], Loss: 0.0338\n",
      "Epoch [742/1000], Loss: 0.0303\n",
      "Epoch [743/1000], Loss: 0.0291\n",
      "Epoch [744/1000], Loss: 0.0266\n",
      "Epoch [745/1000], Loss: 0.0266\n",
      "Epoch [746/1000], Loss: 0.0200\n",
      "Epoch [747/1000], Loss: 0.0209\n",
      "Epoch [748/1000], Loss: 0.0190\n",
      "Epoch [749/1000], Loss: 0.0134\n",
      "Epoch [750/1000], Loss: 0.0210\n",
      "Epoch [751/1000], Loss: 0.0113\n",
      "Epoch [752/1000], Loss: 0.0201\n",
      "Epoch [753/1000], Loss: 0.0100\n",
      "Epoch [754/1000], Loss: 0.0143\n",
      "Epoch [755/1000], Loss: 0.0140\n",
      "Epoch [756/1000], Loss: 0.0135\n",
      "Epoch [757/1000], Loss: 0.0132\n",
      "Epoch [758/1000], Loss: 0.0076\n",
      "Epoch [759/1000], Loss: 0.0126\n",
      "Epoch [760/1000], Loss: 0.0069\n",
      "Epoch [761/1000], Loss: 0.0066\n",
      "Epoch [762/1000], Loss: 0.0117\n",
      "Epoch [763/1000], Loss: 0.0061\n",
      "Epoch [764/1000], Loss: 0.0058\n",
      "Epoch [765/1000], Loss: 0.0111\n",
      "Epoch [766/1000], Loss: 0.0164\n",
      "Epoch [767/1000], Loss: 0.0053\n",
      "Epoch [768/1000], Loss: 0.0105\n",
      "Epoch [769/1000], Loss: 0.0104\n",
      "Epoch [770/1000], Loss: 0.0049\n",
      "Epoch [771/1000], Loss: 0.0102\n",
      "Epoch [772/1000], Loss: 0.0047\n",
      "Epoch [773/1000], Loss: 0.0154\n",
      "Epoch [774/1000], Loss: 0.0099\n",
      "Epoch [775/1000], Loss: 0.0044\n",
      "Epoch [776/1000], Loss: 0.0099\n",
      "Epoch [777/1000], Loss: 0.0043\n",
      "Epoch [778/1000], Loss: 0.0042\n",
      "Epoch [779/1000], Loss: 0.0097\n",
      "Epoch [780/1000], Loss: 0.0096\n",
      "Epoch [781/1000], Loss: 0.0040\n",
      "Epoch [782/1000], Loss: 0.0095\n",
      "Epoch [783/1000], Loss: 0.0150\n",
      "Epoch [784/1000], Loss: 0.0038\n",
      "Epoch [785/1000], Loss: 0.0038\n",
      "Epoch [786/1000], Loss: 0.0150\n",
      "Epoch [787/1000], Loss: 0.0094\n",
      "Epoch [788/1000], Loss: 0.0036\n",
      "Epoch [789/1000], Loss: 0.0092\n",
      "Epoch [790/1000], Loss: 0.0092\n",
      "Epoch [791/1000], Loss: 0.0092\n",
      "Epoch [792/1000], Loss: 0.0146\n",
      "Epoch [793/1000], Loss: 0.0034\n",
      "Epoch [794/1000], Loss: 0.0034\n",
      "Epoch [795/1000], Loss: 0.0033\n",
      "Epoch [796/1000], Loss: 0.0033\n",
      "Epoch [797/1000], Loss: 0.0090\n",
      "Epoch [798/1000], Loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [799/1000], Loss: 0.0146\n",
      "Epoch [800/1000], Loss: 0.0201\n",
      "Epoch [801/1000], Loss: 0.0146\n",
      "Epoch [802/1000], Loss: 0.0031\n",
      "Epoch [803/1000], Loss: 0.0031\n",
      "Epoch [804/1000], Loss: 0.0201\n",
      "Epoch [805/1000], Loss: 0.0030\n",
      "Epoch [806/1000], Loss: 0.0030\n",
      "Epoch [807/1000], Loss: 0.0030\n",
      "Epoch [808/1000], Loss: 0.0030\n",
      "Epoch [809/1000], Loss: 0.0086\n",
      "Epoch [810/1000], Loss: 0.0086\n",
      "Epoch [811/1000], Loss: 0.0029\n",
      "Epoch [812/1000], Loss: 0.0028\n",
      "Epoch [813/1000], Loss: 0.0086\n",
      "Epoch [814/1000], Loss: 0.0028\n",
      "Epoch [815/1000], Loss: 0.0143\n",
      "Epoch [816/1000], Loss: 0.0027\n",
      "Epoch [817/1000], Loss: 0.0027\n",
      "Epoch [818/1000], Loss: 0.0202\n",
      "Epoch [819/1000], Loss: 0.0143\n",
      "Epoch [820/1000], Loss: 0.0026\n",
      "Epoch [821/1000], Loss: 0.0085\n",
      "Epoch [822/1000], Loss: 0.0084\n",
      "Epoch [823/1000], Loss: 0.0142\n",
      "Epoch [824/1000], Loss: 0.0084\n",
      "Epoch [825/1000], Loss: 0.0026\n",
      "Epoch [826/1000], Loss: 0.0026\n",
      "Epoch [827/1000], Loss: 0.0084\n",
      "Epoch [828/1000], Loss: 0.0084\n",
      "Epoch [829/1000], Loss: 0.0025\n",
      "Epoch [830/1000], Loss: 0.0083\n",
      "Epoch [831/1000], Loss: 0.0025\n",
      "Epoch [832/1000], Loss: 0.0024\n",
      "Epoch [833/1000], Loss: 0.0024\n",
      "Epoch [834/1000], Loss: 0.0024\n",
      "Epoch [835/1000], Loss: 0.0024\n",
      "Epoch [836/1000], Loss: 0.0024\n",
      "Epoch [837/1000], Loss: 0.0023\n",
      "Epoch [838/1000], Loss: 0.0083\n",
      "Epoch [839/1000], Loss: 0.0023\n",
      "Epoch [840/1000], Loss: 0.0083\n",
      "Epoch [841/1000], Loss: 0.0083\n",
      "Epoch [842/1000], Loss: 0.0022\n",
      "Epoch [843/1000], Loss: 0.0082\n",
      "Epoch [844/1000], Loss: 0.0022\n",
      "Epoch [845/1000], Loss: 0.0081\n",
      "Epoch [846/1000], Loss: 0.0022\n",
      "Epoch [847/1000], Loss: 0.0021\n",
      "Epoch [848/1000], Loss: 0.0021\n",
      "Epoch [849/1000], Loss: 0.0021\n",
      "Epoch [850/1000], Loss: 0.0021\n",
      "Epoch [851/1000], Loss: 0.0081\n",
      "Epoch [852/1000], Loss: 0.0082\n",
      "Epoch [853/1000], Loss: 0.0144\n",
      "Epoch [854/1000], Loss: 0.0020\n",
      "Epoch [855/1000], Loss: 0.0020\n",
      "Epoch [856/1000], Loss: 0.0020\n",
      "Epoch [857/1000], Loss: 0.0020\n",
      "Epoch [858/1000], Loss: 0.0020\n",
      "Epoch [859/1000], Loss: 0.0081\n",
      "Epoch [860/1000], Loss: 0.0019\n",
      "Epoch [861/1000], Loss: 0.0081\n",
      "Epoch [862/1000], Loss: 0.0081\n",
      "Epoch [863/1000], Loss: 0.0019\n",
      "Epoch [864/1000], Loss: 0.0143\n",
      "Epoch [865/1000], Loss: 0.0019\n",
      "Epoch [866/1000], Loss: 0.0019\n",
      "Epoch [867/1000], Loss: 0.0018\n",
      "Epoch [868/1000], Loss: 0.0018\n",
      "Epoch [869/1000], Loss: 0.0141\n",
      "Epoch [870/1000], Loss: 0.0143\n",
      "Epoch [871/1000], Loss: 0.0018\n",
      "Epoch [872/1000], Loss: 0.0080\n",
      "Epoch [873/1000], Loss: 0.0080\n",
      "Epoch [874/1000], Loss: 0.0018\n",
      "Epoch [875/1000], Loss: 0.0018\n",
      "Epoch [876/1000], Loss: 0.0017\n",
      "Epoch [877/1000], Loss: 0.0017\n",
      "Epoch [878/1000], Loss: 0.0080\n",
      "Epoch [879/1000], Loss: 0.0017\n",
      "Epoch [880/1000], Loss: 0.0017\n",
      "Epoch [881/1000], Loss: 0.0017\n",
      "Epoch [882/1000], Loss: 0.0080\n",
      "Epoch [883/1000], Loss: 0.0016\n",
      "Epoch [884/1000], Loss: 0.0016\n",
      "Epoch [885/1000], Loss: 0.0079\n",
      "Epoch [886/1000], Loss: 0.0016\n",
      "Epoch [887/1000], Loss: 0.0016\n",
      "Epoch [888/1000], Loss: 0.0079\n",
      "Epoch [889/1000], Loss: 0.0015\n",
      "Epoch [890/1000], Loss: 0.0015\n",
      "Epoch [891/1000], Loss: 0.0015\n",
      "Epoch [892/1000], Loss: 0.0015\n",
      "Epoch [893/1000], Loss: 0.0015\n",
      "Epoch [894/1000], Loss: 0.0014\n",
      "Epoch [895/1000], Loss: 0.0079\n",
      "Epoch [896/1000], Loss: 0.0014\n",
      "Epoch [897/1000], Loss: 0.0014\n",
      "Epoch [898/1000], Loss: 0.0014\n",
      "Epoch [899/1000], Loss: 0.0014\n",
      "Epoch [900/1000], Loss: 0.0014\n",
      "Epoch [901/1000], Loss: 0.0014\n",
      "Epoch [902/1000], Loss: 0.0013\n",
      "Epoch [903/1000], Loss: 0.0079\n",
      "Epoch [904/1000], Loss: 0.0013\n",
      "Epoch [905/1000], Loss: 0.0013\n",
      "Epoch [906/1000], Loss: 0.0013\n",
      "Epoch [907/1000], Loss: 0.0013\n",
      "Epoch [908/1000], Loss: 0.0078\n",
      "Epoch [909/1000], Loss: 0.0013\n",
      "Epoch [910/1000], Loss: 0.0079\n",
      "Epoch [911/1000], Loss: 0.0013\n",
      "Epoch [912/1000], Loss: 0.0012\n",
      "Epoch [913/1000], Loss: 0.0141\n",
      "Epoch [914/1000], Loss: 0.0012\n",
      "Epoch [915/1000], Loss: 0.0012\n",
      "Epoch [916/1000], Loss: 0.0078\n",
      "Epoch [917/1000], Loss: 0.0012\n",
      "Epoch [918/1000], Loss: 0.0012\n",
      "Epoch [919/1000], Loss: 0.0012\n",
      "Epoch [920/1000], Loss: 0.0144\n",
      "Epoch [921/1000], Loss: 0.0012\n",
      "Epoch [922/1000], Loss: 0.0078\n",
      "Epoch [923/1000], Loss: 0.0078\n",
      "Epoch [924/1000], Loss: 0.0012\n",
      "Epoch [925/1000], Loss: 0.0012\n",
      "Epoch [926/1000], Loss: 0.0012\n",
      "Epoch [927/1000], Loss: 0.0078\n",
      "Epoch [928/1000], Loss: 0.0077\n",
      "Epoch [929/1000], Loss: 0.0011\n",
      "Epoch [930/1000], Loss: 0.0011\n",
      "Epoch [931/1000], Loss: 0.0011\n",
      "Epoch [932/1000], Loss: 0.0011\n",
      "Epoch [933/1000], Loss: 0.0011\n",
      "Epoch [934/1000], Loss: 0.0078\n",
      "Epoch [935/1000], Loss: 0.0011\n",
      "Epoch [936/1000], Loss: 0.0011\n",
      "Epoch [937/1000], Loss: 0.0144\n",
      "Epoch [938/1000], Loss: 0.0078\n",
      "Epoch [939/1000], Loss: 0.0011\n",
      "Epoch [940/1000], Loss: 0.0011\n",
      "Epoch [941/1000], Loss: 0.0011\n",
      "Epoch [942/1000], Loss: 0.0077\n",
      "Epoch [943/1000], Loss: 0.0078\n",
      "Epoch [944/1000], Loss: 0.0011\n",
      "Epoch [945/1000], Loss: 0.0011\n",
      "Epoch [946/1000], Loss: 0.0011\n",
      "Epoch [947/1000], Loss: 0.0078\n",
      "Epoch [948/1000], Loss: 0.0011\n",
      "Epoch [949/1000], Loss: 0.0011\n",
      "Epoch [950/1000], Loss: 0.0011\n",
      "Epoch [951/1000], Loss: 0.0145\n",
      "Epoch [952/1000], Loss: 0.0078\n",
      "Epoch [953/1000], Loss: 0.0011\n",
      "Epoch [954/1000], Loss: 0.0078\n",
      "Epoch [955/1000], Loss: 0.0010\n",
      "Epoch [956/1000], Loss: 0.0010\n",
      "Epoch [957/1000], Loss: 0.0010\n",
      "Epoch [958/1000], Loss: 0.0212\n",
      "Epoch [959/1000], Loss: 0.0010\n",
      "Epoch [960/1000], Loss: 0.0010\n",
      "Epoch [961/1000], Loss: 0.0010\n",
      "Epoch [962/1000], Loss: 0.0010\n",
      "Epoch [963/1000], Loss: 0.0010\n",
      "Epoch [964/1000], Loss: 0.0143\n",
      "Epoch [965/1000], Loss: 0.0010\n",
      "Epoch [966/1000], Loss: 0.0078\n",
      "Epoch [967/1000], Loss: 0.0010\n",
      "Epoch [968/1000], Loss: 0.0010\n",
      "Epoch [969/1000], Loss: 0.0010\n",
      "Epoch [970/1000], Loss: 0.0010\n",
      "Epoch [971/1000], Loss: 0.0010\n",
      "Epoch [972/1000], Loss: 0.0010\n",
      "Epoch [973/1000], Loss: 0.0010\n",
      "Epoch [974/1000], Loss: 0.0077\n",
      "Epoch [975/1000], Loss: 0.0077\n",
      "Epoch [976/1000], Loss: 0.0010\n",
      "Epoch [977/1000], Loss: 0.0077\n",
      "Epoch [978/1000], Loss: 0.0010\n",
      "Epoch [979/1000], Loss: 0.0010\n",
      "Epoch [980/1000], Loss: 0.0010\n",
      "Epoch [981/1000], Loss: 0.0010\n",
      "Epoch [982/1000], Loss: 0.0010\n",
      "Epoch [983/1000], Loss: 0.0077\n",
      "Epoch [984/1000], Loss: 0.0010\n",
      "Epoch [985/1000], Loss: 0.0010\n",
      "Epoch [986/1000], Loss: 0.0077\n",
      "Epoch [987/1000], Loss: 0.0009\n",
      "Epoch [988/1000], Loss: 0.0077\n",
      "Epoch [989/1000], Loss: 0.0009\n",
      "Epoch [990/1000], Loss: 0.0077\n",
      "Epoch [991/1000], Loss: 0.0077\n",
      "Epoch [992/1000], Loss: 0.0009\n",
      "Epoch [993/1000], Loss: 0.0146\n",
      "Epoch [994/1000], Loss: 0.0009\n",
      "Epoch [995/1000], Loss: 0.0009\n",
      "Epoch [996/1000], Loss: 0.0009\n",
      "Epoch [997/1000], Loss: 0.0144\n",
      "Epoch [998/1000], Loss: 0.0009\n",
      "Epoch [999/1000], Loss: 0.0009\n",
      "Epoch [1000/1000], Loss: 0.0009\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_lstm(training_data[:,:-1],1.0)\n",
    "    loss = criterion(output, training_data[:,-1])\n",
    "    losses.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0767b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(2000),[los.item() for los in losses])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"LSTM Loss VS Epoch for Training batch size 1500\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3cee8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average(over batch) no. of Wrong predictions in set - 0 : 44.1000%\n",
      "Average(over batch) no. of Wrong predictions in set - 1 : 45.4000%\n",
      "Average(over batch) no. of Wrong predictions in set - 2 : 44.7333%\n",
      "Average(over batch) no. of Wrong predictions in set - 3 : 44.4667%\n",
      "Average(over batch) no. of Wrong predictions in set - 4 : 46.5667%\n",
      "Average(over batch) no. of Wrong predictions in set - 5 : 45.6000%\n",
      "Average(over batch) no. of Wrong predictions in set - 6 : 45.8333%\n",
      "Average(over batch) no. of Wrong predictions in set - 7 : 44.3000%\n",
      "Average(over batch) no. of Wrong predictions in set - 8 : 46.7333%\n",
      "Average(over batch) no. of Wrong predictions in set - 9 : 45.1000%\n"
     ]
    }
   ],
   "source": [
    "for idx,test in enumerate(test_datasets):\n",
    "    model_lstm.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model_lstm(test[:,:-1],0.0)\n",
    "        predictions = torch.argmax(output,dim=1)\n",
    "        actual = torch.argmax(test[:,-1],dim=1)\n",
    "        wrong_pred = torch.where(predictions != actual,1.0,0.0)\n",
    "        print(f'Average(over batch) no. of Wrong predictions in set - {idx} : {100*(torch.sum(wrong_pred) / wrong_pred.shape[0]):.4f}%')\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38a873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
